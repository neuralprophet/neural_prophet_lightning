{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0aa2aa96",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fd1f2d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralprophet import NBeats, LSTM, DeepAR, NeuralProphet, TFT\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdc7a13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loc = '../../LIBRA/'\n",
    "datasets = os.listdir(data_loc)\n",
    "\n",
    "datasets_economics = [dataset for dataset in datasets if 'economics' in dataset]\n",
    "datasets_finance = [dataset for dataset in datasets if 'finance' in dataset]\n",
    "datasets_human = [dataset for dataset in datasets if 'human' in dataset]\n",
    "datasets_nature = [dataset for dataset in datasets if 'nature' in dataset]\n",
    "\n",
    "one-step-ahead, multistep, rolling_origin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "202a9028",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    return 200*np.mean(np.abs((y_true-y_pred))/(np.abs(y_true+y_pred)))\n",
    "def mase(y_true, y_pred, y_pred_naive):\n",
    "    \n",
    "    naive_mae = mae(y_true, y_pred_naive)\n",
    "    y_pred_mae = mae(y_true, y_pred)\n",
    "\n",
    "    return y_pred_mae/naive_mae\n",
    "\n",
    "def mues(y_true, y_pred):\n",
    "    return(np.mean(np.maximum(np.sign(y_true-y_pred),0)))\n",
    "\n",
    "def moes(y_true, y_pred):\n",
    "    return(np.mean(np.maximum(np.sign(y_pred-y_true),0)))\n",
    "\n",
    "def muas(y_true, y_pred):\n",
    "    m = mues(y_true, y_pred)\n",
    "    if m == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return (1/m) * np.mean(np.maximum(y_true - y_pred, 0)/np.abs(y_true))\n",
    "\n",
    "def moas(y_true, y_pred):\n",
    "    m = moes(y_true, y_pred)\n",
    "    if m == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return (1/m) * np.mean(np.maximum(y_pred - y_true, 0)/np.abs(y_true))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8160d242",
   "metadata": {},
   "outputs": [],
   "source": [
    "usecase = 'finance'\n",
    "\n",
    "datasets = {}\n",
    "\n",
    "if usecase == 'economics':\n",
    "    for dataset in datasets_economics:\n",
    "        datasets.update({dataset:pd.read_csv(data_loc + dataset, header = None)})\n",
    "elif usecase == 'finance':\n",
    "    for dataset in datasets_finance:\n",
    "        datasets.update({dataset:pd.read_csv(data_loc + dataset, header = None)})\n",
    "elif usecase == 'human':\n",
    "    for dataset in datasets_human:\n",
    "        datasets.update({dataset:pd.read_csv(data_loc + dataset, header = None)})\n",
    "elif usecase == 'nature':\n",
    "    for dataset in datasets_nature:\n",
    "        datasets.update({dataset:pd.read_csv(data_loc + dataset, header = None)})\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ab4a993",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'finance_33.csv':                0\n",
       " 0    2854.123802\n",
       " 1    2862.026398\n",
       " 2    2862.026398\n",
       " 3    2877.831590\n",
       " 4    2885.734186\n",
       " ..           ...\n",
       " 319  1676.636996\n",
       " 320  1668.734400\n",
       " 321  1660.831804\n",
       " 322  1652.929208\n",
       " 323  1668.734400\n",
       " \n",
       " [324 rows x 1 columns],\n",
       " 'finance_27.csv':                0\n",
       " 0     111.314362\n",
       " 1     111.681110\n",
       " 2     109.629995\n",
       " 3     109.049671\n",
       " 4     111.845929\n",
       " ...          ...\n",
       " 4206  557.732206\n",
       " 4207  553.035318\n",
       " 4208  553.635142\n",
       " 4209  556.589981\n",
       " 4210  554.253337\n",
       " \n",
       " [4211 rows x 1 columns],\n",
       " 'finance_26.csv':                 0\n",
       " 0     3694.299157\n",
       " 1     3757.561279\n",
       " 2     3846.590277\n",
       " 3     3810.872056\n",
       " 4     3762.803506\n",
       " ...           ...\n",
       " 4205  3640.988380\n",
       " 4206  3723.086977\n",
       " 4207  3693.410644\n",
       " 4208  3789.547746\n",
       " 4209  3781.462278\n",
       " \n",
       " [4210 rows x 1 columns],\n",
       " 'finance_32.csv':                0\n",
       " 0     994.064991\n",
       " 1     994.064991\n",
       " 2    1008.736841\n",
       " 3    1016.072766\n",
       " 4    1016.072766\n",
       " ..           ...\n",
       " 319  1815.688566\n",
       " 320  1808.352641\n",
       " 321  1830.360416\n",
       " 322  1823.024491\n",
       " 323  1830.360416\n",
       " \n",
       " [324 rows x 1 columns],\n",
       " 'finance_24.csv':                 0\n",
       " 0     1313.121294\n",
       " 1     1313.121294\n",
       " 2     1313.121294\n",
       " 3     1323.318707\n",
       " 4     1323.318707\n",
       " ..            ...\n",
       " 547  13300.180250\n",
       " 548  13300.180250\n",
       " 549  13300.180250\n",
       " 550  13300.180250\n",
       " 551  13300.180250\n",
       " \n",
       " [552 rows x 1 columns],\n",
       " 'finance_30.csv':                0\n",
       " 0    4072.143310\n",
       " 1    4182.706782\n",
       " 2    4230.091128\n",
       " 3    4024.758964\n",
       " 4    3929.990273\n",
       " ..           ...\n",
       " 319  7704.943133\n",
       " 320  7768.122260\n",
       " 321  7926.070079\n",
       " 322  8052.428333\n",
       " 323  8068.223115\n",
       " \n",
       " [324 rows x 1 columns],\n",
       " 'finance_18.csv':               0\n",
       " 0   6147.079672\n",
       " 1   6266.143415\n",
       " 2   6384.943451\n",
       " 3   6332.729451\n",
       " 4   6631.179930\n",
       " 5   6694.008140\n",
       " 6   6507.105753\n",
       " 7   6850.584214\n",
       " 8   6854.342040\n",
       " 9   6733.366421\n",
       " 10  6163.363584\n",
       " 11  6398.656219\n",
       " 12  6179.911203\n",
       " 13  5869.593906\n",
       " 14  5825.818532\n",
       " 15  6008.963093\n",
       " 16  6299.897921\n",
       " 17  6343.673295\n",
       " 18  6681.482054\n",
       " 19  7091.546551\n",
       " 20  6979.339192\n",
       " 21  6217.093900\n",
       " 22  6268.055292\n",
       " 23  6613.709337\n",
       " 24  6726.510037\n",
       " 25  6936.223086\n",
       " 26  7440.628788\n",
       " 27  6787.228590\n",
       " 28  6300.227555\n",
       " 29  6150.244157\n",
       " 30  5561.584045\n",
       " 31  5443.245497\n",
       " 32  5361.430378\n",
       " 33  5494.404669\n",
       " 34  5880.339969\n",
       " 35  5949.892709\n",
       " 36  6111.347364\n",
       " 37  6377.823360\n",
       " 38  6292.250416,\n",
       " 'finance_19.csv':               0\n",
       " 0   5738.044421\n",
       " 1   5748.203368\n",
       " 2   5754.045852\n",
       " 3   5723.525411\n",
       " 4   5645.044277\n",
       " 5   5566.563143\n",
       " 6   5525.840154\n",
       " 7   5460.439209\n",
       " 8   5432.840010\n",
       " 9   5249.717364\n",
       " 10  5100.036401\n",
       " 11  5406.679632\n",
       " 12  5485.160766\n",
       " 13  5525.840154\n",
       " 14  5560.720658\n",
       " 15  5700.242675\n",
       " 16  5572.362026\n",
       " 17  5861.565006\n",
       " 18  5909.525699\n",
       " 19  5963.328877\n",
       " 20  5976.409066\n",
       " 21  5820.885618\n",
       " 22  5924.088310\n",
       " 23  5916.807004\n",
       " 24  5736.605600\n",
       " 25  5653.764403\n",
       " 26  5348.559992\n",
       " 27  4838.432620\n",
       " 28  4688.708056\n",
       " 29  4717.789676\n",
       " 30  4947.434195\n",
       " 31  4687.269235\n",
       " 32  4748.310117\n",
       " 33  4646.589847\n",
       " 34  4646.589847\n",
       " 35  4530.306967\n",
       " 36  4236.743924\n",
       " 37  4230.901440\n",
       " 38  4246.902871\n",
       " 39  4117.539802\n",
       " 40  4166.982916\n",
       " 41  4521.586841,\n",
       " 'finance_31.csv':                 0\n",
       " 0     7997.749506\n",
       " 1     8016.064157\n",
       " 2     8052.693459\n",
       " 3     8144.266714\n",
       " 4     8199.210667\n",
       " ..            ...\n",
       " 319  13382.256903\n",
       " 320  13363.942252\n",
       " 321  13455.515507\n",
       " 322  13437.200856\n",
       " 323  13418.886205\n",
       " \n",
       " [324 rows x 1 columns],\n",
       " 'finance_25.csv':                  0\n",
       " 0      1036.385787\n",
       " 1       930.588031\n",
       " 2       861.718869\n",
       " 3       863.367241\n",
       " 4       927.537193\n",
       " ...            ...\n",
       " 4203  11923.498774\n",
       " 4204  11896.508151\n",
       " 4205  11852.956820\n",
       " 4206  11808.101989\n",
       " 4207  12019.957406\n",
       " \n",
       " [4208 rows x 1 columns],\n",
       " 'finance_21.csv':                0\n",
       " 0   11338.747712\n",
       " 1   11743.262665\n",
       " 2   12312.811040\n",
       " 3   12211.105973\n",
       " 4   11779.469669\n",
       " 5   12649.590418\n",
       " 6   10784.997523\n",
       " 7   10728.517310\n",
       " 8   10667.494269\n",
       " 9   11146.592938\n",
       " 10  11361.326236\n",
       " 11  11092.350236\n",
       " 12  10771.436848\n",
       " 13   9702.380987\n",
       " 14   8904.606442\n",
       " 15   8793.815722\n",
       " 16   9105.711261\n",
       " 17   9008.549020\n",
       " 18   8906.843953\n",
       " 19   8418.659631\n",
       " 20   8337.295578\n",
       " 21   8217.487009\n",
       " 22   8339.533089\n",
       " 23   8599.491241\n",
       " 24   8662.751792\n",
       " 25   7932.712821\n",
       " 26   6893.083627\n",
       " 27   6474.940194\n",
       " 28   5826.333081\n",
       " 29   5885.050806\n",
       " 30   5620.617632\n",
       " 31   4938.108829\n",
       " 32   4908.682163\n",
       " 33   5069.172758\n",
       " 34   4840.878785\n",
       " 35   4278.110747\n",
       " 36   3972.995546\n",
       " 37   3778.671065\n",
       " 38   4782.161059\n",
       " 39   5665.842485\n",
       " 40   6070.425241\n",
       " 41   5914.477472\n",
       " 42   5281.600742\n",
       " 43   5362.964795,\n",
       " 'finance_35.csv':                0\n",
       " 0     368.883734\n",
       " 1     364.674112\n",
       " 2     368.883734\n",
       " 3     419.980302\n",
       " 4     364.674112\n",
       " ..           ...\n",
       " 95  18235.880404\n",
       " 96  21142.245336\n",
       " 97  19234.768935\n",
       " 98  18803.303149\n",
       " 99  21889.029895\n",
       " \n",
       " [100 rows x 1 columns],\n",
       " 'finance_34.csv':                 0\n",
       " 0     2326.958954\n",
       " 1     2437.347549\n",
       " 2     2437.347549\n",
       " 3     2437.347549\n",
       " 4     2437.347549\n",
       " ..            ...\n",
       " 246  11489.212350\n",
       " 247  11489.212350\n",
       " 248  11709.989541\n",
       " 249  11709.989541\n",
       " 250  11709.989541\n",
       " \n",
       " [251 rows x 1 columns],\n",
       " 'finance_20.csv':               0\n",
       " 0   7053.806645\n",
       " 1   7162.719618\n",
       " 2   7266.040399\n",
       " 3   7418.747637\n",
       " 4   7063.913015\n",
       " 5   7215.508553\n",
       " 6   6874.115401\n",
       " 7   7283.996048\n",
       " 8   6903.322808\n",
       " 9   6886.478859\n",
       " 10  5496.280399\n",
       " 11  5479.436450\n",
       " 12  5090.913930\n",
       " 13  4860.724528\n",
       " 14  4859.579139\n",
       " 15  5099.908599\n",
       " 16  5147.071655\n",
       " 17  5126.858917\n",
       " 18  4852.841560\n",
       " 19  4636.127316\n",
       " 20  4577.746190\n",
       " 21  4614.802877\n",
       " 22  4600.182329\n",
       " 23  5011.174677\n",
       " 24  5188.608833\n",
       " 25  5048.231364\n",
       " 26  5048.231364\n",
       " 27  5094.282720\n",
       " 28  5131.339407\n",
       " 29  5156.032636\n",
       " 30  6296.940656\n",
       " 31  6295.828955\n",
       " 32  6209.352122\n",
       " 33  5131.339407\n",
       " 34  5613.076339\n",
       " 35  5065.075313\n",
       " 36  5081.919262\n",
       " 37  4949.424761\n",
       " 38  4659.708844\n",
       " 39  4724.827550\n",
       " 40  3846.718817\n",
       " 41  3530.052582\n",
       " 42  3421.105922\n",
       " 43  3409.887852\n",
       " 44  4084.757500\n",
       " 45  3665.915872\n",
       " 46  3747.878526,\n",
       " 'finance_36.csv':                0\n",
       " 0    1387.314249\n",
       " 1    1202.042049\n",
       " 2    1278.633185\n",
       " 3    1155.090049\n",
       " 4    1226.889766\n",
       " ..           ...\n",
       " 188  2407.864260\n",
       " 189  2169.801406\n",
       " 190  2024.869226\n",
       " 191  2266.012322\n",
       " 192  2172.331620\n",
       " \n",
       " [193 rows x 1 columns],\n",
       " 'finance_22.csv':               0\n",
       " 0   5516.671011\n",
       " 1   5658.026814\n",
       " 2   5603.655614\n",
       " 3   5550.868493\n",
       " 4   5786.896343\n",
       " 5   5715.472992\n",
       " 6   4620.594494\n",
       " 7   4710.654074\n",
       " 8   5645.587131\n",
       " 9   5644.049642\n",
       " 10  5479.398552\n",
       " 11  6085.076019\n",
       " 12  8647.557612\n",
       " 13  8290.394268\n",
       " 14  6970.296933\n",
       " 15  5712.351424\n",
       " 16  5029.054059\n",
       " 17  4904.796997\n",
       " 18  5459.224833\n",
       " 19  6179.841247\n",
       " 20  6582.057676\n",
       " 21  7030.864679\n",
       " 22  7079.039333\n",
       " 23  6985.858185\n",
       " 24  6842.964893\n",
       " 25  6846.086461\n",
       " 26  6880.237352\n",
       " 27  6726.488457\n",
       " 28  6133.250673\n",
       " 29  5906.494347\n",
       " 30  5887.858117\n",
       " 31  5864.562830\n",
       " 32  5746.548905\n",
       " 33  6022.970783\n",
       " 34  6656.602595\n",
       " 35  6970.296933\n",
       " 36  6148.765334,\n",
       " 'finance_23.csv':                0\n",
       " 0     272.189234\n",
       " 1     260.792034\n",
       " 2     243.696233\n",
       " 3     272.189234\n",
       " 4     249.394833\n",
       " ..           ...\n",
       " 64  15453.260485\n",
       " 65  15390.575882\n",
       " 66  16940.595169\n",
       " 67  16097.202321\n",
       " 68  17185.634982\n",
       " \n",
       " [69 rows x 1 columns],\n",
       " 'finance_37.csv':               0\n",
       " 0   1875.511918\n",
       " 1   1609.459649\n",
       " 2   1568.644812\n",
       " 3   1691.089322\n",
       " 4   1939.001664\n",
       " ..          ...\n",
       " 91  4791.505258\n",
       " 92  6761.199049\n",
       " 93  4590.454395\n",
       " 94  4717.433888\n",
       " 95  4779.411973\n",
       " \n",
       " [96 rows x 1 columns],\n",
       " 'finance_5.csv':                0\n",
       " 0    2622.948850\n",
       " 1    2824.855654\n",
       " 2    2714.724670\n",
       " 3    2622.948850\n",
       " 4    2824.855654\n",
       " 5    2925.809055\n",
       " 6    3146.071023\n",
       " 7    2898.276309\n",
       " 8    2980.874547\n",
       " 9    3274.557171\n",
       " 10   3861.922418\n",
       " 11   3816.034508\n",
       " 12   4265.736026\n",
       " 13   4339.156682\n",
       " 14   4274.913608\n",
       " 15   4238.203280\n",
       " 16   4128.072296\n",
       " 17   4192.315370\n",
       " 18   4256.558444\n",
       " 19   4898.989183\n",
       " 20   5339.513119\n",
       " 21   5972.766276\n",
       " 22   6752.860745\n",
       " 23   7808.282674\n",
       " 24   7285.160501\n",
       " 25   7000.655459\n",
       " 26   7156.674353\n",
       " 27   8285.516937\n",
       " 28   8781.106365\n",
       " 29   8267.161773\n",
       " 30   7734.862018\n",
       " 31   8322.227265\n",
       " 32   9285.873374\n",
       " 33  11699.577438\n",
       " 34  13819.598877\n",
       " 35  13709.467893\n",
       " 36  11727.110184\n",
       " 37  12378.718505\n",
       " 38  11057.146698\n",
       " 39   8909.592513\n",
       " 40   9093.144153\n",
       " 41   9340.938866\n",
       " 42   8863.704603\n",
       " 43   8964.658005\n",
       " 44   8469.068577\n",
       " 45   7844.993002\n",
       " 46   6918.057221,\n",
       " 'finance_93.csv':                0\n",
       " 0     133.210199\n",
       " 1     133.174191\n",
       " 2     132.548786\n",
       " 3     132.850005\n",
       " 4     132.868786\n",
       " ...          ...\n",
       " 1197  164.295154\n",
       " 1198  164.015468\n",
       " 1199  163.904096\n",
       " 1200  162.651013\n",
       " 1201  162.149660\n",
       " \n",
       " [1202 rows x 1 columns],\n",
       " 'finance_87.csv':                0\n",
       " 0      12.968413\n",
       " 1      12.974406\n",
       " 2      12.977402\n",
       " 3      12.977402\n",
       " 4      12.995383\n",
       " ...          ...\n",
       " 12123  81.374017\n",
       " 12124  80.560845\n",
       " 12125  79.977813\n",
       " 12126  79.686300\n",
       " 12127  79.295054\n",
       " \n",
       " [12128 rows x 1 columns],\n",
       " 'finance_50.csv':                  0\n",
       " 0      1222.723531\n",
       " 1      1425.355651\n",
       " 2      1296.603268\n",
       " 3      1271.646131\n",
       " 4      1240.738948\n",
       " ...            ...\n",
       " 2187  11818.433099\n",
       " 2188  12466.492268\n",
       " 2189  12466.492268\n",
       " 2190  12604.665557\n",
       " 2191  12604.665557\n",
       " \n",
       " [2192 rows x 1 columns],\n",
       " 'finance_44.csv':                  0\n",
       " 0      2861.064688\n",
       " 1      2795.138658\n",
       " 2      2930.008303\n",
       " 3      2823.856221\n",
       " 4      2981.553457\n",
       " ...            ...\n",
       " 1652  15674.684795\n",
       " 1653  15565.534066\n",
       " 1654  15448.239644\n",
       " 1655  15536.305154\n",
       " 1656  15685.479922\n",
       " \n",
       " [1657 rows x 1 columns],\n",
       " 'finance_78.csv':               0\n",
       " 0     24.268246\n",
       " 1     24.021774\n",
       " 2     24.310197\n",
       " 3     24.179114\n",
       " 4     24.336454\n",
       " ...         ...\n",
       " 5421  43.607446\n",
       " 5422  43.833096\n",
       " 5423  43.556163\n",
       " 5424  43.525392\n",
       " 5425  43.094604\n",
       " \n",
       " [5426 rows x 1 columns],\n",
       " 'finance_79.csv':                0\n",
       " 0    2545.321492\n",
       " 1    2521.464423\n",
       " 2    2530.028499\n",
       " 3    2539.714061\n",
       " 4    2523.503489\n",
       " ..           ...\n",
       " 255  3709.831892\n",
       " 256  3676.493168\n",
       " 257  3669.764252\n",
       " 258  3622.457928\n",
       " 259  3700.554143\n",
       " \n",
       " [260 rows x 1 columns],\n",
       " 'finance_45.csv':                0\n",
       " 0      33.307799\n",
       " 1      33.242052\n",
       " 2      33.361861\n",
       " 3      33.233806\n",
       " 4      33.753303\n",
       " ...          ...\n",
       " 1652  137.622427\n",
       " 1653  138.084801\n",
       " 1654  138.141263\n",
       " 1655  137.917677\n",
       " 1656  138.161248\n",
       " \n",
       " [1657 rows x 1 columns],\n",
       " 'finance_51.csv':                 0\n",
       " 0      337.153897\n",
       " 1      342.192319\n",
       " 2      338.569274\n",
       " 3      336.953891\n",
       " 4      335.707753\n",
       " ...           ...\n",
       " 8313  6682.634107\n",
       " 8314  6731.235924\n",
       " 8315  6748.466835\n",
       " 8316  6756.412976\n",
       " 8317  6795.817662\n",
       " \n",
       " [8318 rows x 1 columns],\n",
       " 'finance_86.csv':              0\n",
       " 0    23.853570\n",
       " 1    20.346301\n",
       " 2    23.152117\n",
       " 3    21.328336\n",
       " 4    23.011826\n",
       " ..         ...\n",
       " 278  20.065719\n",
       " 279  18.382230\n",
       " 280  18.803103\n",
       " 281  18.522521\n",
       " 282  17.961358\n",
       " \n",
       " [283 rows x 1 columns],\n",
       " 'finance_92.csv':                 0\n",
       " 0      121.197952\n",
       " 1      121.271358\n",
       " 2      121.239322\n",
       " 3      121.230412\n",
       " 4      121.365130\n",
       " ...           ...\n",
       " 11748   98.536742\n",
       " 11749   98.536742\n",
       " 11750   97.817113\n",
       " 11751   97.875455\n",
       " 11752   97.799080\n",
       " \n",
       " [11753 rows x 1 columns],\n",
       " 'finance_4.csv':                0\n",
       " 0    1531.868414\n",
       " 1    1092.176718\n",
       " 2     928.223882\n",
       " 3    1825.824257\n",
       " 4     795.736742\n",
       " 5    1671.807956\n",
       " 6    1648.622707\n",
       " 7    1483.013781\n",
       " 8    1811.747498\n",
       " 9    4394.418688\n",
       " 10   3508.410938\n",
       " 11   3014.896340\n",
       " 12   4059.888659\n",
       " 13   3582.934954\n",
       " 14   2996.679358\n",
       " 15   2710.175918\n",
       " 16   3063.750973\n",
       " 17   2462.590574\n",
       " 18   3726.186674\n",
       " 19   5696.932885\n",
       " 20   4874.684571\n",
       " 21   3241.780568\n",
       " 22   4589.837220\n",
       " 23   1890.411738\n",
       " 24   3452.103903\n",
       " 25  12395.813912\n",
       " 26   6079.489502\n",
       " 27   3351.082459,\n",
       " 'finance_100.csv':               0\n",
       " 0     88.563259\n",
       " 1     88.563259\n",
       " 2     88.563259\n",
       " 3     88.563259\n",
       " 4     88.701120\n",
       " ..          ...\n",
       " 382  185.479231\n",
       " 383  185.617092\n",
       " 384  185.203510\n",
       " 385  185.341371\n",
       " 386  184.858859\n",
       " \n",
       " [387 rows x 1 columns],\n",
       " 'finance_6.csv':               0\n",
       " 0   1832.966600\n",
       " 1   1967.740312\n",
       " 2   1909.143046\n",
       " 3   1827.106873\n",
       " 4   1920.862499\n",
       " 5   1979.459765\n",
       " 6   2090.794571\n",
       " 7   1915.002772\n",
       " 8   1967.740312\n",
       " 9   2149.391837\n",
       " 10  2541.993520\n",
       " 11  2583.011606\n",
       " 12  2793.961765\n",
       " 13  2893.577117\n",
       " 14  2858.418757\n",
       " 15  2858.418757\n",
       " 16  2735.364498\n",
       " 17  2747.083952\n",
       " 18  2776.382585\n",
       " 19  3157.264815\n",
       " 20  3461.970599\n",
       " 21  3977.626541\n",
       " 22  4381.947677\n",
       " 23  5149.571864\n",
       " 24  4921.042526\n",
       " 25  4686.653461\n",
       " 26  4768.689634\n",
       " 27  5272.626123\n",
       " 28  5512.874914\n",
       " 29  5196.449677\n",
       " 30  4774.549361\n",
       " 31  5073.395418\n",
       " 32  5635.929173\n",
       " 33  6737.557777\n",
       " 34  7757.150208\n",
       " 35  8026.697632\n",
       " 36  7089.141374\n",
       " 37  7669.254309\n",
       " 38  7007.105201\n",
       " 39  5782.422338\n",
       " 40  5653.508353\n",
       " 41  5887.897418,\n",
       " 'finance_84.csv':                0\n",
       " 0      15.781587\n",
       " 1      15.856278\n",
       " 2      15.855355\n",
       " 3      15.791730\n",
       " 4      15.718883\n",
       " ...          ...\n",
       " 3942  301.847711\n",
       " 3943  300.879499\n",
       " 3944  343.545386\n",
       " 3945  338.162129\n",
       " 3946  353.808431\n",
       " \n",
       " [3947 rows x 1 columns],\n",
       " 'finance_90.csv':                0\n",
       " 0      11.017738\n",
       " 1      11.037031\n",
       " 2      11.082049\n",
       " 3      11.056325\n",
       " 4      11.069186\n",
       " ...          ...\n",
       " 6440  110.971566\n",
       " 6441  111.432546\n",
       " 6442  111.745352\n",
       " 6443  110.955099\n",
       " 6444  105.867835\n",
       " \n",
       " [6445 rows x 1 columns],\n",
       " 'finance_47.csv':                 0\n",
       " 0     1809.740420\n",
       " 1     1803.407273\n",
       " 2     1798.261590\n",
       " 3     1798.261590\n",
       " 4     1788.563958\n",
       " ...           ...\n",
       " 1306  7260.799364\n",
       " 1307  7259.413988\n",
       " 1308  7294.048389\n",
       " 1309  7316.511272\n",
       " 1310  7312.355144\n",
       " \n",
       " [1311 rows x 1 columns],\n",
       " 'finance_53.csv':               0\n",
       " 0     11.107331\n",
       " 1     11.096405\n",
       " 2     11.080512\n",
       " 3     11.084485\n",
       " 4     11.090445\n",
       " ...         ...\n",
       " 9356  90.360697\n",
       " 9357  89.777746\n",
       " 9358  89.777746\n",
       " 9359  89.755494\n",
       " 9360  88.536186\n",
       " \n",
       " [9361 rows x 1 columns],\n",
       " 'finance_52.csv':               0\n",
       " 0     12.641907\n",
       " 1     12.814758\n",
       " 2     12.849328\n",
       " 3     12.901183\n",
       " 4     12.901183\n",
       " ...         ...\n",
       " 1298  13.782721\n",
       " 1299  13.834576\n",
       " 1300  13.921002\n",
       " 1301  13.955572\n",
       " 1302  13.990142\n",
       " \n",
       " [1303 rows x 1 columns],\n",
       " 'finance_46.csv':                0\n",
       " 0    4976.638953\n",
       " 1    4994.750580\n",
       " 2    4929.548725\n",
       " 3    4933.895516\n",
       " 4    4873.764917\n",
       " ..           ...\n",
       " 832  3011.165281\n",
       " 833  3012.614211\n",
       " 834  3066.949089\n",
       " 835  3032.899232\n",
       " 836  3088.683041\n",
       " \n",
       " [837 rows x 1 columns],\n",
       " 'finance_91.csv':               0\n",
       " 0     11.967239\n",
       " 1     11.830926\n",
       " 2     11.980870\n",
       " 3     11.885451\n",
       " 4     11.926345\n",
       " ...         ...\n",
       " 4827  13.837445\n",
       " 4828  14.066450\n",
       " 4829  14.120975\n",
       " 4830  14.063724\n",
       " 4831  14.028283\n",
       " \n",
       " [4832 rows x 1 columns],\n",
       " 'finance_85.csv':                 0\n",
       " 0       12.750099\n",
       " 1       12.768573\n",
       " 2       12.763955\n",
       " 3       12.727008\n",
       " 4       12.727008\n",
       " ...           ...\n",
       " 11511  130.978760\n",
       " 11512  131.946404\n",
       " 11513  132.115989\n",
       " 11514  131.487523\n",
       " 11515  131.487523\n",
       " \n",
       " [11516 rows x 1 columns],\n",
       " 'finance_7.csv':                0\n",
       " 0    7957.578091\n",
       " 1    8637.695802\n",
       " 2   10895.148653\n",
       " 3    8437.887209\n",
       " 4    9938.372891\n",
       " 5   13340.882679\n",
       " 6   13961.442058\n",
       " 7   10537.798670\n",
       " 8    8977.754657\n",
       " 9   14401.405210\n",
       " 10  12399.476809\n",
       " 11  10749.134681\n",
       " 12  19946.573969\n",
       " 13  20796.721107\n",
       " 14  15387.633526\n",
       " 15  10301.966893\n",
       " 16  12631.466112\n",
       " 17  11754.095054\n",
       " 18   9977.431629\n",
       " 19   8363.112685\n",
       " 20   8829.819449\n",
       " 21  14348.571207\n",
       " 22  16394.688046\n",
       " 23  17494.595925\n",
       " 24  17973.310416\n",
       " 25  13885.879828\n",
       " 26   9683.175051,\n",
       " 'finance_3.csv':               0\n",
       " 0    504.544622\n",
       " 1    500.321519\n",
       " 2    499.476898\n",
       " 3    533.261720\n",
       " 4    549.309510\n",
       " 5    591.540538\n",
       " 6    661.644043\n",
       " 7    713.165896\n",
       " 8    655.731699\n",
       " 9    643.907011\n",
       " 10   671.779489\n",
       " 11   750.329200\n",
       " 12   753.707682\n",
       " 13   755.396923\n",
       " 14   757.930784\n",
       " 15   802.695673\n",
       " 16   900.671656\n",
       " 17  1050.169492\n",
       " 18  1208.113534\n",
       " 19  1238.519873\n",
       " 20  1037.500184\n",
       " 21  1018.073912\n",
       " 22   951.348889\n",
       " 23   837.325115\n",
       " 24   769.755472\n",
       " 25   760.464646\n",
       " 26   839.858977\n",
       " 27   832.257392\n",
       " 28   775.667816\n",
       " 29   688.671900\n",
       " 30   608.432948,\n",
       " 'finance_81.csv':                  0\n",
       " 0    192174.135805\n",
       " 1    191263.378388\n",
       " 2    206564.102989\n",
       " 3    201281.709972\n",
       " 4    204924.739639\n",
       " ..             ...\n",
       " 113  589446.520976\n",
       " 114  533890.318556\n",
       " 115  641541.845212\n",
       " 116  686168.958631\n",
       " 117  633891.482912\n",
       " \n",
       " [118 rows x 1 columns],\n",
       " 'finance_95.csv':               0\n",
       " 0      5.405689\n",
       " 1      5.405689\n",
       " 2      5.406105\n",
       " 3      5.406105\n",
       " 4      5.405273\n",
       " ...         ...\n",
       " 9545  11.050838\n",
       " 9546  11.097744\n",
       " 9547  11.134670\n",
       " 9548  11.114710\n",
       " 9549  11.067804\n",
       " \n",
       " [9550 rows x 1 columns],\n",
       " 'finance_42.csv':                0\n",
       " 0    1776.397442\n",
       " 1    1854.133031\n",
       " 2    1860.389920\n",
       " 3    1859.468906\n",
       " 4    1834.281174\n",
       " ..           ...\n",
       " 387  1087.198613\n",
       " 388  1096.679051\n",
       " 389  1095.818103\n",
       " 390  1092.244168\n",
       " 391  1085.406640\n",
       " \n",
       " [392 rows x 1 columns],\n",
       " 'finance_56.csv':               0\n",
       " 0     14.325701\n",
       " 1     14.383755\n",
       " 2     14.354728\n",
       " 3     14.216832\n",
       " 4     14.238602\n",
       " ...         ...\n",
       " 5005  27.397652\n",
       " 5006  27.448757\n",
       " 5007  27.414688\n",
       " 5008  27.131910\n",
       " 5009  26.917272\n",
       " \n",
       " [5010 rows x 1 columns],\n",
       " 'finance_57.csv':                0\n",
       " 0      47.754915\n",
       " 1      47.719082\n",
       " 2      47.667115\n",
       " 3      47.995020\n",
       " 4      47.745957\n",
       " ...          ...\n",
       " 5447  182.661072\n",
       " 5448  184.882926\n",
       " 5449  189.022040\n",
       " 5450  186.692668\n",
       " 5451  183.341959\n",
       " \n",
       " [5452 rows x 1 columns],\n",
       " 'finance_43.csv':                0\n",
       " 0    2047.954173\n",
       " 1    2070.955902\n",
       " 2    2056.647409\n",
       " 3    2040.542950\n",
       " 4    2030.183670\n",
       " ..           ...\n",
       " 652  3360.223954\n",
       " 653  3373.867558\n",
       " 654  3352.753502\n",
       " 655  3356.935809\n",
       " 656  3363.468155\n",
       " \n",
       " [657 rows x 1 columns],\n",
       " 'finance_94.csv':               0\n",
       " 0     42.336075\n",
       " 1     43.069142\n",
       " 2     38.273304\n",
       " 3     41.064252\n",
       " 4     38.741405\n",
       " ...         ...\n",
       " 1056  23.806302\n",
       " 1057  22.967250\n",
       " 1058  22.384331\n",
       " 1059  22.675791\n",
       " 1060  22.375499\n",
       " \n",
       " [1061 rows x 1 columns],\n",
       " 'finance_80.csv':                 0\n",
       " 0        3.171382\n",
       " 1        3.187140\n",
       " 2        3.196592\n",
       " 3        3.199744\n",
       " 4        3.196592\n",
       " ...           ...\n",
       " 12122  270.622180\n",
       " 12123  272.123019\n",
       " 12124  271.510438\n",
       " 12125  274.159884\n",
       " 12126  272.781543\n",
       " \n",
       " [12127 rows x 1 columns],\n",
       " 'finance_2.csv':                0\n",
       " 0    1425.979514\n",
       " 1     858.914825\n",
       " 2     758.103325\n",
       " 3     909.320576\n",
       " 4    4154.190737\n",
       " 5   10051.663495\n",
       " 6    2793.235485\n",
       " 7    1564.595327\n",
       " 8    5300.921551\n",
       " 9    4349.513018\n",
       " 10   4488.128831\n",
       " 11   3524.118861\n",
       " 12   5943.594864\n",
       " 13    480.871700\n",
       " 14    852.614107\n",
       " 15   1652.805389\n",
       " 16   2106.457140\n",
       " 17   1678.008264\n",
       " 18   2812.137641\n",
       " 19   3366.600892\n",
       " 20   1451.182389\n",
       " 21   4714.954706\n",
       " 22   7065.122804\n",
       " 23   2106.457140\n",
       " 24    808.509075\n",
       " 25   6630.373209\n",
       " 26   8192.951461\n",
       " 27   4595.241050\n",
       " 28    833.711950\n",
       " 29    348.556606\n",
       " 30   3599.727486\n",
       " 31   5483.642395\n",
       " 32   9295.577244\n",
       " 33  10662.833215\n",
       " 34   4021.875643\n",
       " 35   4009.274205\n",
       " 36   4891.374832\n",
       " 37  20088.708479\n",
       " 38   8318.965837\n",
       " 39   5225.312926\n",
       " 40   4910.276988\n",
       " 41  10826.651903\n",
       " 42   1684.308983\n",
       " 43   2068.652827\n",
       " 44   1224.356514\n",
       " 45    795.907638\n",
       " 46    531.277450,\n",
       " 'finance_96.csv':              0\n",
       " 0     6.167020\n",
       " 1     6.163822\n",
       " 2     6.156197\n",
       " 3     6.158411\n",
       " 4     6.151155\n",
       " ...        ...\n",
       " 4964  6.186574\n",
       " 4965  6.186574\n",
       " 4966  6.193584\n",
       " 4967  6.192662\n",
       " 4968  6.193215\n",
       " \n",
       " [4969 rows x 1 columns],\n",
       " 'finance_82.csv':               0\n",
       " 0     39.861292\n",
       " 1     47.231730\n",
       " 2     46.448046\n",
       " 3     45.481565\n",
       " 4     45.594303\n",
       " ..          ...\n",
       " 546  169.472878\n",
       " 547  170.997085\n",
       " 548  185.727655\n",
       " 549  173.293704\n",
       " 550  169.239995\n",
       " \n",
       " [551 rows x 1 columns],\n",
       " 'finance_69.csv':                0\n",
       " 0     597.936775\n",
       " 1     599.286592\n",
       " 2     601.356312\n",
       " 3     604.325910\n",
       " 4     600.906373\n",
       " ...          ...\n",
       " 1298  480.232702\n",
       " 1299  482.410407\n",
       " 1300  481.816487\n",
       " 1301  482.878344\n",
       " 1302  487.701691\n",
       " \n",
       " [1303 rows x 1 columns],\n",
       " 'finance_55.csv':                 0\n",
       " 0       17.414852\n",
       " 1       17.062738\n",
       " 2       16.906243\n",
       " 3       16.882769\n",
       " 4       16.812346\n",
       " ...           ...\n",
       " 5204  1001.128078\n",
       " 5205   989.988156\n",
       " 5206  1020.726260\n",
       " 5207  1048.316976\n",
       " 5208  1043.193990\n",
       " \n",
       " [5209 rows x 1 columns],\n",
       " 'finance_41.csv':                 0\n",
       " 0     7470.461080\n",
       " 1     7428.008133\n",
       " 2     7462.395417\n",
       " 3     7343.814422\n",
       " 4     7358.481670\n",
       " ..            ...\n",
       " 387  13209.240375\n",
       " 388  13241.366679\n",
       " 389  13340.784941\n",
       " 390  13264.854132\n",
       " 391  13364.369029\n",
       " \n",
       " [392 rows x 1 columns],\n",
       " 'finance_40.csv':                 0\n",
       " 0     1743.423704\n",
       " 1     2104.312594\n",
       " 2     1855.591872\n",
       " 3     1844.212493\n",
       " 4     1853.966247\n",
       " ..            ...\n",
       " 129  15444.196529\n",
       " 130  13446.302628\n",
       " 131  13602.362688\n",
       " 132  14060.789117\n",
       " 133  15923.756091\n",
       " \n",
       " [134 rows x 1 columns],\n",
       " 'finance_54.csv':                0\n",
       " 0    6737.897243\n",
       " 1    6743.727332\n",
       " 2    6740.202162\n",
       " 3    6740.337745\n",
       " 4    6742.913831\n",
       " ..           ...\n",
       " 330  8490.177942\n",
       " 331  8494.381029\n",
       " 332  8504.007455\n",
       " 333  8500.753452\n",
       " 334  8501.702537\n",
       " \n",
       " [335 rows x 1 columns],\n",
       " 'finance_68.csv':               0\n",
       " 0     10.632142\n",
       " 1     10.632142\n",
       " 2     10.632142\n",
       " 3     10.632142\n",
       " 4     10.632142\n",
       " ...         ...\n",
       " 1917  35.931584\n",
       " 1918  36.172919\n",
       " 1919  36.462524\n",
       " 1920  36.498723\n",
       " 1921  37.198596\n",
       " \n",
       " [1922 rows x 1 columns],\n",
       " 'finance_83.csv':                0\n",
       " 0      19.625157\n",
       " 1      20.435136\n",
       " 2      21.093244\n",
       " 3      20.890750\n",
       " 4      20.435136\n",
       " ...          ...\n",
       " 4339  108.034387\n",
       " 4340  109.127857\n",
       " 4341  109.022562\n",
       " 4342  109.808237\n",
       " 4343  110.666819\n",
       " \n",
       " [4344 rows x 1 columns],\n",
       " 'finance_97.csv':              0\n",
       " 0    17.493556\n",
       " 1    16.158791\n",
       " 2    16.659328\n",
       " 3    18.828322\n",
       " 4    21.497852\n",
       " ..         ...\n",
       " 277   7.649661\n",
       " 278   7.983352\n",
       " 279   6.815433\n",
       " 280   6.982278\n",
       " 281   6.648587\n",
       " \n",
       " [282 rows x 1 columns],\n",
       " 'finance_1.csv':               0\n",
       " 0     87.764439\n",
       " 1     91.764396\n",
       " 2     97.097672\n",
       " 3    103.836339\n",
       " 4    113.313714\n",
       " 5    119.511846\n",
       " 6    124.520801\n",
       " 7    133.421606\n",
       " 8    157.277206\n",
       " 9    179.835522\n",
       " 10   192.159713\n",
       " 11   199.835307\n",
       " 12   229.744895\n",
       " 13   251.762676\n",
       " 14   274.465135\n",
       " 15   295.041490\n",
       " 16   311.221496\n",
       " 17   351.617458\n",
       " 18   381.491011\n",
       " 19   413.238418\n",
       " 20   437.850766\n",
       " 21   494.570876\n",
       " 22   562.534110\n",
       " 23   578.389795\n",
       " 24   649.668308\n",
       " 25   709.451449\n",
       " 26   774.603902\n",
       " 27   802.351351\n",
       " 28   829.053767\n",
       " 29   901.917848\n",
       " 30  1012.655396\n",
       " 31  1101.303092\n",
       " 32  1233.770136\n",
       " 33  1399.137728\n",
       " 34  1443.029148\n",
       " 35  1644.900851\n",
       " 36  1788.106519\n",
       " 37  1908.285407\n",
       " 38  2167.489827\n",
       " 39  2606.476099\n",
       " 40  2761.105067\n",
       " 41  3002.688055\n",
       " 42  3288.630927\n",
       " 43  3608.987843\n",
       " 44  4193.377956\n",
       " 45  4739.858567,\n",
       " 'finance_71.csv':               0\n",
       " 0     92.682867\n",
       " 1     94.931156\n",
       " 2    117.976120\n",
       " 3    136.524505\n",
       " 4    137.889538\n",
       " ..          ...\n",
       " 702  105.610530\n",
       " 703   97.821814\n",
       " 704   99.267143\n",
       " 705  103.442537\n",
       " 706   94.208492\n",
       " \n",
       " [707 rows x 1 columns],\n",
       " 'finance_65.csv':                0\n",
       " 0      38.822918\n",
       " 1      39.327415\n",
       " 2      39.201289\n",
       " 3      40.147218\n",
       " 4      40.399467\n",
       " ...          ...\n",
       " 5334  174.946240\n",
       " 5335  173.871961\n",
       " 5336  173.871961\n",
       " 5337  174.930890\n",
       " 5338  174.378405\n",
       " \n",
       " [5339 rows x 1 columns],\n",
       " 'finance_59.csv':             0\n",
       " 0    4.677534\n",
       " 1    4.654995\n",
       " 2    4.632456\n",
       " 3    4.609916\n",
       " 4    4.598647\n",
       " ..        ...\n",
       " 448  3.539309\n",
       " 449  3.550579\n",
       " 450  3.550579\n",
       " 451  3.550579\n",
       " 452  3.550579\n",
       " \n",
       " [453 rows x 1 columns],\n",
       " 'finance_58.csv':                0\n",
       " 0      10.298265\n",
       " 1      10.297629\n",
       " 2      10.297992\n",
       " 3      10.301809\n",
       " 4      10.302354\n",
       " ...          ...\n",
       " 12269  10.517091\n",
       " 12270  10.517091\n",
       " 12271  10.508458\n",
       " 12272  10.510366\n",
       " 12273  10.510275\n",
       " \n",
       " [12274 rows x 1 columns],\n",
       " 'finance_64.csv':              0\n",
       " 0    26.817482\n",
       " 1    26.868331\n",
       " 2    26.754428\n",
       " 3    27.173432\n",
       " 4    27.397171\n",
       " ..         ...\n",
       " 815  35.258560\n",
       " 816  35.441621\n",
       " 817  35.543318\n",
       " 818  35.838249\n",
       " 819  35.685701\n",
       " \n",
       " [820 rows x 1 columns],\n",
       " 'finance_70.csv':                 0\n",
       " 0       39.592101\n",
       " 1       39.342762\n",
       " 2       39.405096\n",
       " 3       38.781749\n",
       " 4       39.093423\n",
       " ...           ...\n",
       " 12993  844.801602\n",
       " 12994  848.572856\n",
       " 12995  847.544332\n",
       " 12996  849.383208\n",
       " 12997  857.736069\n",
       " \n",
       " [12998 rows x 1 columns],\n",
       " 'finance_99.csv':                 0\n",
       " 0        7.690361\n",
       " 1        7.692155\n",
       " 2        7.691258\n",
       " 3        7.690361\n",
       " 4        7.689463\n",
       " ...           ...\n",
       " 11451  199.590410\n",
       " 11452  201.042022\n",
       " 11453  202.989745\n",
       " 11454  202.071005\n",
       " 11455  204.184111\n",
       " \n",
       " [11456 rows x 1 columns],\n",
       " 'finance_66.csv':              0\n",
       " 0    10.438459\n",
       " 1    11.125112\n",
       " 2    10.863529\n",
       " 3    10.520203\n",
       " 4    10.487505\n",
       " ..         ...\n",
       " 756  11.010669\n",
       " 757  11.027018\n",
       " 758  11.010669\n",
       " 759  11.010669\n",
       " 760  11.027018\n",
       " \n",
       " [761 rows x 1 columns],\n",
       " 'finance_72.csv':                 0\n",
       " 0       23.925391\n",
       " 1       23.805100\n",
       " 2       23.897632\n",
       " 3       23.777340\n",
       " 4       23.573767\n",
       " ...           ...\n",
       " 14109  241.488538\n",
       " 14110  237.393945\n",
       " 14111  239.212231\n",
       " 14112  244.667031\n",
       " 14113  243.501123\n",
       " \n",
       " [14114 rows x 1 columns],\n",
       " 'finance_73.csv':              0\n",
       " 0     4.301017\n",
       " 1     4.294630\n",
       " 2     4.297823\n",
       " 3     4.294630\n",
       " 4     4.323371\n",
       " ...        ...\n",
       " 3924  4.428756\n",
       " 3925  4.431950\n",
       " 3926  4.435143\n",
       " 3927  4.435143\n",
       " 3928  4.435143\n",
       " \n",
       " [3929 rows x 1 columns],\n",
       " 'finance_67.csv':                0\n",
       " 0      33.086299\n",
       " 1      29.691666\n",
       " 2      27.280986\n",
       " 3      26.518424\n",
       " 4      27.490076\n",
       " ...          ...\n",
       " 1426  118.444106\n",
       " 1427  118.413356\n",
       " 1428  121.641947\n",
       " 1429  124.003428\n",
       " 1430  122.810386\n",
       " \n",
       " [1431 rows x 1 columns],\n",
       " 'finance_98.csv':               0\n",
       " 0     17.205042\n",
       " 1     17.269918\n",
       " 2     16.831233\n",
       " 3     15.515179\n",
       " 4     15.323641\n",
       " ...         ...\n",
       " 1666  26.825209\n",
       " 1667  26.902442\n",
       " 1668  27.118695\n",
       " 1669  27.739650\n",
       " 1670  28.196870\n",
       " \n",
       " [1671 rows x 1 columns],\n",
       " 'finance_88.csv':                0\n",
       " 0      35.375649\n",
       " 1      35.211674\n",
       " 2      35.211674\n",
       " 3      35.211674\n",
       " 4      35.047698\n",
       " ...          ...\n",
       " 1254  332.827155\n",
       " 1255  333.319082\n",
       " 1256  334.466910\n",
       " 1257  334.958837\n",
       " 1258  336.598591\n",
       " \n",
       " [1259 rows x 1 columns],\n",
       " 'finance_63.csv':                0\n",
       " 0      92.244120\n",
       " 1      91.758715\n",
       " 2      93.214726\n",
       " 3      93.214726\n",
       " 4      94.175462\n",
       " ...          ...\n",
       " 5454  147.038952\n",
       " 5455  148.007081\n",
       " 5456  150.133198\n",
       " 5457  150.133198\n",
       " 5458  148.500646\n",
       " \n",
       " [5459 rows x 1 columns],\n",
       " 'finance_77.csv':                0\n",
       " 0      12.067660\n",
       " 1      12.063401\n",
       " 2      12.061982\n",
       " 3      12.063401\n",
       " 4      12.054884\n",
       " ...          ...\n",
       " 14110  63.171297\n",
       " 14111  63.247609\n",
       " 14112  63.596462\n",
       " 14113  63.781792\n",
       " 14114  63.869003\n",
       " \n",
       " [14115 rows x 1 columns],\n",
       " 'finance_76.csv':                0\n",
       " 0      13.532622\n",
       " 1      13.556562\n",
       " 2      13.700203\n",
       " 3      13.700203\n",
       " 4      13.628383\n",
       " ...          ...\n",
       " 9545  113.022969\n",
       " 9546  113.053619\n",
       " 9547  113.160870\n",
       " 9548  113.666489\n",
       " 9549  114.309996\n",
       " \n",
       " [9550 rows x 1 columns],\n",
       " 'finance_62.csv':               0\n",
       " 0     21.020884\n",
       " 1     21.083967\n",
       " 2     21.159953\n",
       " 3     21.062461\n",
       " 4     21.065329\n",
       " ...         ...\n",
       " 8357  26.563541\n",
       " 8358  26.506193\n",
       " 8359  26.520530\n",
       " 8360  26.526265\n",
       " 8361  26.443111\n",
       " \n",
       " [8362 rows x 1 columns],\n",
       " 'finance_89.csv':               0\n",
       " 0     45.950354\n",
       " 1     45.380874\n",
       " 2     44.975911\n",
       " 3     45.254323\n",
       " 4     45.153082\n",
       " ...         ...\n",
       " 3204  49.253327\n",
       " 3205  49.310276\n",
       " 3206  49.746877\n",
       " 3207  49.778514\n",
       " 3208  49.576034\n",
       " \n",
       " [3209 rows x 1 columns],\n",
       " 'finance_9.csv':              0\n",
       " 0   135.265407\n",
       " 1   132.267911\n",
       " 2   126.565938\n",
       " 3   112.167402\n",
       " 4   115.537344\n",
       " 5   104.940770\n",
       " 6    99.630616\n",
       " 7    94.935073\n",
       " 8    89.900986\n",
       " 9    95.889196\n",
       " 10  100.138675\n",
       " 11   99.742012\n",
       " 12  108.660880\n",
       " 13  115.269512\n",
       " 14  102.517685\n",
       " 15   91.810200\n",
       " 16   87.887157\n",
       " 17   92.482445\n",
       " 18   85.789540\n",
       " 19   84.156876\n",
       " 20   84.642171\n",
       " 21   86.201218\n",
       " 22   91.370432\n",
       " 23   89.035495,\n",
       " 'finance_48.csv':                0\n",
       " 0    7851.321687\n",
       " 1    7851.321687\n",
       " 2    7879.052297\n",
       " 3    7879.352943\n",
       " 4    7879.656753\n",
       " ..           ...\n",
       " 465  7889.734714\n",
       " 466  7892.296531\n",
       " 467  7139.266070\n",
       " 468  7886.924467\n",
       " 469  7139.266070\n",
       " \n",
       " [470 rows x 1 columns],\n",
       " 'finance_74.csv':                 0\n",
       " 0      518.663076\n",
       " 1      518.778361\n",
       " 2      518.850413\n",
       " 3      518.864824\n",
       " 4      518.792771\n",
       " ...           ...\n",
       " 12269  163.443795\n",
       " 12270  163.443795\n",
       " 12271  162.737680\n",
       " 12272  162.838553\n",
       " 12273  162.939427\n",
       " \n",
       " [12274 rows x 1 columns],\n",
       " 'finance_60.csv':              0\n",
       " 0    17.473096\n",
       " 1    18.738883\n",
       " 2    18.377229\n",
       " 3    17.473096\n",
       " 4    16.388136\n",
       " ..         ...\n",
       " 834  18.558056\n",
       " 835  18.377229\n",
       " 836  17.653923\n",
       " 837  17.292270\n",
       " 838  17.292270\n",
       " \n",
       " [839 rows x 1 columns],\n",
       " 'finance_61.csv':                0\n",
       " 0      16.037937\n",
       " 1      16.214932\n",
       " 2      16.407651\n",
       " 3      16.609200\n",
       " 4      16.804320\n",
       " ..           ...\n",
       " 846  1640.452615\n",
       " 847  1644.554475\n",
       " 848  1653.457420\n",
       " 849  1655.043168\n",
       " 850  1652.226901\n",
       " \n",
       " [851 rows x 1 columns],\n",
       " 'finance_75.csv':               0\n",
       " 0    330.213104\n",
       " 1    486.830551\n",
       " 2    376.090942\n",
       " 3    339.705070\n",
       " 4    376.090942\n",
       " ..          ...\n",
       " 198  455.190662\n",
       " 199  464.682629\n",
       " 200  407.730830\n",
       " 201  515.306450\n",
       " 202  440.952713\n",
       " \n",
       " [203 rows x 1 columns],\n",
       " 'finance_49.csv':              0\n",
       " 0    65.017487\n",
       " 1    64.799034\n",
       " 2    64.580581\n",
       " 3    64.362129\n",
       " 4    64.143676\n",
       " ..         ...\n",
       " 440  64.580581\n",
       " 441  64.362129\n",
       " 442  64.143676\n",
       " 443  63.925223\n",
       " 444  63.706771\n",
       " \n",
       " [445 rows x 1 columns],\n",
       " 'finance_8.csv':              0\n",
       " 0   466.742240\n",
       " 1   440.854946\n",
       " 2   473.172039\n",
       " 3   470.158858\n",
       " 4   520.735738\n",
       " 5   525.904792\n",
       " 6   515.936503\n",
       " 7   508.649398\n",
       " 8   574.569542\n",
       " 9   665.229703\n",
       " 10  662.565328\n",
       " 11  656.244794\n",
       " 12  595.985394\n",
       " 13  585.823791\n",
       " 14  563.407748\n",
       " 15  560.226469\n",
       " 16  660.997802\n",
       " 17  725.535330\n",
       " 18  790.825102\n",
       " 19  690.406777\n",
       " 20  655.320248\n",
       " 21  709.607920\n",
       " 22  710.574491\n",
       " 23  750.393015\n",
       " 24  780.159201\n",
       " 25  876.517928,\n",
       " 'finance_12.csv':               0\n",
       " 0   2103.367106\n",
       " 1   2061.346883\n",
       " 2   1989.134648\n",
       " 3   1918.686620\n",
       " 4   1863.073977\n",
       " 5   1753.131751\n",
       " 6   1675.506606\n",
       " 7   1589.421282\n",
       " 8   1516.126465\n",
       " 9   1457.266075\n",
       " 10  1422.543257\n",
       " 11  1391.348855\n",
       " 12  1360.074261\n",
       " 13  1339.304723\n",
       " 14  1338.903767\n",
       " 15  1304.581905\n",
       " 16  1259.233744\n",
       " 17  1242.112908\n",
       " 18  1236.098563\n",
       " 19  1226.916663\n",
       " 20  1214.005870\n",
       " 21  1200.854502\n",
       " 22  1194.639679\n",
       " 23  1193.677384\n",
       " 24  1179.884486\n",
       " 25  1183.092137\n",
       " 26  1187.221987\n",
       " 27  1167.655318\n",
       " 28  1168.016179\n",
       " 29  1167.976083\n",
       " 30  1169.579908\n",
       " 31  1163.525468\n",
       " 32  1158.393227\n",
       " 33  1160.638582\n",
       " 34  1169.379430,\n",
       " 'finance_13.csv':               0\n",
       " 0   8455.974784\n",
       " 1   8507.531544\n",
       " 2   8212.228719\n",
       " 3   7183.645846\n",
       " 4   6588.446029\n",
       " 5   3465.688845\n",
       " 6   3303.616854\n",
       " 7   2953.439260\n",
       " 8   2662.475371\n",
       " 9   2720.157686\n",
       " 10  2686.977593\n",
       " 11  2535.880556\n",
       " 12  2421.536852\n",
       " 13  2586.926852\n",
       " 14  2506.273704\n",
       " 15  2364.620231\n",
       " 16  2372.277176\n",
       " 17  2549.407824\n",
       " 18  2615.768010\n",
       " 19  2559.617083\n",
       " 20  2478.198241\n",
       " 21  2692.847917\n",
       " 22  2803.873612\n",
       " 23  2726.283241\n",
       " 24  2675.492176\n",
       " 25  2858.237918\n",
       " 26  2909.028983\n",
       " 27  2866.660556\n",
       " 28  2720.412917\n",
       " 29  2911.326066\n",
       " 30  2938.635834\n",
       " 31  2837.308936\n",
       " 32  2660.433519\n",
       " 33  2831.949075\n",
       " 34  2918.217316,\n",
       " 'finance_11.csv':                0\n",
       " 0    7421.997232\n",
       " 1    6933.706249\n",
       " 2    6601.826435\n",
       " 3    7511.837309\n",
       " 4    7581.693050\n",
       " 5    8705.238747\n",
       " 6    8662.944803\n",
       " 7    9216.945061\n",
       " 8    9698.634221\n",
       " 9    8792.932418\n",
       " 10   8400.676820\n",
       " 11   9156.504235\n",
       " 12   9447.277132\n",
       " 13   9637.656793\n",
       " 14  13126.167315\n",
       " 15  14969.701959\n",
       " 16  15974.675014\n",
       " 17  12799.409604\n",
       " 18  13489.104966\n",
       " 19  14967.994591\n",
       " 20  15316.899303\n",
       " 21  16245.105842\n",
       " 22  16503.536312\n",
       " 23  15289.841586,\n",
       " 'finance_39.csv':                 0\n",
       " 0     1589.284598\n",
       " 1     2288.378240\n",
       " 2     1682.497084\n",
       " 3     1775.709569\n",
       " 4     1799.012691\n",
       " ..            ...\n",
       " 129  20523.070753\n",
       " 130  17039.254100\n",
       " 131  17400.452482\n",
       " 132  17272.285315\n",
       " 133  20907.572256\n",
       " \n",
       " [134 rows x 1 columns],\n",
       " 'finance_38.csv':               0\n",
       " 0   1126.989102\n",
       " 1   1366.077249\n",
       " 2   1556.261002\n",
       " 3   1333.474320\n",
       " 4   1262.834640\n",
       " ..          ...\n",
       " 77  4275.345292\n",
       " 78  5367.543418\n",
       " 79  5086.614845\n",
       " 80  4456.834931\n",
       " 81  4829.051705\n",
       " \n",
       " [82 rows x 1 columns],\n",
       " 'finance_10.csv':                0\n",
       " 0    5874.705975\n",
       " 1    5988.435067\n",
       " 2    6274.731244\n",
       " 3    6629.732656\n",
       " 4    8156.874620\n",
       " 5    8401.903801\n",
       " 6    7645.166798\n",
       " 7    7164.083969\n",
       " 8    7135.578606\n",
       " 9    9103.954361\n",
       " 10  10321.118768\n",
       " 11  11784.627988\n",
       " 12  13507.755290\n",
       " 13  13844.864105\n",
       " 14  10884.881769\n",
       " 15   9858.527880\n",
       " 16   9618.059557\n",
       " 17  10335.459158\n",
       " 18   8859.685322\n",
       " 19   9103.954361\n",
       " 20   8613.121236\n",
       " 21   9921.853642\n",
       " 22   9795.830699,\n",
       " 'finance_28.csv':                 0\n",
       " 0      290.119563\n",
       " 1      290.603970\n",
       " 2      288.804747\n",
       " 3      289.946561\n",
       " 4      291.918787\n",
       " ...           ...\n",
       " 3707  7713.506238\n",
       " 3708  7650.810235\n",
       " 3709  7602.750219\n",
       " 3710  7525.695033\n",
       " 3711  7541.888040\n",
       " \n",
       " [3712 rows x 1 columns],\n",
       " 'finance_14.csv':                0\n",
       " 0    9123.917377\n",
       " 1    8303.690189\n",
       " 2    7714.120828\n",
       " 3    8064.084428\n",
       " 4    8738.162045\n",
       " 5    8021.333193\n",
       " 6    7430.769618\n",
       " 7    7366.145657\n",
       " 8    7590.838196\n",
       " 9    7593.820841\n",
       " 10   7957.703448\n",
       " 11   8186.372846\n",
       " 12   9721.440456\n",
       " 13   9886.480108\n",
       " 14   9686.642939\n",
       " 15   9941.161921\n",
       " 16  10356.743696\n",
       " 17   9739.336322\n",
       " 18   9827.821436\n",
       " 19  10390.546998\n",
       " 20  11514.009692\n",
       " 21  11015.908091\n",
       " 22  10640.094906\n",
       " 23  11027.838668\n",
       " 24  11247.560133\n",
       " 25  10683.840356\n",
       " 26  10565.528798\n",
       " 27  11409.617141\n",
       " 28  12606.651728\n",
       " 29  12008.134435\n",
       " 30  11986.261710\n",
       " 31  12570.859996\n",
       " 32  13324.474795\n",
       " 33  12966.557476\n",
       " 34  12965.563261,\n",
       " 'finance_15.csv':              0\n",
       " 0   309.609658\n",
       " 1   323.395626\n",
       " 2   340.470294\n",
       " 3   354.023728\n",
       " 4   379.801827\n",
       " 5   374.752508\n",
       " 6   373.722713\n",
       " 7   431.424463\n",
       " 8   414.250136\n",
       " 9   377.476483\n",
       " 10  365.251817\n",
       " 11  387.973750\n",
       " 12  363.966234\n",
       " 13  350.236739\n",
       " 14  365.584009\n",
       " 15  396.079234\n",
       " 16  399.367935\n",
       " 17  408.636092\n",
       " 18  435.443986\n",
       " 19  451.322763\n",
       " 20  397.142249\n",
       " 21  375.051481\n",
       " 22  407.573077\n",
       " 23  443.881662\n",
       " 24  411.625820\n",
       " 25  444.346731\n",
       " 26  462.849825\n",
       " 27  400.696703\n",
       " 28  397.507660\n",
       " 29  384.136932\n",
       " 30  389.116490\n",
       " 31  370.490485\n",
       " 32  382.007581\n",
       " 33  398.454407\n",
       " 34  410.695682\n",
       " 35  407.054858\n",
       " 36  443.386696\n",
       " 37  444.565978\n",
       " 38  436.430596,\n",
       " 'finance_29.csv':                 0\n",
       " 0     9742.674644\n",
       " 1     9907.194277\n",
       " 2    10032.178185\n",
       " 3    10061.511143\n",
       " 4    10037.279569\n",
       " ..            ...\n",
       " 247  13496.017904\n",
       " 248  13603.146967\n",
       " 249  13567.437280\n",
       " 250  13734.507605\n",
       " 251  13737.058297\n",
       " \n",
       " [252 rows x 1 columns],\n",
       " 'finance_17.csv':               0\n",
       " 0   2849.147411\n",
       " 1   2973.340795\n",
       " 2   3201.788258\n",
       " 3   3324.520252\n",
       " 4   3627.779326\n",
       " 5   3695.713322\n",
       " 6   3627.680249\n",
       " 7   3918.265686\n",
       " 8   3980.857764\n",
       " 9   3908.679958\n",
       " 10  3575.623389\n",
       " 11  3758.866838\n",
       " 12  3608.252843\n",
       " 13  3452.899651\n",
       " 14  3468.826326\n",
       " 15  3683.766252\n",
       " 16  3945.090862\n",
       " 17  3975.169076\n",
       " 18  4187.285299\n",
       " 19  4443.878969\n",
       " 20  4363.593338\n",
       " 21  3847.227268\n",
       " 22  3827.345759\n",
       " 23  4099.445025\n",
       " 24  4121.275054\n",
       " 25  4133.172586\n",
       " 26  4559.568219\n",
       " 27  4309.051289\n",
       " 28  4079.613054\n",
       " 29  4122.472238\n",
       " 30  3977.968010\n",
       " 31  3965.393450\n",
       " 32  3869.197657\n",
       " 33  4014.833018\n",
       " 34  4269.461655\n",
       " 35  4322.781751\n",
       " 36  4511.317578\n",
       " 37  4776.423639\n",
       " 38  4658.777613,\n",
       " 'finance_16.csv':               0\n",
       " 0   2174.560252\n",
       " 1   2289.969935\n",
       " 2   2484.128006\n",
       " 3   2736.266141\n",
       " 4   3015.576969\n",
       " 5   3148.198937\n",
       " 6   3386.121646\n",
       " 7   3513.265389\n",
       " 8   3839.337714\n",
       " 9   3910.904124\n",
       " 10  3837.721332\n",
       " 11  4138.368404\n",
       " 12  4213.831606\n",
       " 13  4136.402534\n",
       " 14  3781.838197\n",
       " 15  3977.455381\n",
       " 16  3816.332665\n",
       " 17  3650.518072\n",
       " 18  3666.306194\n",
       " 19  3891.883239\n",
       " 20  4169.001030\n",
       " 21  4203.329491\n",
       " 22  4427.840597\n",
       " 23  4700.546101\n",
       " 24  4615.672935\n",
       " 25  4068.182472\n",
       " 26  4045.675443\n",
       " 27  4335.497124\n",
       " 28  4354.142310\n",
       " 29  4369.301353\n",
       " 30  4820.726296\n",
       " 31  4558.557855\n",
       " 32  4314.370573\n",
       " 33  4359.201149\n",
       " 34  4204.841026\n",
       " 35  4188.607308\n",
       " 36  4092.768954\n",
       " 37  4246.613582\n",
       " 38  4513.535060\n",
       " 39  4562.847820\n",
       " 40  4771.911556\n",
       " 41  5054.193032\n",
       " 42  4929.128743}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a01c4cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = pd.read_csv(data_loc + 'freq.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "da7b910e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,    4,   12,    7,  360,  672,  120,   60, 1440, 2016,  288,\n",
       "         96, 1320, 1800,   48,  180,  336, 4368,   84, 2880,   28,  730,\n",
       "         30,  365,  245,  480,  240,  720])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies[[col for col in frequencies.columns if usecase in col][0]].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eaa75535",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_frequencies_economics = {\n",
    "    1 : 'D',\n",
    "    4: 'Q',\n",
    "    12: 'M',\n",
    "    52: 'W',\n",
    "    24: 'H',\n",
    "    7: 'W',\n",
    "    91: 'D',\n",
    "    364: 'D', \n",
    "    360: 'D',\n",
    "    168: 'D',\n",
    "    672: 'D',\n",
    "    96: 'H', \n",
    "    288: 'D',\n",
    "    28: 'D',\n",
    "    6: 'D',\n",
    "    30: 'D',\n",
    "    720: 'D'\n",
    "    \n",
    "}\n",
    "\n",
    "def mapping(x):\n",
    "    try:\n",
    "        return mapping_frequencies_economics[x]\n",
    "    except:\n",
    "        return 'D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f080b7e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M\n",
      "               y         ds\n",
      "0    2854.123802 2000-01-31\n",
      "1    2862.026398 2000-02-29\n",
      "2    2862.026398 2000-03-31\n",
      "3    2877.831590 2000-04-30\n",
      "4    2885.734186 2000-05-31\n",
      "..           ...        ...\n",
      "319  1676.636996 2026-08-31\n",
      "320  1668.734400 2026-09-30\n",
      "321  1660.831804 2026-10-31\n",
      "322  1652.929208 2026-11-30\n",
      "323  1668.734400 2026-12-31\n",
      "\n",
      "[324 rows x 2 columns]\n",
      "D\n",
      "               y         ds\n",
      "0     111.314362 2000-01-01\n",
      "1     111.681110 2000-01-02\n",
      "2     109.629995 2000-01-03\n",
      "3     109.049671 2000-01-04\n",
      "4     111.845929 2000-01-05\n",
      "...          ...        ...\n",
      "4206  557.732206 2011-07-08\n",
      "4207  553.035318 2011-07-09\n",
      "4208  553.635142 2011-07-10\n",
      "4209  556.589981 2011-07-11\n",
      "4210  554.253337 2011-07-12\n",
      "\n",
      "[4211 rows x 2 columns]\n",
      "D\n",
      "                y         ds\n",
      "0     3694.299157 2000-01-01\n",
      "1     3757.561279 2000-01-02\n",
      "2     3846.590277 2000-01-03\n",
      "3     3810.872056 2000-01-04\n",
      "4     3762.803506 2000-01-05\n",
      "...           ...        ...\n",
      "4205  3640.988380 2011-07-07\n",
      "4206  3723.086977 2011-07-08\n",
      "4207  3693.410644 2011-07-09\n",
      "4208  3789.547746 2011-07-10\n",
      "4209  3781.462278 2011-07-11\n",
      "\n",
      "[4210 rows x 2 columns]\n",
      "M\n",
      "               y         ds\n",
      "0     994.064991 2000-01-31\n",
      "1     994.064991 2000-02-29\n",
      "2    1008.736841 2000-03-31\n",
      "3    1016.072766 2000-04-30\n",
      "4    1016.072766 2000-05-31\n",
      "..           ...        ...\n",
      "319  1815.688566 2026-08-31\n",
      "320  1808.352641 2026-09-30\n",
      "321  1830.360416 2026-10-31\n",
      "322  1823.024491 2026-11-30\n",
      "323  1830.360416 2026-12-31\n",
      "\n",
      "[324 rows x 2 columns]\n",
      "D\n",
      "                y         ds\n",
      "0     1313.121294 2000-01-01\n",
      "1     1313.121294 2000-01-02\n",
      "2     1313.121294 2000-01-03\n",
      "3     1323.318707 2000-01-04\n",
      "4     1323.318707 2000-01-05\n",
      "..            ...        ...\n",
      "547  13300.180250 2001-07-01\n",
      "548  13300.180250 2001-07-02\n",
      "549  13300.180250 2001-07-03\n",
      "550  13300.180250 2001-07-04\n",
      "551  13300.180250 2001-07-05\n",
      "\n",
      "[552 rows x 2 columns]\n",
      "M\n",
      "               y         ds\n",
      "0    4072.143310 2000-01-31\n",
      "1    4182.706782 2000-02-29\n",
      "2    4230.091128 2000-03-31\n",
      "3    4024.758964 2000-04-30\n",
      "4    3929.990273 2000-05-31\n",
      "..           ...        ...\n",
      "319  7704.943133 2026-08-31\n",
      "320  7768.122260 2026-09-30\n",
      "321  7926.070079 2026-10-31\n",
      "322  8052.428333 2026-11-30\n",
      "323  8068.223115 2026-12-31\n",
      "\n",
      "[324 rows x 2 columns]\n",
      "D\n",
      "              y         ds\n",
      "0   6147.079672 2000-01-01\n",
      "1   6266.143415 2000-01-02\n",
      "2   6384.943451 2000-01-03\n",
      "3   6332.729451 2000-01-04\n",
      "4   6631.179930 2000-01-05\n",
      "5   6694.008140 2000-01-06\n",
      "6   6507.105753 2000-01-07\n",
      "7   6850.584214 2000-01-08\n",
      "8   6854.342040 2000-01-09\n",
      "9   6733.366421 2000-01-10\n",
      "10  6163.363584 2000-01-11\n",
      "11  6398.656219 2000-01-12\n",
      "12  6179.911203 2000-01-13\n",
      "13  5869.593906 2000-01-14\n",
      "14  5825.818532 2000-01-15\n",
      "15  6008.963093 2000-01-16\n",
      "16  6299.897921 2000-01-17\n",
      "17  6343.673295 2000-01-18\n",
      "18  6681.482054 2000-01-19\n",
      "19  7091.546551 2000-01-20\n",
      "20  6979.339192 2000-01-21\n",
      "21  6217.093900 2000-01-22\n",
      "22  6268.055292 2000-01-23\n",
      "23  6613.709337 2000-01-24\n",
      "24  6726.510037 2000-01-25\n",
      "25  6936.223086 2000-01-26\n",
      "26  7440.628788 2000-01-27\n",
      "27  6787.228590 2000-01-28\n",
      "28  6300.227555 2000-01-29\n",
      "29  6150.244157 2000-01-30\n",
      "30  5561.584045 2000-01-31\n",
      "31  5443.245497 2000-02-01\n",
      "32  5361.430378 2000-02-02\n",
      "33  5494.404669 2000-02-03\n",
      "34  5880.339969 2000-02-04\n",
      "35  5949.892709 2000-02-05\n",
      "36  6111.347364 2000-02-06\n",
      "37  6377.823360 2000-02-07\n",
      "38  6292.250416 2000-02-08\n",
      "D\n",
      "              y         ds\n",
      "0   5738.044421 2000-01-01\n",
      "1   5748.203368 2000-01-02\n",
      "2   5754.045852 2000-01-03\n",
      "3   5723.525411 2000-01-04\n",
      "4   5645.044277 2000-01-05\n",
      "5   5566.563143 2000-01-06\n",
      "6   5525.840154 2000-01-07\n",
      "7   5460.439209 2000-01-08\n",
      "8   5432.840010 2000-01-09\n",
      "9   5249.717364 2000-01-10\n",
      "10  5100.036401 2000-01-11\n",
      "11  5406.679632 2000-01-12\n",
      "12  5485.160766 2000-01-13\n",
      "13  5525.840154 2000-01-14\n",
      "14  5560.720658 2000-01-15\n",
      "15  5700.242675 2000-01-16\n",
      "16  5572.362026 2000-01-17\n",
      "17  5861.565006 2000-01-18\n",
      "18  5909.525699 2000-01-19\n",
      "19  5963.328877 2000-01-20\n",
      "20  5976.409066 2000-01-21\n",
      "21  5820.885618 2000-01-22\n",
      "22  5924.088310 2000-01-23\n",
      "23  5916.807004 2000-01-24\n",
      "24  5736.605600 2000-01-25\n",
      "25  5653.764403 2000-01-26\n",
      "26  5348.559992 2000-01-27\n",
      "27  4838.432620 2000-01-28\n",
      "28  4688.708056 2000-01-29\n",
      "29  4717.789676 2000-01-30\n",
      "30  4947.434195 2000-01-31\n",
      "31  4687.269235 2000-02-01\n",
      "32  4748.310117 2000-02-02\n",
      "33  4646.589847 2000-02-03\n",
      "34  4646.589847 2000-02-04\n",
      "35  4530.306967 2000-02-05\n",
      "36  4236.743924 2000-02-06\n",
      "37  4230.901440 2000-02-07\n",
      "38  4246.902871 2000-02-08\n",
      "39  4117.539802 2000-02-09\n",
      "40  4166.982916 2000-02-10\n",
      "41  4521.586841 2000-02-11\n",
      "M\n",
      "                y         ds\n",
      "0     7997.749506 2000-01-31\n",
      "1     8016.064157 2000-02-29\n",
      "2     8052.693459 2000-03-31\n",
      "3     8144.266714 2000-04-30\n",
      "4     8199.210667 2000-05-31\n",
      "..            ...        ...\n",
      "319  13382.256903 2026-08-31\n",
      "320  13363.942252 2026-09-30\n",
      "321  13455.515507 2026-10-31\n",
      "322  13437.200856 2026-11-30\n",
      "323  13418.886205 2026-12-31\n",
      "\n",
      "[324 rows x 2 columns]\n",
      "D\n",
      "                 y         ds\n",
      "0      1036.385787 2000-01-01\n",
      "1       930.588031 2000-01-02\n",
      "2       861.718869 2000-01-03\n",
      "3       863.367241 2000-01-04\n",
      "4       927.537193 2000-01-05\n",
      "...            ...        ...\n",
      "4203  11923.498774 2011-07-05\n",
      "4204  11896.508151 2011-07-06\n",
      "4205  11852.956820 2011-07-07\n",
      "4206  11808.101989 2011-07-08\n",
      "4207  12019.957406 2011-07-09\n",
      "\n",
      "[4208 rows x 2 columns]\n",
      "D\n",
      "               y         ds\n",
      "0   11338.747712 2000-01-01\n",
      "1   11743.262665 2000-01-02\n",
      "2   12312.811040 2000-01-03\n",
      "3   12211.105973 2000-01-04\n",
      "4   11779.469669 2000-01-05\n",
      "5   12649.590418 2000-01-06\n",
      "6   10784.997523 2000-01-07\n",
      "7   10728.517310 2000-01-08\n",
      "8   10667.494269 2000-01-09\n",
      "9   11146.592938 2000-01-10\n",
      "10  11361.326236 2000-01-11\n",
      "11  11092.350236 2000-01-12\n",
      "12  10771.436848 2000-01-13\n",
      "13   9702.380987 2000-01-14\n",
      "14   8904.606442 2000-01-15\n",
      "15   8793.815722 2000-01-16\n",
      "16   9105.711261 2000-01-17\n",
      "17   9008.549020 2000-01-18\n",
      "18   8906.843953 2000-01-19\n",
      "19   8418.659631 2000-01-20\n",
      "20   8337.295578 2000-01-21\n",
      "21   8217.487009 2000-01-22\n",
      "22   8339.533089 2000-01-23\n",
      "23   8599.491241 2000-01-24\n",
      "24   8662.751792 2000-01-25\n",
      "25   7932.712821 2000-01-26\n",
      "26   6893.083627 2000-01-27\n",
      "27   6474.940194 2000-01-28\n",
      "28   5826.333081 2000-01-29\n",
      "29   5885.050806 2000-01-30\n",
      "30   5620.617632 2000-01-31\n",
      "31   4938.108829 2000-02-01\n",
      "32   4908.682163 2000-02-02\n",
      "33   5069.172758 2000-02-03\n",
      "34   4840.878785 2000-02-04\n",
      "35   4278.110747 2000-02-05\n",
      "36   3972.995546 2000-02-06\n",
      "37   3778.671065 2000-02-07\n",
      "38   4782.161059 2000-02-08\n",
      "39   5665.842485 2000-02-09\n",
      "40   6070.425241 2000-02-10\n",
      "41   5914.477472 2000-02-11\n",
      "42   5281.600742 2000-02-12\n",
      "43   5362.964795 2000-02-13\n",
      "M\n",
      "               y         ds\n",
      "0     368.883734 2000-01-31\n",
      "1     364.674112 2000-02-29\n",
      "2     368.883734 2000-03-31\n",
      "3     419.980302 2000-04-30\n",
      "4     364.674112 2000-05-31\n",
      "..           ...        ...\n",
      "95  18235.880404 2007-12-31\n",
      "96  21142.245336 2008-01-31\n",
      "97  19234.768935 2008-02-29\n",
      "98  18803.303149 2008-03-31\n",
      "99  21889.029895 2008-04-30\n",
      "\n",
      "[100 rows x 2 columns]\n",
      "M\n",
      "                y         ds\n",
      "0     2326.958954 2000-01-31\n",
      "1     2437.347549 2000-02-29\n",
      "2     2437.347549 2000-03-31\n",
      "3     2437.347549 2000-04-30\n",
      "4     2437.347549 2000-05-31\n",
      "..            ...        ...\n",
      "246  11489.212350 2020-07-31\n",
      "247  11489.212350 2020-08-31\n",
      "248  11709.989541 2020-09-30\n",
      "249  11709.989541 2020-10-31\n",
      "250  11709.989541 2020-11-30\n",
      "\n",
      "[251 rows x 2 columns]\n",
      "D\n",
      "              y         ds\n",
      "0   7053.806645 2000-01-01\n",
      "1   7162.719618 2000-01-02\n",
      "2   7266.040399 2000-01-03\n",
      "3   7418.747637 2000-01-04\n",
      "4   7063.913015 2000-01-05\n",
      "5   7215.508553 2000-01-06\n",
      "6   6874.115401 2000-01-07\n",
      "7   7283.996048 2000-01-08\n",
      "8   6903.322808 2000-01-09\n",
      "9   6886.478859 2000-01-10\n",
      "10  5496.280399 2000-01-11\n",
      "11  5479.436450 2000-01-12\n",
      "12  5090.913930 2000-01-13\n",
      "13  4860.724528 2000-01-14\n",
      "14  4859.579139 2000-01-15\n",
      "15  5099.908599 2000-01-16\n",
      "16  5147.071655 2000-01-17\n",
      "17  5126.858917 2000-01-18\n",
      "18  4852.841560 2000-01-19\n",
      "19  4636.127316 2000-01-20\n",
      "20  4577.746190 2000-01-21\n",
      "21  4614.802877 2000-01-22\n",
      "22  4600.182329 2000-01-23\n",
      "23  5011.174677 2000-01-24\n",
      "24  5188.608833 2000-01-25\n",
      "25  5048.231364 2000-01-26\n",
      "26  5048.231364 2000-01-27\n",
      "27  5094.282720 2000-01-28\n",
      "28  5131.339407 2000-01-29\n",
      "29  5156.032636 2000-01-30\n",
      "30  6296.940656 2000-01-31\n",
      "31  6295.828955 2000-02-01\n",
      "32  6209.352122 2000-02-02\n",
      "33  5131.339407 2000-02-03\n",
      "34  5613.076339 2000-02-04\n",
      "35  5065.075313 2000-02-05\n",
      "36  5081.919262 2000-02-06\n",
      "37  4949.424761 2000-02-07\n",
      "38  4659.708844 2000-02-08\n",
      "39  4724.827550 2000-02-09\n",
      "40  3846.718817 2000-02-10\n",
      "41  3530.052582 2000-02-11\n",
      "42  3421.105922 2000-02-12\n",
      "43  3409.887852 2000-02-13\n",
      "44  4084.757500 2000-02-14\n",
      "45  3665.915872 2000-02-15\n",
      "46  3747.878526 2000-02-16\n",
      "M\n",
      "               y         ds\n",
      "0    1387.314249 2000-01-31\n",
      "1    1202.042049 2000-02-29\n",
      "2    1278.633185 2000-03-31\n",
      "3    1155.090049 2000-04-30\n",
      "4    1226.889766 2000-05-31\n",
      "..           ...        ...\n",
      "188  2407.864260 2015-09-30\n",
      "189  2169.801406 2015-10-31\n",
      "190  2024.869226 2015-11-30\n",
      "191  2266.012322 2015-12-31\n",
      "192  2172.331620 2016-01-31\n",
      "\n",
      "[193 rows x 2 columns]\n",
      "D\n",
      "              y         ds\n",
      "0   5516.671011 2000-01-01\n",
      "1   5658.026814 2000-01-02\n",
      "2   5603.655614 2000-01-03\n",
      "3   5550.868493 2000-01-04\n",
      "4   5786.896343 2000-01-05\n",
      "5   5715.472992 2000-01-06\n",
      "6   4620.594494 2000-01-07\n",
      "7   4710.654074 2000-01-08\n",
      "8   5645.587131 2000-01-09\n",
      "9   5644.049642 2000-01-10\n",
      "10  5479.398552 2000-01-11\n",
      "11  6085.076019 2000-01-12\n",
      "12  8647.557612 2000-01-13\n",
      "13  8290.394268 2000-01-14\n",
      "14  6970.296933 2000-01-15\n",
      "15  5712.351424 2000-01-16\n",
      "16  5029.054059 2000-01-17\n",
      "17  4904.796997 2000-01-18\n",
      "18  5459.224833 2000-01-19\n",
      "19  6179.841247 2000-01-20\n",
      "20  6582.057676 2000-01-21\n",
      "21  7030.864679 2000-01-22\n",
      "22  7079.039333 2000-01-23\n",
      "23  6985.858185 2000-01-24\n",
      "24  6842.964893 2000-01-25\n",
      "25  6846.086461 2000-01-26\n",
      "26  6880.237352 2000-01-27\n",
      "27  6726.488457 2000-01-28\n",
      "28  6133.250673 2000-01-29\n",
      "29  5906.494347 2000-01-30\n",
      "30  5887.858117 2000-01-31\n",
      "31  5864.562830 2000-02-01\n",
      "32  5746.548905 2000-02-02\n",
      "33  6022.970783 2000-02-03\n",
      "34  6656.602595 2000-02-04\n",
      "35  6970.296933 2000-02-05\n",
      "36  6148.765334 2000-02-06\n",
      "D\n",
      "               y         ds\n",
      "0     272.189234 2000-01-01\n",
      "1     260.792034 2000-01-02\n",
      "2     243.696233 2000-01-03\n",
      "3     272.189234 2000-01-04\n",
      "4     249.394833 2000-01-05\n",
      "..           ...        ...\n",
      "64  15453.260485 2000-03-05\n",
      "65  15390.575882 2000-03-06\n",
      "66  16940.595169 2000-03-07\n",
      "67  16097.202321 2000-03-08\n",
      "68  17185.634982 2000-03-09\n",
      "\n",
      "[69 rows x 2 columns]\n",
      "Q\n",
      "              y         ds\n",
      "0   1875.511918 2000-03-31\n",
      "1   1609.459649 2000-06-30\n",
      "2   1568.644812 2000-09-30\n",
      "3   1691.089322 2000-12-31\n",
      "4   1939.001664 2001-03-31\n",
      "..          ...        ...\n",
      "91  4791.505258 2022-12-31\n",
      "92  6761.199049 2023-03-31\n",
      "93  4590.454395 2023-06-30\n",
      "94  4717.433888 2023-09-30\n",
      "95  4779.411973 2023-12-31\n",
      "\n",
      "[96 rows x 2 columns]\n",
      "D\n",
      "               y         ds\n",
      "0    2622.948850 2000-01-01\n",
      "1    2824.855654 2000-01-02\n",
      "2    2714.724670 2000-01-03\n",
      "3    2622.948850 2000-01-04\n",
      "4    2824.855654 2000-01-05\n",
      "5    2925.809055 2000-01-06\n",
      "6    3146.071023 2000-01-07\n",
      "7    2898.276309 2000-01-08\n",
      "8    2980.874547 2000-01-09\n",
      "9    3274.557171 2000-01-10\n",
      "10   3861.922418 2000-01-11\n",
      "11   3816.034508 2000-01-12\n",
      "12   4265.736026 2000-01-13\n",
      "13   4339.156682 2000-01-14\n",
      "14   4274.913608 2000-01-15\n",
      "15   4238.203280 2000-01-16\n",
      "16   4128.072296 2000-01-17\n",
      "17   4192.315370 2000-01-18\n",
      "18   4256.558444 2000-01-19\n",
      "19   4898.989183 2000-01-20\n",
      "20   5339.513119 2000-01-21\n",
      "21   5972.766276 2000-01-22\n",
      "22   6752.860745 2000-01-23\n",
      "23   7808.282674 2000-01-24\n",
      "24   7285.160501 2000-01-25\n",
      "25   7000.655459 2000-01-26\n",
      "26   7156.674353 2000-01-27\n",
      "27   8285.516937 2000-01-28\n",
      "28   8781.106365 2000-01-29\n",
      "29   8267.161773 2000-01-30\n",
      "30   7734.862018 2000-01-31\n",
      "31   8322.227265 2000-02-01\n",
      "32   9285.873374 2000-02-02\n",
      "33  11699.577438 2000-02-03\n",
      "34  13819.598877 2000-02-04\n",
      "35  13709.467893 2000-02-05\n",
      "36  11727.110184 2000-02-06\n",
      "37  12378.718505 2000-02-07\n",
      "38  11057.146698 2000-02-08\n",
      "39   8909.592513 2000-02-09\n",
      "40   9093.144153 2000-02-10\n",
      "41   9340.938866 2000-02-11\n",
      "42   8863.704603 2000-02-12\n",
      "43   8964.658005 2000-02-13\n",
      "44   8469.068577 2000-02-14\n",
      "45   7844.993002 2000-02-15\n",
      "46   6918.057221 2000-02-16\n",
      "D\n",
      "               y         ds\n",
      "0     133.210199 2000-01-01\n",
      "1     133.174191 2000-01-02\n",
      "2     132.548786 2000-01-03\n",
      "3     132.850005 2000-01-04\n",
      "4     132.868786 2000-01-05\n",
      "...          ...        ...\n",
      "1197  164.295154 2003-04-12\n",
      "1198  164.015468 2003-04-13\n",
      "1199  163.904096 2003-04-14\n",
      "1200  162.651013 2003-04-15\n",
      "1201  162.149660 2003-04-16\n",
      "\n",
      "[1202 rows x 2 columns]\n",
      "D\n",
      "               0         ds\n",
      "0      12.968413 2000-01-01\n",
      "1      12.974406 2000-01-02\n",
      "2      12.977402 2000-01-03\n",
      "3      12.977402 2000-01-04\n",
      "4      12.995383 2000-01-05\n",
      "...          ...        ...\n",
      "12123  81.374017 2033-03-11\n",
      "12124  80.560845 2033-03-12\n",
      "12125  79.977813 2033-03-13\n",
      "12126  79.686300 2033-03-14\n",
      "12127  79.295054 2033-03-15\n",
      "\n",
      "[12128 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W\n",
      "                 0         ds\n",
      "0      1222.723531 2000-01-02\n",
      "1      1425.355651 2000-01-09\n",
      "2      1296.603268 2000-01-16\n",
      "3      1271.646131 2000-01-23\n",
      "4      1240.738948 2000-01-30\n",
      "...            ...        ...\n",
      "2187  11818.433099 2041-12-01\n",
      "2188  12466.492268 2041-12-08\n",
      "2189  12466.492268 2041-12-15\n",
      "2190  12604.665557 2041-12-22\n",
      "2191  12604.665557 2041-12-29\n",
      "\n",
      "[2192 rows x 2 columns]\n",
      "W\n",
      "                 0         ds\n",
      "0      2861.064688 2000-01-02\n",
      "1      2795.138658 2000-01-09\n",
      "2      2930.008303 2000-01-16\n",
      "3      2823.856221 2000-01-23\n",
      "4      2981.553457 2000-01-30\n",
      "...            ...        ...\n",
      "1652  15674.684795 2031-08-31\n",
      "1653  15565.534066 2031-09-07\n",
      "1654  15448.239644 2031-09-14\n",
      "1655  15536.305154 2031-09-21\n",
      "1656  15685.479922 2031-09-28\n",
      "\n",
      "[1657 rows x 2 columns]\n",
      "D\n",
      "              0         ds\n",
      "0     24.268246 2000-01-01\n",
      "1     24.021774 2000-01-02\n",
      "2     24.310197 2000-01-03\n",
      "3     24.179114 2000-01-04\n",
      "4     24.336454 2000-01-05\n",
      "...         ...        ...\n",
      "5421  43.607446 2014-11-04\n",
      "5422  43.833096 2014-11-05\n",
      "5423  43.556163 2014-11-06\n",
      "5424  43.525392 2014-11-07\n",
      "5425  43.094604 2014-11-08\n",
      "\n",
      "[5426 rows x 2 columns]\n",
      "W\n",
      "               0         ds\n",
      "0    2545.321492 2000-01-02\n",
      "1    2521.464423 2000-01-09\n",
      "2    2530.028499 2000-01-16\n",
      "3    2539.714061 2000-01-23\n",
      "4    2523.503489 2000-01-30\n",
      "..           ...        ...\n",
      "255  3709.831892 2004-11-21\n",
      "256  3676.493168 2004-11-28\n",
      "257  3669.764252 2004-12-05\n",
      "258  3622.457928 2004-12-12\n",
      "259  3700.554143 2004-12-19\n",
      "\n",
      "[260 rows x 2 columns]\n",
      "W\n",
      "               0         ds\n",
      "0      33.307799 2000-01-02\n",
      "1      33.242052 2000-01-09\n",
      "2      33.361861 2000-01-16\n",
      "3      33.233806 2000-01-23\n",
      "4      33.753303 2000-01-30\n",
      "...          ...        ...\n",
      "1652  137.622427 2031-08-31\n",
      "1653  138.084801 2031-09-07\n",
      "1654  138.141263 2031-09-14\n",
      "1655  137.917677 2031-09-21\n",
      "1656  138.161248 2031-09-28\n",
      "\n",
      "[1657 rows x 2 columns]\n",
      "D\n",
      "                0         ds\n",
      "0      337.153897 2000-01-01\n",
      "1      342.192319 2000-01-02\n",
      "2      338.569274 2000-01-03\n",
      "3      336.953891 2000-01-04\n",
      "4      335.707753 2000-01-05\n",
      "...           ...        ...\n",
      "8313  6682.634107 2022-10-05\n",
      "8314  6731.235924 2022-10-06\n",
      "8315  6748.466835 2022-10-07\n",
      "8316  6756.412976 2022-10-08\n",
      "8317  6795.817662 2022-10-09\n",
      "\n",
      "[8318 rows x 2 columns]\n",
      "H\n",
      "             0                  ds\n",
      "0    23.853570 2000-01-01 00:00:00\n",
      "1    20.346301 2000-01-01 01:00:00\n",
      "2    23.152117 2000-01-01 02:00:00\n",
      "3    21.328336 2000-01-01 03:00:00\n",
      "4    23.011826 2000-01-01 04:00:00\n",
      "..         ...                 ...\n",
      "278  20.065719 2000-01-12 14:00:00\n",
      "279  18.382230 2000-01-12 15:00:00\n",
      "280  18.803103 2000-01-12 16:00:00\n",
      "281  18.522521 2000-01-12 17:00:00\n",
      "282  17.961358 2000-01-12 18:00:00\n",
      "\n",
      "[283 rows x 2 columns]\n",
      "D\n",
      "                0         ds\n",
      "0      121.197952 2000-01-01\n",
      "1      121.271358 2000-01-02\n",
      "2      121.239322 2000-01-03\n",
      "3      121.230412 2000-01-04\n",
      "4      121.365130 2000-01-05\n",
      "...           ...        ...\n",
      "11748   98.536742 2032-03-01\n",
      "11749   98.536742 2032-03-02\n",
      "11750   97.817113 2032-03-03\n",
      "11751   97.875455 2032-03-04\n",
      "11752   97.799080 2032-03-05\n",
      "\n",
      "[11753 rows x 2 columns]\n",
      "D\n",
      "               0         ds\n",
      "0    1531.868414 2000-01-01\n",
      "1    1092.176718 2000-01-02\n",
      "2     928.223882 2000-01-03\n",
      "3    1825.824257 2000-01-04\n",
      "4     795.736742 2000-01-05\n",
      "5    1671.807956 2000-01-06\n",
      "6    1648.622707 2000-01-07\n",
      "7    1483.013781 2000-01-08\n",
      "8    1811.747498 2000-01-09\n",
      "9    4394.418688 2000-01-10\n",
      "10   3508.410938 2000-01-11\n",
      "11   3014.896340 2000-01-12\n",
      "12   4059.888659 2000-01-13\n",
      "13   3582.934954 2000-01-14\n",
      "14   2996.679358 2000-01-15\n",
      "15   2710.175918 2000-01-16\n",
      "16   3063.750973 2000-01-17\n",
      "17   2462.590574 2000-01-18\n",
      "18   3726.186674 2000-01-19\n",
      "19   5696.932885 2000-01-20\n",
      "20   4874.684571 2000-01-21\n",
      "21   3241.780568 2000-01-22\n",
      "22   4589.837220 2000-01-23\n",
      "23   1890.411738 2000-01-24\n",
      "24   3452.103903 2000-01-25\n",
      "25  12395.813912 2000-01-26\n",
      "26   6079.489502 2000-01-27\n",
      "27   3351.082459 2000-01-28\n",
      "D\n",
      "              0         ds\n",
      "0     88.563259 2000-01-01\n",
      "1     88.563259 2000-01-02\n",
      "2     88.563259 2000-01-03\n",
      "3     88.563259 2000-01-04\n",
      "4     88.701120 2000-01-05\n",
      "..          ...        ...\n",
      "382  185.479231 2001-01-17\n",
      "383  185.617092 2001-01-18\n",
      "384  185.203510 2001-01-19\n",
      "385  185.341371 2001-01-20\n",
      "386  184.858859 2001-01-21\n",
      "\n",
      "[387 rows x 2 columns]\n",
      "D\n",
      "              0         ds\n",
      "0   1832.966600 2000-01-01\n",
      "1   1967.740312 2000-01-02\n",
      "2   1909.143046 2000-01-03\n",
      "3   1827.106873 2000-01-04\n",
      "4   1920.862499 2000-01-05\n",
      "5   1979.459765 2000-01-06\n",
      "6   2090.794571 2000-01-07\n",
      "7   1915.002772 2000-01-08\n",
      "8   1967.740312 2000-01-09\n",
      "9   2149.391837 2000-01-10\n",
      "10  2541.993520 2000-01-11\n",
      "11  2583.011606 2000-01-12\n",
      "12  2793.961765 2000-01-13\n",
      "13  2893.577117 2000-01-14\n",
      "14  2858.418757 2000-01-15\n",
      "15  2858.418757 2000-01-16\n",
      "16  2735.364498 2000-01-17\n",
      "17  2747.083952 2000-01-18\n",
      "18  2776.382585 2000-01-19\n",
      "19  3157.264815 2000-01-20\n",
      "20  3461.970599 2000-01-21\n",
      "21  3977.626541 2000-01-22\n",
      "22  4381.947677 2000-01-23\n",
      "23  5149.571864 2000-01-24\n",
      "24  4921.042526 2000-01-25\n",
      "25  4686.653461 2000-01-26\n",
      "26  4768.689634 2000-01-27\n",
      "27  5272.626123 2000-01-28\n",
      "28  5512.874914 2000-01-29\n",
      "29  5196.449677 2000-01-30\n",
      "30  4774.549361 2000-01-31\n",
      "31  5073.395418 2000-02-01\n",
      "32  5635.929173 2000-02-02\n",
      "33  6737.557777 2000-02-03\n",
      "34  7757.150208 2000-02-04\n",
      "35  8026.697632 2000-02-05\n",
      "36  7089.141374 2000-02-06\n",
      "37  7669.254309 2000-02-07\n",
      "38  7007.105201 2000-02-08\n",
      "39  5782.422338 2000-02-09\n",
      "40  5653.508353 2000-02-10\n",
      "41  5887.897418 2000-02-11\n",
      "H\n",
      "               0                  ds\n",
      "0      15.781587 2000-01-01 00:00:00\n",
      "1      15.856278 2000-01-01 01:00:00\n",
      "2      15.855355 2000-01-01 02:00:00\n",
      "3      15.791730 2000-01-01 03:00:00\n",
      "4      15.718883 2000-01-01 04:00:00\n",
      "...          ...                 ...\n",
      "3942  301.847711 2000-06-13 06:00:00\n",
      "3943  300.879499 2000-06-13 07:00:00\n",
      "3944  343.545386 2000-06-13 08:00:00\n",
      "3945  338.162129 2000-06-13 09:00:00\n",
      "3946  353.808431 2000-06-13 10:00:00\n",
      "\n",
      "[3947 rows x 2 columns]\n",
      "D\n",
      "               0         ds\n",
      "0      11.017738 2000-01-01\n",
      "1      11.037031 2000-01-02\n",
      "2      11.082049 2000-01-03\n",
      "3      11.056325 2000-01-04\n",
      "4      11.069186 2000-01-05\n",
      "...          ...        ...\n",
      "6440  110.971566 2017-08-19\n",
      "6441  111.432546 2017-08-20\n",
      "6442  111.745352 2017-08-21\n",
      "6443  110.955099 2017-08-22\n",
      "6444  105.867835 2017-08-23\n",
      "\n",
      "[6445 rows x 2 columns]\n",
      "W\n",
      "                0         ds\n",
      "0     1809.740420 2000-01-02\n",
      "1     1803.407273 2000-01-09\n",
      "2     1798.261590 2000-01-16\n",
      "3     1798.261590 2000-01-23\n",
      "4     1788.563958 2000-01-30\n",
      "...           ...        ...\n",
      "1306  7260.799364 2025-01-12\n",
      "1307  7259.413988 2025-01-19\n",
      "1308  7294.048389 2025-01-26\n",
      "1309  7316.511272 2025-02-02\n",
      "1310  7312.355144 2025-02-09\n",
      "\n",
      "[1311 rows x 2 columns]\n",
      "D\n",
      "              0         ds\n",
      "0     11.107331 2000-01-01\n",
      "1     11.096405 2000-01-02\n",
      "2     11.080512 2000-01-03\n",
      "3     11.084485 2000-01-04\n",
      "4     11.090445 2000-01-05\n",
      "...         ...        ...\n",
      "9356  90.360697 2025-08-13\n",
      "9357  89.777746 2025-08-14\n",
      "9358  89.777746 2025-08-15\n",
      "9359  89.755494 2025-08-16\n",
      "9360  88.536186 2025-08-17\n",
      "\n",
      "[9361 rows x 2 columns]\n",
      "D\n",
      "              0         ds\n",
      "0     12.641907 2000-01-01\n",
      "1     12.814758 2000-01-02\n",
      "2     12.849328 2000-01-03\n",
      "3     12.901183 2000-01-04\n",
      "4     12.901183 2000-01-05\n",
      "...         ...        ...\n",
      "1298  13.782721 2003-07-22\n",
      "1299  13.834576 2003-07-23\n",
      "1300  13.921002 2003-07-24\n",
      "1301  13.955572 2003-07-25\n",
      "1302  13.990142 2003-07-26\n",
      "\n",
      "[1303 rows x 2 columns]\n",
      "W\n",
      "               0         ds\n",
      "0    4976.638953 2000-01-02\n",
      "1    4994.750580 2000-01-09\n",
      "2    4929.548725 2000-01-16\n",
      "3    4933.895516 2000-01-23\n",
      "4    4873.764917 2000-01-30\n",
      "..           ...        ...\n",
      "832  3011.165281 2015-12-13\n",
      "833  3012.614211 2015-12-20\n",
      "834  3066.949089 2015-12-27\n",
      "835  3032.899232 2016-01-03\n",
      "836  3088.683041 2016-01-10\n",
      "\n",
      "[837 rows x 2 columns]\n",
      "D\n",
      "              0         ds\n",
      "0     11.967239 2000-01-01\n",
      "1     11.830926 2000-01-02\n",
      "2     11.980870 2000-01-03\n",
      "3     11.885451 2000-01-04\n",
      "4     11.926345 2000-01-05\n",
      "...         ...        ...\n",
      "4827  13.837445 2013-03-20\n",
      "4828  14.066450 2013-03-21\n",
      "4829  14.120975 2013-03-22\n",
      "4830  14.063724 2013-03-23\n",
      "4831  14.028283 2013-03-24\n",
      "\n",
      "[4832 rows x 2 columns]\n",
      "D\n",
      "                0         ds\n",
      "0       12.750099 2000-01-01\n",
      "1       12.768573 2000-01-02\n",
      "2       12.763955 2000-01-03\n",
      "3       12.727008 2000-01-04\n",
      "4       12.727008 2000-01-05\n",
      "...           ...        ...\n",
      "11511  130.978760 2031-07-08\n",
      "11512  131.946404 2031-07-09\n",
      "11513  132.115989 2031-07-10\n",
      "11514  131.487523 2031-07-11\n",
      "11515  131.487523 2031-07-12\n",
      "\n",
      "[11516 rows x 2 columns]\n",
      "Q\n",
      "               0         ds\n",
      "0    7957.578091 2000-03-31\n",
      "1    8637.695802 2000-06-30\n",
      "2   10895.148653 2000-09-30\n",
      "3    8437.887209 2000-12-31\n",
      "4    9938.372891 2001-03-31\n",
      "5   13340.882679 2001-06-30\n",
      "6   13961.442058 2001-09-30\n",
      "7   10537.798670 2001-12-31\n",
      "8    8977.754657 2002-03-31\n",
      "9   14401.405210 2002-06-30\n",
      "10  12399.476809 2002-09-30\n",
      "11  10749.134681 2002-12-31\n",
      "12  19946.573969 2003-03-31\n",
      "13  20796.721107 2003-06-30\n",
      "14  15387.633526 2003-09-30\n",
      "15  10301.966893 2003-12-31\n",
      "16  12631.466112 2004-03-31\n",
      "17  11754.095054 2004-06-30\n",
      "18   9977.431629 2004-09-30\n",
      "19   8363.112685 2004-12-31\n",
      "20   8829.819449 2005-03-31\n",
      "21  14348.571207 2005-06-30\n",
      "22  16394.688046 2005-09-30\n",
      "23  17494.595925 2005-12-31\n",
      "24  17973.310416 2006-03-31\n",
      "25  13885.879828 2006-06-30\n",
      "26   9683.175051 2006-09-30\n",
      "D\n",
      "              0         ds\n",
      "0    504.544622 2000-01-01\n",
      "1    500.321519 2000-01-02\n",
      "2    499.476898 2000-01-03\n",
      "3    533.261720 2000-01-04\n",
      "4    549.309510 2000-01-05\n",
      "5    591.540538 2000-01-06\n",
      "6    661.644043 2000-01-07\n",
      "7    713.165896 2000-01-08\n",
      "8    655.731699 2000-01-09\n",
      "9    643.907011 2000-01-10\n",
      "10   671.779489 2000-01-11\n",
      "11   750.329200 2000-01-12\n",
      "12   753.707682 2000-01-13\n",
      "13   755.396923 2000-01-14\n",
      "14   757.930784 2000-01-15\n",
      "15   802.695673 2000-01-16\n",
      "16   900.671656 2000-01-17\n",
      "17  1050.169492 2000-01-18\n",
      "18  1208.113534 2000-01-19\n",
      "19  1238.519873 2000-01-20\n",
      "20  1037.500184 2000-01-21\n",
      "21  1018.073912 2000-01-22\n",
      "22   951.348889 2000-01-23\n",
      "23   837.325115 2000-01-24\n",
      "24   769.755472 2000-01-25\n",
      "25   760.464646 2000-01-26\n",
      "26   839.858977 2000-01-27\n",
      "27   832.257392 2000-01-28\n",
      "28   775.667816 2000-01-29\n",
      "29   688.671900 2000-01-30\n",
      "30   608.432948 2000-01-31\n",
      "D\n",
      "                 0         ds\n",
      "0    192174.135805 2000-01-01\n",
      "1    191263.378388 2000-01-02\n",
      "2    206564.102989 2000-01-03\n",
      "3    201281.709972 2000-01-04\n",
      "4    204924.739639 2000-01-05\n",
      "..             ...        ...\n",
      "113  589446.520976 2000-04-23\n",
      "114  533890.318556 2000-04-24\n",
      "115  641541.845212 2000-04-25\n",
      "116  686168.958631 2000-04-26\n",
      "117  633891.482912 2000-04-27\n",
      "\n",
      "[118 rows x 2 columns]\n",
      "D\n",
      "              0         ds\n",
      "0      5.405689 2000-01-01\n",
      "1      5.405689 2000-01-02\n",
      "2      5.406105 2000-01-03\n",
      "3      5.406105 2000-01-04\n",
      "4      5.405273 2000-01-05\n",
      "...         ...        ...\n",
      "9545  11.050838 2026-02-18\n",
      "9546  11.097744 2026-02-19\n",
      "9547  11.134670 2026-02-20\n",
      "9548  11.114710 2026-02-21\n",
      "9549  11.067804 2026-02-22\n",
      "\n",
      "[9550 rows x 2 columns]\n",
      "W\n",
      "               0         ds\n",
      "0    1776.397442 2000-01-02\n",
      "1    1854.133031 2000-01-09\n",
      "2    1860.389920 2000-01-16\n",
      "3    1859.468906 2000-01-23\n",
      "4    1834.281174 2000-01-30\n",
      "..           ...        ...\n",
      "387  1087.198613 2007-06-03\n",
      "388  1096.679051 2007-06-10\n",
      "389  1095.818103 2007-06-17\n",
      "390  1092.244168 2007-06-24\n",
      "391  1085.406640 2007-07-01\n",
      "\n",
      "[392 rows x 2 columns]\n",
      "D\n",
      "              0         ds\n",
      "0     14.325701 2000-01-01\n",
      "1     14.383755 2000-01-02\n",
      "2     14.354728 2000-01-03\n",
      "3     14.216832 2000-01-04\n",
      "4     14.238602 2000-01-05\n",
      "...         ...        ...\n",
      "5005  27.397652 2013-09-14\n",
      "5006  27.448757 2013-09-15\n",
      "5007  27.414688 2013-09-16\n",
      "5008  27.131910 2013-09-17\n",
      "5009  26.917272 2013-09-18\n",
      "\n",
      "[5010 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D\n",
      "               0         ds\n",
      "0      47.754915 2000-01-01\n",
      "1      47.719082 2000-01-02\n",
      "2      47.667115 2000-01-03\n",
      "3      47.995020 2000-01-04\n",
      "4      47.745957 2000-01-05\n",
      "...          ...        ...\n",
      "5447  182.661072 2014-11-30\n",
      "5448  184.882926 2014-12-01\n",
      "5449  189.022040 2014-12-02\n",
      "5450  186.692668 2014-12-03\n",
      "5451  183.341959 2014-12-04\n",
      "\n",
      "[5452 rows x 2 columns]\n",
      "W\n",
      "               0         ds\n",
      "0    2047.954173 2000-01-02\n",
      "1    2070.955902 2000-01-09\n",
      "2    2056.647409 2000-01-16\n",
      "3    2040.542950 2000-01-23\n",
      "4    2030.183670 2000-01-30\n",
      "..           ...        ...\n",
      "652  3360.223954 2012-07-01\n",
      "653  3373.867558 2012-07-08\n",
      "654  3352.753502 2012-07-15\n",
      "655  3356.935809 2012-07-22\n",
      "656  3363.468155 2012-07-29\n",
      "\n",
      "[657 rows x 2 columns]\n",
      "D\n",
      "              0         ds\n",
      "0     42.336075 2000-01-01\n",
      "1     43.069142 2000-01-02\n",
      "2     38.273304 2000-01-03\n",
      "3     41.064252 2000-01-04\n",
      "4     38.741405 2000-01-05\n",
      "...         ...        ...\n",
      "1056  23.806302 2002-11-22\n",
      "1057  22.967250 2002-11-23\n",
      "1058  22.384331 2002-11-24\n",
      "1059  22.675791 2002-11-25\n",
      "1060  22.375499 2002-11-26\n",
      "\n",
      "[1061 rows x 2 columns]\n",
      "D\n",
      "                0         ds\n",
      "0        3.171382 2000-01-01\n",
      "1        3.187140 2000-01-02\n",
      "2        3.196592 2000-01-03\n",
      "3        3.199744 2000-01-04\n",
      "4        3.196592 2000-01-05\n",
      "...           ...        ...\n",
      "12122  270.622180 2033-03-10\n",
      "12123  272.123019 2033-03-11\n",
      "12124  271.510438 2033-03-12\n",
      "12125  274.159884 2033-03-13\n",
      "12126  272.781543 2033-03-14\n",
      "\n",
      "[12127 rows x 2 columns]\n",
      "Q\n",
      "               0         ds\n",
      "0    1425.979514 2000-03-31\n",
      "1     858.914825 2000-06-30\n",
      "2     758.103325 2000-09-30\n",
      "3     909.320576 2000-12-31\n",
      "4    4154.190737 2001-03-31\n",
      "5   10051.663495 2001-06-30\n",
      "6    2793.235485 2001-09-30\n",
      "7    1564.595327 2001-12-31\n",
      "8    5300.921551 2002-03-31\n",
      "9    4349.513018 2002-06-30\n",
      "10   4488.128831 2002-09-30\n",
      "11   3524.118861 2002-12-31\n",
      "12   5943.594864 2003-03-31\n",
      "13    480.871700 2003-06-30\n",
      "14    852.614107 2003-09-30\n",
      "15   1652.805389 2003-12-31\n",
      "16   2106.457140 2004-03-31\n",
      "17   1678.008264 2004-06-30\n",
      "18   2812.137641 2004-09-30\n",
      "19   3366.600892 2004-12-31\n",
      "20   1451.182389 2005-03-31\n",
      "21   4714.954706 2005-06-30\n",
      "22   7065.122804 2005-09-30\n",
      "23   2106.457140 2005-12-31\n",
      "24    808.509075 2006-03-31\n",
      "25   6630.373209 2006-06-30\n",
      "26   8192.951461 2006-09-30\n",
      "27   4595.241050 2006-12-31\n",
      "28    833.711950 2007-03-31\n",
      "29    348.556606 2007-06-30\n",
      "30   3599.727486 2007-09-30\n",
      "31   5483.642395 2007-12-31\n",
      "32   9295.577244 2008-03-31\n",
      "33  10662.833215 2008-06-30\n",
      "34   4021.875643 2008-09-30\n",
      "35   4009.274205 2008-12-31\n",
      "36   4891.374832 2009-03-31\n",
      "37  20088.708479 2009-06-30\n",
      "38   8318.965837 2009-09-30\n",
      "39   5225.312926 2009-12-31\n",
      "40   4910.276988 2010-03-31\n",
      "41  10826.651903 2010-06-30\n",
      "42   1684.308983 2010-09-30\n",
      "43   2068.652827 2010-12-31\n",
      "44   1224.356514 2011-03-31\n",
      "45    795.907638 2011-06-30\n",
      "46    531.277450 2011-09-30\n",
      "D\n",
      "             0         ds\n",
      "0     6.167020 2000-01-01\n",
      "1     6.163822 2000-01-02\n",
      "2     6.156197 2000-01-03\n",
      "3     6.158411 2000-01-04\n",
      "4     6.151155 2000-01-05\n",
      "...        ...        ...\n",
      "4964  6.186574 2013-08-04\n",
      "4965  6.186574 2013-08-05\n",
      "4966  6.193584 2013-08-06\n",
      "4967  6.192662 2013-08-07\n",
      "4968  6.193215 2013-08-08\n",
      "\n",
      "[4969 rows x 2 columns]\n",
      "H\n",
      "              0                  ds\n",
      "0     39.861292 2000-01-01 00:00:00\n",
      "1     47.231730 2000-01-01 01:00:00\n",
      "2     46.448046 2000-01-01 02:00:00\n",
      "3     45.481565 2000-01-01 03:00:00\n",
      "4     45.594303 2000-01-01 04:00:00\n",
      "..          ...                 ...\n",
      "546  169.472878 2000-01-23 18:00:00\n",
      "547  170.997085 2000-01-23 19:00:00\n",
      "548  185.727655 2000-01-23 20:00:00\n",
      "549  173.293704 2000-01-23 21:00:00\n",
      "550  169.239995 2000-01-23 22:00:00\n",
      "\n",
      "[551 rows x 2 columns]\n",
      "D\n",
      "               0         ds\n",
      "0     597.936775 2000-01-01\n",
      "1     599.286592 2000-01-02\n",
      "2     601.356312 2000-01-03\n",
      "3     604.325910 2000-01-04\n",
      "4     600.906373 2000-01-05\n",
      "...          ...        ...\n",
      "1298  480.232702 2003-07-22\n",
      "1299  482.410407 2003-07-23\n",
      "1300  481.816487 2003-07-24\n",
      "1301  482.878344 2003-07-25\n",
      "1302  487.701691 2003-07-26\n",
      "\n",
      "[1303 rows x 2 columns]\n",
      "D\n",
      "                0         ds\n",
      "0       17.414852 2000-01-01\n",
      "1       17.062738 2000-01-02\n",
      "2       16.906243 2000-01-03\n",
      "3       16.882769 2000-01-04\n",
      "4       16.812346 2000-01-05\n",
      "...           ...        ...\n",
      "5204  1001.128078 2014-04-01\n",
      "5205   989.988156 2014-04-02\n",
      "5206  1020.726260 2014-04-03\n",
      "5207  1048.316976 2014-04-04\n",
      "5208  1043.193990 2014-04-05\n",
      "\n",
      "[5209 rows x 2 columns]\n",
      "W\n",
      "                0         ds\n",
      "0     7470.461080 2000-01-02\n",
      "1     7428.008133 2000-01-09\n",
      "2     7462.395417 2000-01-16\n",
      "3     7343.814422 2000-01-23\n",
      "4     7358.481670 2000-01-30\n",
      "..            ...        ...\n",
      "387  13209.240375 2007-06-03\n",
      "388  13241.366679 2007-06-10\n",
      "389  13340.784941 2007-06-17\n",
      "390  13264.854132 2007-06-24\n",
      "391  13364.369029 2007-07-01\n",
      "\n",
      "[392 rows x 2 columns]\n",
      "Q\n",
      "                0         ds\n",
      "0     1743.423704 2000-03-31\n",
      "1     2104.312594 2000-06-30\n",
      "2     1855.591872 2000-09-30\n",
      "3     1844.212493 2000-12-31\n",
      "4     1853.966247 2001-03-31\n",
      "..            ...        ...\n",
      "129  15444.196529 2032-06-30\n",
      "130  13446.302628 2032-09-30\n",
      "131  13602.362688 2032-12-31\n",
      "132  14060.789117 2033-03-31\n",
      "133  15923.756091 2033-06-30\n",
      "\n",
      "[134 rows x 2 columns]\n",
      "D\n",
      "               0         ds\n",
      "0    6737.897243 2000-01-01\n",
      "1    6743.727332 2000-01-02\n",
      "2    6740.202162 2000-01-03\n",
      "3    6740.337745 2000-01-04\n",
      "4    6742.913831 2000-01-05\n",
      "..           ...        ...\n",
      "330  8490.177942 2000-11-26\n",
      "331  8494.381029 2000-11-27\n",
      "332  8504.007455 2000-11-28\n",
      "333  8500.753452 2000-11-29\n",
      "334  8501.702537 2000-11-30\n",
      "\n",
      "[335 rows x 2 columns]\n",
      "D\n",
      "              0         ds\n",
      "0     10.632142 2000-01-01\n",
      "1     10.632142 2000-01-02\n",
      "2     10.632142 2000-01-03\n",
      "3     10.632142 2000-01-04\n",
      "4     10.632142 2000-01-05\n",
      "...         ...        ...\n",
      "1917  35.931584 2005-04-01\n",
      "1918  36.172919 2005-04-02\n",
      "1919  36.462524 2005-04-03\n",
      "1920  36.498723 2005-04-04\n",
      "1921  37.198596 2005-04-05\n",
      "\n",
      "[1922 rows x 2 columns]\n",
      "D\n",
      "               0         ds\n",
      "0      19.625157 2000-01-01\n",
      "1      20.435136 2000-01-02\n",
      "2      21.093244 2000-01-03\n",
      "3      20.890750 2000-01-04\n",
      "4      20.435136 2000-01-05\n",
      "...          ...        ...\n",
      "4339  108.034387 2011-11-18\n",
      "4340  109.127857 2011-11-19\n",
      "4341  109.022562 2011-11-20\n",
      "4342  109.808237 2011-11-21\n",
      "4343  110.666819 2011-11-22\n",
      "\n",
      "[4344 rows x 2 columns]\n",
      "H\n",
      "             0                  ds\n",
      "0    17.493556 2000-01-01 00:00:00\n",
      "1    16.158791 2000-01-01 01:00:00\n",
      "2    16.659328 2000-01-01 02:00:00\n",
      "3    18.828322 2000-01-01 03:00:00\n",
      "4    21.497852 2000-01-01 04:00:00\n",
      "..         ...                 ...\n",
      "277   7.649661 2000-01-12 13:00:00\n",
      "278   7.983352 2000-01-12 14:00:00\n",
      "279   6.815433 2000-01-12 15:00:00\n",
      "280   6.982278 2000-01-12 16:00:00\n",
      "281   6.648587 2000-01-12 17:00:00\n",
      "\n",
      "[282 rows x 2 columns]\n",
      "D\n",
      "              0         ds\n",
      "0     87.764439 2000-01-01\n",
      "1     91.764396 2000-01-02\n",
      "2     97.097672 2000-01-03\n",
      "3    103.836339 2000-01-04\n",
      "4    113.313714 2000-01-05\n",
      "5    119.511846 2000-01-06\n",
      "6    124.520801 2000-01-07\n",
      "7    133.421606 2000-01-08\n",
      "8    157.277206 2000-01-09\n",
      "9    179.835522 2000-01-10\n",
      "10   192.159713 2000-01-11\n",
      "11   199.835307 2000-01-12\n",
      "12   229.744895 2000-01-13\n",
      "13   251.762676 2000-01-14\n",
      "14   274.465135 2000-01-15\n",
      "15   295.041490 2000-01-16\n",
      "16   311.221496 2000-01-17\n",
      "17   351.617458 2000-01-18\n",
      "18   381.491011 2000-01-19\n",
      "19   413.238418 2000-01-20\n",
      "20   437.850766 2000-01-21\n",
      "21   494.570876 2000-01-22\n",
      "22   562.534110 2000-01-23\n",
      "23   578.389795 2000-01-24\n",
      "24   649.668308 2000-01-25\n",
      "25   709.451449 2000-01-26\n",
      "26   774.603902 2000-01-27\n",
      "27   802.351351 2000-01-28\n",
      "28   829.053767 2000-01-29\n",
      "29   901.917848 2000-01-30\n",
      "30  1012.655396 2000-01-31\n",
      "31  1101.303092 2000-02-01\n",
      "32  1233.770136 2000-02-02\n",
      "33  1399.137728 2000-02-03\n",
      "34  1443.029148 2000-02-04\n",
      "35  1644.900851 2000-02-05\n",
      "36  1788.106519 2000-02-06\n",
      "37  1908.285407 2000-02-07\n",
      "38  2167.489827 2000-02-08\n",
      "39  2606.476099 2000-02-09\n",
      "40  2761.105067 2000-02-10\n",
      "41  3002.688055 2000-02-11\n",
      "42  3288.630927 2000-02-12\n",
      "43  3608.987843 2000-02-13\n",
      "44  4193.377956 2000-02-14\n",
      "45  4739.858567 2000-02-15\n",
      "D\n",
      "              0         ds\n",
      "0     92.682867 2000-01-01\n",
      "1     94.931156 2000-01-02\n",
      "2    117.976120 2000-01-03\n",
      "3    136.524505 2000-01-04\n",
      "4    137.889538 2000-01-05\n",
      "..          ...        ...\n",
      "702  105.610530 2001-12-03\n",
      "703   97.821814 2001-12-04\n",
      "704   99.267143 2001-12-05\n",
      "705  103.442537 2001-12-06\n",
      "706   94.208492 2001-12-07\n",
      "\n",
      "[707 rows x 2 columns]\n",
      "D\n",
      "               0         ds\n",
      "0      38.822918 2000-01-01\n",
      "1      39.327415 2000-01-02\n",
      "2      39.201289 2000-01-03\n",
      "3      40.147218 2000-01-04\n",
      "4      40.399467 2000-01-05\n",
      "...          ...        ...\n",
      "5334  174.946240 2014-08-09\n",
      "5335  173.871961 2014-08-10\n",
      "5336  173.871961 2014-08-11\n",
      "5337  174.930890 2014-08-12\n",
      "5338  174.378405 2014-08-13\n",
      "\n",
      "[5339 rows x 2 columns]\n",
      "D\n",
      "            0         ds\n",
      "0    4.677534 2000-01-01\n",
      "1    4.654995 2000-01-02\n",
      "2    4.632456 2000-01-03\n",
      "3    4.609916 2000-01-04\n",
      "4    4.598647 2000-01-05\n",
      "..        ...        ...\n",
      "448  3.539309 2001-03-24\n",
      "449  3.550579 2001-03-25\n",
      "450  3.550579 2001-03-26\n",
      "451  3.550579 2001-03-27\n",
      "452  3.550579 2001-03-28\n",
      "\n",
      "[453 rows x 2 columns]\n",
      "D\n",
      "               0         ds\n",
      "0      10.298265 2000-01-01\n",
      "1      10.297629 2000-01-02\n",
      "2      10.297992 2000-01-03\n",
      "3      10.301809 2000-01-04\n",
      "4      10.302354 2000-01-05\n",
      "...          ...        ...\n",
      "12269  10.517091 2033-08-04\n",
      "12270  10.517091 2033-08-05\n",
      "12271  10.508458 2033-08-06\n",
      "12272  10.510366 2033-08-07\n",
      "12273  10.510275 2033-08-08\n",
      "\n",
      "[12274 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D\n",
      "             0         ds\n",
      "0    26.817482 2000-01-01\n",
      "1    26.868331 2000-01-02\n",
      "2    26.754428 2000-01-03\n",
      "3    27.173432 2000-01-04\n",
      "4    27.397171 2000-01-05\n",
      "..         ...        ...\n",
      "815  35.258560 2002-03-26\n",
      "816  35.441621 2002-03-27\n",
      "817  35.543318 2002-03-28\n",
      "818  35.838249 2002-03-29\n",
      "819  35.685701 2002-03-30\n",
      "\n",
      "[820 rows x 2 columns]\n",
      "D\n",
      "                0         ds\n",
      "0       39.592101 2000-01-01\n",
      "1       39.342762 2000-01-02\n",
      "2       39.405096 2000-01-03\n",
      "3       38.781749 2000-01-04\n",
      "4       39.093423 2000-01-05\n",
      "...           ...        ...\n",
      "12993  844.801602 2035-07-29\n",
      "12994  848.572856 2035-07-30\n",
      "12995  847.544332 2035-07-31\n",
      "12996  849.383208 2035-08-01\n",
      "12997  857.736069 2035-08-02\n",
      "\n",
      "[12998 rows x 2 columns]\n",
      "D\n",
      "                0         ds\n",
      "0        7.690361 2000-01-01\n",
      "1        7.692155 2000-01-02\n",
      "2        7.691258 2000-01-03\n",
      "3        7.690361 2000-01-04\n",
      "4        7.689463 2000-01-05\n",
      "...           ...        ...\n",
      "11451  199.590410 2031-05-09\n",
      "11452  201.042022 2031-05-10\n",
      "11453  202.989745 2031-05-11\n",
      "11454  202.071005 2031-05-12\n",
      "11455  204.184111 2031-05-13\n",
      "\n",
      "[11456 rows x 2 columns]\n",
      "H\n",
      "             0                  ds\n",
      "0    10.438459 2000-01-01 00:00:00\n",
      "1    11.125112 2000-01-01 01:00:00\n",
      "2    10.863529 2000-01-01 02:00:00\n",
      "3    10.520203 2000-01-01 03:00:00\n",
      "4    10.487505 2000-01-01 04:00:00\n",
      "..         ...                 ...\n",
      "756  11.010669 2000-02-01 12:00:00\n",
      "757  11.027018 2000-02-01 13:00:00\n",
      "758  11.010669 2000-02-01 14:00:00\n",
      "759  11.010669 2000-02-01 15:00:00\n",
      "760  11.027018 2000-02-01 16:00:00\n",
      "\n",
      "[761 rows x 2 columns]\n",
      "D\n",
      "                0         ds\n",
      "0       23.925391 2000-01-01\n",
      "1       23.805100 2000-01-02\n",
      "2       23.897632 2000-01-03\n",
      "3       23.777340 2000-01-04\n",
      "4       23.573767 2000-01-05\n",
      "...           ...        ...\n",
      "14109  241.488538 2038-08-18\n",
      "14110  237.393945 2038-08-19\n",
      "14111  239.212231 2038-08-20\n",
      "14112  244.667031 2038-08-21\n",
      "14113  243.501123 2038-08-22\n",
      "\n",
      "[14114 rows x 2 columns]\n",
      "D\n",
      "             0         ds\n",
      "0     4.301017 2000-01-01\n",
      "1     4.294630 2000-01-02\n",
      "2     4.297823 2000-01-03\n",
      "3     4.294630 2000-01-04\n",
      "4     4.323371 2000-01-05\n",
      "...        ...        ...\n",
      "3924  4.428756 2010-09-29\n",
      "3925  4.431950 2010-09-30\n",
      "3926  4.435143 2010-10-01\n",
      "3927  4.435143 2010-10-02\n",
      "3928  4.435143 2010-10-03\n",
      "\n",
      "[3929 rows x 2 columns]\n",
      "D\n",
      "               0         ds\n",
      "0      33.086299 2000-01-01\n",
      "1      29.691666 2000-01-02\n",
      "2      27.280986 2000-01-03\n",
      "3      26.518424 2000-01-04\n",
      "4      27.490076 2000-01-05\n",
      "...          ...        ...\n",
      "1426  118.444106 2003-11-27\n",
      "1427  118.413356 2003-11-28\n",
      "1428  121.641947 2003-11-29\n",
      "1429  124.003428 2003-11-30\n",
      "1430  122.810386 2003-12-01\n",
      "\n",
      "[1431 rows x 2 columns]\n",
      "D\n",
      "              0         ds\n",
      "0     17.205042 2000-01-01\n",
      "1     17.269918 2000-01-02\n",
      "2     16.831233 2000-01-03\n",
      "3     15.515179 2000-01-04\n",
      "4     15.323641 2000-01-05\n",
      "...         ...        ...\n",
      "1666  26.825209 2004-07-24\n",
      "1667  26.902442 2004-07-25\n",
      "1668  27.118695 2004-07-26\n",
      "1669  27.739650 2004-07-27\n",
      "1670  28.196870 2004-07-28\n",
      "\n",
      "[1671 rows x 2 columns]\n",
      "D\n",
      "               0         ds\n",
      "0      35.375649 2000-01-01\n",
      "1      35.211674 2000-01-02\n",
      "2      35.211674 2000-01-03\n",
      "3      35.211674 2000-01-04\n",
      "4      35.047698 2000-01-05\n",
      "...          ...        ...\n",
      "1254  332.827155 2003-06-08\n",
      "1255  333.319082 2003-06-09\n",
      "1256  334.466910 2003-06-10\n",
      "1257  334.958837 2003-06-11\n",
      "1258  336.598591 2003-06-12\n",
      "\n",
      "[1259 rows x 2 columns]\n",
      "D\n",
      "               0         ds\n",
      "0      92.244120 2000-01-01\n",
      "1      91.758715 2000-01-02\n",
      "2      93.214726 2000-01-03\n",
      "3      93.214726 2000-01-04\n",
      "4      94.175462 2000-01-05\n",
      "...          ...        ...\n",
      "5454  147.038952 2014-12-07\n",
      "5455  148.007081 2014-12-08\n",
      "5456  150.133198 2014-12-09\n",
      "5457  150.133198 2014-12-10\n",
      "5458  148.500646 2014-12-11\n",
      "\n",
      "[5459 rows x 2 columns]\n",
      "D\n",
      "               0         ds\n",
      "0      12.067660 2000-01-01\n",
      "1      12.063401 2000-01-02\n",
      "2      12.061982 2000-01-03\n",
      "3      12.063401 2000-01-04\n",
      "4      12.054884 2000-01-05\n",
      "...          ...        ...\n",
      "14110  63.171297 2038-08-19\n",
      "14111  63.247609 2038-08-20\n",
      "14112  63.596462 2038-08-21\n",
      "14113  63.781792 2038-08-22\n",
      "14114  63.869003 2038-08-23\n",
      "\n",
      "[14115 rows x 2 columns]\n",
      "D\n",
      "               0         ds\n",
      "0      13.532622 2000-01-01\n",
      "1      13.556562 2000-01-02\n",
      "2      13.700203 2000-01-03\n",
      "3      13.700203 2000-01-04\n",
      "4      13.628383 2000-01-05\n",
      "...          ...        ...\n",
      "9545  113.022969 2026-02-18\n",
      "9546  113.053619 2026-02-19\n",
      "9547  113.160870 2026-02-20\n",
      "9548  113.666489 2026-02-21\n",
      "9549  114.309996 2026-02-22\n",
      "\n",
      "[9550 rows x 2 columns]\n",
      "D\n",
      "              0         ds\n",
      "0     21.020884 2000-01-01\n",
      "1     21.083967 2000-01-02\n",
      "2     21.159953 2000-01-03\n",
      "3     21.062461 2000-01-04\n",
      "4     21.065329 2000-01-05\n",
      "...         ...        ...\n",
      "8357  26.563541 2022-11-18\n",
      "8358  26.506193 2022-11-19\n",
      "8359  26.520530 2022-11-20\n",
      "8360  26.526265 2022-11-21\n",
      "8361  26.443111 2022-11-22\n",
      "\n",
      "[8362 rows x 2 columns]\n",
      "D\n",
      "              0         ds\n",
      "0     45.950354 2000-01-01\n",
      "1     45.380874 2000-01-02\n",
      "2     44.975911 2000-01-03\n",
      "3     45.254323 2000-01-04\n",
      "4     45.153082 2000-01-05\n",
      "...         ...        ...\n",
      "3204  49.253327 2008-10-09\n",
      "3205  49.310276 2008-10-10\n",
      "3206  49.746877 2008-10-11\n",
      "3207  49.778514 2008-10-12\n",
      "3208  49.576034 2008-10-13\n",
      "\n",
      "[3209 rows x 2 columns]\n",
      "D\n",
      "             0         ds\n",
      "0   135.265407 2000-01-01\n",
      "1   132.267911 2000-01-02\n",
      "2   126.565938 2000-01-03\n",
      "3   112.167402 2000-01-04\n",
      "4   115.537344 2000-01-05\n",
      "5   104.940770 2000-01-06\n",
      "6    99.630616 2000-01-07\n",
      "7    94.935073 2000-01-08\n",
      "8    89.900986 2000-01-09\n",
      "9    95.889196 2000-01-10\n",
      "10  100.138675 2000-01-11\n",
      "11   99.742012 2000-01-12\n",
      "12  108.660880 2000-01-13\n",
      "13  115.269512 2000-01-14\n",
      "14  102.517685 2000-01-15\n",
      "15   91.810200 2000-01-16\n",
      "16   87.887157 2000-01-17\n",
      "17   92.482445 2000-01-18\n",
      "18   85.789540 2000-01-19\n",
      "19   84.156876 2000-01-20\n",
      "20   84.642171 2000-01-21\n",
      "21   86.201218 2000-01-22\n",
      "22   91.370432 2000-01-23\n",
      "23   89.035495 2000-01-24\n",
      "W\n",
      "               0         ds\n",
      "0    7851.321687 2000-01-02\n",
      "1    7851.321687 2000-01-09\n",
      "2    7879.052297 2000-01-16\n",
      "3    7879.352943 2000-01-23\n",
      "4    7879.656753 2000-01-30\n",
      "..           ...        ...\n",
      "465  7889.734714 2008-11-30\n",
      "466  7892.296531 2008-12-07\n",
      "467  7139.266070 2008-12-14\n",
      "468  7886.924467 2008-12-21\n",
      "469  7139.266070 2008-12-28\n",
      "\n",
      "[470 rows x 2 columns]\n",
      "D\n",
      "                0         ds\n",
      "0      518.663076 2000-01-01\n",
      "1      518.778361 2000-01-02\n",
      "2      518.850413 2000-01-03\n",
      "3      518.864824 2000-01-04\n",
      "4      518.792771 2000-01-05\n",
      "...           ...        ...\n",
      "12269  163.443795 2033-08-04\n",
      "12270  163.443795 2033-08-05\n",
      "12271  162.737680 2033-08-06\n",
      "12272  162.838553 2033-08-07\n",
      "12273  162.939427 2033-08-08\n",
      "\n",
      "[12274 rows x 2 columns]\n",
      "D\n",
      "             0         ds\n",
      "0    17.473096 2000-01-01\n",
      "1    18.738883 2000-01-02\n",
      "2    18.377229 2000-01-03\n",
      "3    17.473096 2000-01-04\n",
      "4    16.388136 2000-01-05\n",
      "..         ...        ...\n",
      "834  18.558056 2002-04-14\n",
      "835  18.377229 2002-04-15\n",
      "836  17.653923 2002-04-16\n",
      "837  17.292270 2002-04-17\n",
      "838  17.292270 2002-04-18\n",
      "\n",
      "[839 rows x 2 columns]\n",
      "H\n",
      "               0                  ds\n",
      "0      16.037937 2000-01-01 00:00:00\n",
      "1      16.214932 2000-01-01 01:00:00\n",
      "2      16.407651 2000-01-01 02:00:00\n",
      "3      16.609200 2000-01-01 03:00:00\n",
      "4      16.804320 2000-01-01 04:00:00\n",
      "..           ...                 ...\n",
      "846  1640.452615 2000-02-05 06:00:00\n",
      "847  1644.554475 2000-02-05 07:00:00\n",
      "848  1653.457420 2000-02-05 08:00:00\n",
      "849  1655.043168 2000-02-05 09:00:00\n",
      "850  1652.226901 2000-02-05 10:00:00\n",
      "\n",
      "[851 rows x 2 columns]\n",
      "D\n",
      "              0         ds\n",
      "0    330.213104 2000-01-01\n",
      "1    486.830551 2000-01-02\n",
      "2    376.090942 2000-01-03\n",
      "3    339.705070 2000-01-04\n",
      "4    376.090942 2000-01-05\n",
      "..          ...        ...\n",
      "198  455.190662 2000-07-17\n",
      "199  464.682629 2000-07-18\n",
      "200  407.730830 2000-07-19\n",
      "201  515.306450 2000-07-20\n",
      "202  440.952713 2000-07-21\n",
      "\n",
      "[203 rows x 2 columns]\n",
      "W\n",
      "             0         ds\n",
      "0    65.017487 2000-01-02\n",
      "1    64.799034 2000-01-09\n",
      "2    64.580581 2000-01-16\n",
      "3    64.362129 2000-01-23\n",
      "4    64.143676 2000-01-30\n",
      "..         ...        ...\n",
      "440  64.580581 2008-06-08\n",
      "441  64.362129 2008-06-15\n",
      "442  64.143676 2008-06-22\n",
      "443  63.925223 2008-06-29\n",
      "444  63.706771 2008-07-06\n",
      "\n",
      "[445 rows x 2 columns]\n",
      "D\n",
      "             0         ds\n",
      "0   466.742240 2000-01-01\n",
      "1   440.854946 2000-01-02\n",
      "2   473.172039 2000-01-03\n",
      "3   470.158858 2000-01-04\n",
      "4   520.735738 2000-01-05\n",
      "5   525.904792 2000-01-06\n",
      "6   515.936503 2000-01-07\n",
      "7   508.649398 2000-01-08\n",
      "8   574.569542 2000-01-09\n",
      "9   665.229703 2000-01-10\n",
      "10  662.565328 2000-01-11\n",
      "11  656.244794 2000-01-12\n",
      "12  595.985394 2000-01-13\n",
      "13  585.823791 2000-01-14\n",
      "14  563.407748 2000-01-15\n",
      "15  560.226469 2000-01-16\n",
      "16  660.997802 2000-01-17\n",
      "17  725.535330 2000-01-18\n",
      "18  790.825102 2000-01-19\n",
      "19  690.406777 2000-01-20\n",
      "20  655.320248 2000-01-21\n",
      "21  709.607920 2000-01-22\n",
      "22  710.574491 2000-01-23\n",
      "23  750.393015 2000-01-24\n",
      "24  780.159201 2000-01-25\n",
      "25  876.517928 2000-01-26\n",
      "D\n",
      "              0         ds\n",
      "0   2103.367106 2000-01-01\n",
      "1   2061.346883 2000-01-02\n",
      "2   1989.134648 2000-01-03\n",
      "3   1918.686620 2000-01-04\n",
      "4   1863.073977 2000-01-05\n",
      "5   1753.131751 2000-01-06\n",
      "6   1675.506606 2000-01-07\n",
      "7   1589.421282 2000-01-08\n",
      "8   1516.126465 2000-01-09\n",
      "9   1457.266075 2000-01-10\n",
      "10  1422.543257 2000-01-11\n",
      "11  1391.348855 2000-01-12\n",
      "12  1360.074261 2000-01-13\n",
      "13  1339.304723 2000-01-14\n",
      "14  1338.903767 2000-01-15\n",
      "15  1304.581905 2000-01-16\n",
      "16  1259.233744 2000-01-17\n",
      "17  1242.112908 2000-01-18\n",
      "18  1236.098563 2000-01-19\n",
      "19  1226.916663 2000-01-20\n",
      "20  1214.005870 2000-01-21\n",
      "21  1200.854502 2000-01-22\n",
      "22  1194.639679 2000-01-23\n",
      "23  1193.677384 2000-01-24\n",
      "24  1179.884486 2000-01-25\n",
      "25  1183.092137 2000-01-26\n",
      "26  1187.221987 2000-01-27\n",
      "27  1167.655318 2000-01-28\n",
      "28  1168.016179 2000-01-29\n",
      "29  1167.976083 2000-01-30\n",
      "30  1169.579908 2000-01-31\n",
      "31  1163.525468 2000-02-01\n",
      "32  1158.393227 2000-02-02\n",
      "33  1160.638582 2000-02-03\n",
      "34  1169.379430 2000-02-04\n",
      "Q\n",
      "              0         ds\n",
      "0   8455.974784 2000-03-31\n",
      "1   8507.531544 2000-06-30\n",
      "2   8212.228719 2000-09-30\n",
      "3   7183.645846 2000-12-31\n",
      "4   6588.446029 2001-03-31\n",
      "5   3465.688845 2001-06-30\n",
      "6   3303.616854 2001-09-30\n",
      "7   2953.439260 2001-12-31\n",
      "8   2662.475371 2002-03-31\n",
      "9   2720.157686 2002-06-30\n",
      "10  2686.977593 2002-09-30\n",
      "11  2535.880556 2002-12-31\n",
      "12  2421.536852 2003-03-31\n",
      "13  2586.926852 2003-06-30\n",
      "14  2506.273704 2003-09-30\n",
      "15  2364.620231 2003-12-31\n",
      "16  2372.277176 2004-03-31\n",
      "17  2549.407824 2004-06-30\n",
      "18  2615.768010 2004-09-30\n",
      "19  2559.617083 2004-12-31\n",
      "20  2478.198241 2005-03-31\n",
      "21  2692.847917 2005-06-30\n",
      "22  2803.873612 2005-09-30\n",
      "23  2726.283241 2005-12-31\n",
      "24  2675.492176 2006-03-31\n",
      "25  2858.237918 2006-06-30\n",
      "26  2909.028983 2006-09-30\n",
      "27  2866.660556 2006-12-31\n",
      "28  2720.412917 2007-03-31\n",
      "29  2911.326066 2007-06-30\n",
      "30  2938.635834 2007-09-30\n",
      "31  2837.308936 2007-12-31\n",
      "32  2660.433519 2008-03-31\n",
      "33  2831.949075 2008-06-30\n",
      "34  2918.217316 2008-09-30\n",
      "D\n",
      "               0         ds\n",
      "0    7421.997232 2000-01-01\n",
      "1    6933.706249 2000-01-02\n",
      "2    6601.826435 2000-01-03\n",
      "3    7511.837309 2000-01-04\n",
      "4    7581.693050 2000-01-05\n",
      "5    8705.238747 2000-01-06\n",
      "6    8662.944803 2000-01-07\n",
      "7    9216.945061 2000-01-08\n",
      "8    9698.634221 2000-01-09\n",
      "9    8792.932418 2000-01-10\n",
      "10   8400.676820 2000-01-11\n",
      "11   9156.504235 2000-01-12\n",
      "12   9447.277132 2000-01-13\n",
      "13   9637.656793 2000-01-14\n",
      "14  13126.167315 2000-01-15\n",
      "15  14969.701959 2000-01-16\n",
      "16  15974.675014 2000-01-17\n",
      "17  12799.409604 2000-01-18\n",
      "18  13489.104966 2000-01-19\n",
      "19  14967.994591 2000-01-20\n",
      "20  15316.899303 2000-01-21\n",
      "21  16245.105842 2000-01-22\n",
      "22  16503.536312 2000-01-23\n",
      "23  15289.841586 2000-01-24\n",
      "Q\n",
      "                0         ds\n",
      "0     1589.284598 2000-03-31\n",
      "1     2288.378240 2000-06-30\n",
      "2     1682.497084 2000-09-30\n",
      "3     1775.709569 2000-12-31\n",
      "4     1799.012691 2001-03-31\n",
      "..            ...        ...\n",
      "129  20523.070753 2032-06-30\n",
      "130  17039.254100 2032-09-30\n",
      "131  17400.452482 2032-12-31\n",
      "132  17272.285315 2033-03-31\n",
      "133  20907.572256 2033-06-30\n",
      "\n",
      "[134 rows x 2 columns]\n",
      "Q\n",
      "              0         ds\n",
      "0   1126.989102 2000-03-31\n",
      "1   1366.077249 2000-06-30\n",
      "2   1556.261002 2000-09-30\n",
      "3   1333.474320 2000-12-31\n",
      "4   1262.834640 2001-03-31\n",
      "..          ...        ...\n",
      "77  4275.345292 2019-06-30\n",
      "78  5367.543418 2019-09-30\n",
      "79  5086.614845 2019-12-31\n",
      "80  4456.834931 2020-03-31\n",
      "81  4829.051705 2020-06-30\n",
      "\n",
      "[82 rows x 2 columns]\n",
      "D\n",
      "               0         ds\n",
      "0    5874.705975 2000-01-01\n",
      "1    5988.435067 2000-01-02\n",
      "2    6274.731244 2000-01-03\n",
      "3    6629.732656 2000-01-04\n",
      "4    8156.874620 2000-01-05\n",
      "5    8401.903801 2000-01-06\n",
      "6    7645.166798 2000-01-07\n",
      "7    7164.083969 2000-01-08\n",
      "8    7135.578606 2000-01-09\n",
      "9    9103.954361 2000-01-10\n",
      "10  10321.118768 2000-01-11\n",
      "11  11784.627988 2000-01-12\n",
      "12  13507.755290 2000-01-13\n",
      "13  13844.864105 2000-01-14\n",
      "14  10884.881769 2000-01-15\n",
      "15   9858.527880 2000-01-16\n",
      "16   9618.059557 2000-01-17\n",
      "17  10335.459158 2000-01-18\n",
      "18   8859.685322 2000-01-19\n",
      "19   9103.954361 2000-01-20\n",
      "20   8613.121236 2000-01-21\n",
      "21   9921.853642 2000-01-22\n",
      "22   9795.830699 2000-01-23\n",
      "D\n",
      "                0         ds\n",
      "0      290.119563 2000-01-01\n",
      "1      290.603970 2000-01-02\n",
      "2      288.804747 2000-01-03\n",
      "3      289.946561 2000-01-04\n",
      "4      291.918787 2000-01-05\n",
      "...           ...        ...\n",
      "3707  7713.506238 2010-02-24\n",
      "3708  7650.810235 2010-02-25\n",
      "3709  7602.750219 2010-02-26\n",
      "3710  7525.695033 2010-02-27\n",
      "3711  7541.888040 2010-02-28\n",
      "\n",
      "[3712 rows x 2 columns]\n",
      "Q\n",
      "               0         ds\n",
      "0    9123.917377 2000-03-31\n",
      "1    8303.690189 2000-06-30\n",
      "2    7714.120828 2000-09-30\n",
      "3    8064.084428 2000-12-31\n",
      "4    8738.162045 2001-03-31\n",
      "5    8021.333193 2001-06-30\n",
      "6    7430.769618 2001-09-30\n",
      "7    7366.145657 2001-12-31\n",
      "8    7590.838196 2002-03-31\n",
      "9    7593.820841 2002-06-30\n",
      "10   7957.703448 2002-09-30\n",
      "11   8186.372846 2002-12-31\n",
      "12   9721.440456 2003-03-31\n",
      "13   9886.480108 2003-06-30\n",
      "14   9686.642939 2003-09-30\n",
      "15   9941.161921 2003-12-31\n",
      "16  10356.743696 2004-03-31\n",
      "17   9739.336322 2004-06-30\n",
      "18   9827.821436 2004-09-30\n",
      "19  10390.546998 2004-12-31\n",
      "20  11514.009692 2005-03-31\n",
      "21  11015.908091 2005-06-30\n",
      "22  10640.094906 2005-09-30\n",
      "23  11027.838668 2005-12-31\n",
      "24  11247.560133 2006-03-31\n",
      "25  10683.840356 2006-06-30\n",
      "26  10565.528798 2006-09-30\n",
      "27  11409.617141 2006-12-31\n",
      "28  12606.651728 2007-03-31\n",
      "29  12008.134435 2007-06-30\n",
      "30  11986.261710 2007-09-30\n",
      "31  12570.859996 2007-12-31\n",
      "32  13324.474795 2008-03-31\n",
      "33  12966.557476 2008-06-30\n",
      "34  12965.563261 2008-09-30\n",
      "D\n",
      "             0         ds\n",
      "0   309.609658 2000-01-01\n",
      "1   323.395626 2000-01-02\n",
      "2   340.470294 2000-01-03\n",
      "3   354.023728 2000-01-04\n",
      "4   379.801827 2000-01-05\n",
      "5   374.752508 2000-01-06\n",
      "6   373.722713 2000-01-07\n",
      "7   431.424463 2000-01-08\n",
      "8   414.250136 2000-01-09\n",
      "9   377.476483 2000-01-10\n",
      "10  365.251817 2000-01-11\n",
      "11  387.973750 2000-01-12\n",
      "12  363.966234 2000-01-13\n",
      "13  350.236739 2000-01-14\n",
      "14  365.584009 2000-01-15\n",
      "15  396.079234 2000-01-16\n",
      "16  399.367935 2000-01-17\n",
      "17  408.636092 2000-01-18\n",
      "18  435.443986 2000-01-19\n",
      "19  451.322763 2000-01-20\n",
      "20  397.142249 2000-01-21\n",
      "21  375.051481 2000-01-22\n",
      "22  407.573077 2000-01-23\n",
      "23  443.881662 2000-01-24\n",
      "24  411.625820 2000-01-25\n",
      "25  444.346731 2000-01-26\n",
      "26  462.849825 2000-01-27\n",
      "27  400.696703 2000-01-28\n",
      "28  397.507660 2000-01-29\n",
      "29  384.136932 2000-01-30\n",
      "30  389.116490 2000-01-31\n",
      "31  370.490485 2000-02-01\n",
      "32  382.007581 2000-02-02\n",
      "33  398.454407 2000-02-03\n",
      "34  410.695682 2000-02-04\n",
      "35  407.054858 2000-02-05\n",
      "36  443.386696 2000-02-06\n",
      "37  444.565978 2000-02-07\n",
      "38  436.430596 2000-02-08\n",
      "M\n",
      "                0         ds\n",
      "0     9742.674644 2000-01-31\n",
      "1     9907.194277 2000-02-29\n",
      "2    10032.178185 2000-03-31\n",
      "3    10061.511143 2000-04-30\n",
      "4    10037.279569 2000-05-31\n",
      "..            ...        ...\n",
      "247  13496.017904 2020-08-31\n",
      "248  13603.146967 2020-09-30\n",
      "249  13567.437280 2020-10-31\n",
      "250  13734.507605 2020-11-30\n",
      "251  13737.058297 2020-12-31\n",
      "\n",
      "[252 rows x 2 columns]\n",
      "D\n",
      "              0         ds\n",
      "0   2849.147411 2000-01-01\n",
      "1   2973.340795 2000-01-02\n",
      "2   3201.788258 2000-01-03\n",
      "3   3324.520252 2000-01-04\n",
      "4   3627.779326 2000-01-05\n",
      "5   3695.713322 2000-01-06\n",
      "6   3627.680249 2000-01-07\n",
      "7   3918.265686 2000-01-08\n",
      "8   3980.857764 2000-01-09\n",
      "9   3908.679958 2000-01-10\n",
      "10  3575.623389 2000-01-11\n",
      "11  3758.866838 2000-01-12\n",
      "12  3608.252843 2000-01-13\n",
      "13  3452.899651 2000-01-14\n",
      "14  3468.826326 2000-01-15\n",
      "15  3683.766252 2000-01-16\n",
      "16  3945.090862 2000-01-17\n",
      "17  3975.169076 2000-01-18\n",
      "18  4187.285299 2000-01-19\n",
      "19  4443.878969 2000-01-20\n",
      "20  4363.593338 2000-01-21\n",
      "21  3847.227268 2000-01-22\n",
      "22  3827.345759 2000-01-23\n",
      "23  4099.445025 2000-01-24\n",
      "24  4121.275054 2000-01-25\n",
      "25  4133.172586 2000-01-26\n",
      "26  4559.568219 2000-01-27\n",
      "27  4309.051289 2000-01-28\n",
      "28  4079.613054 2000-01-29\n",
      "29  4122.472238 2000-01-30\n",
      "30  3977.968010 2000-01-31\n",
      "31  3965.393450 2000-02-01\n",
      "32  3869.197657 2000-02-02\n",
      "33  4014.833018 2000-02-03\n",
      "34  4269.461655 2000-02-04\n",
      "35  4322.781751 2000-02-05\n",
      "36  4511.317578 2000-02-06\n",
      "37  4776.423639 2000-02-07\n",
      "38  4658.777613 2000-02-08\n",
      "D\n",
      "              0         ds\n",
      "0   2174.560252 2000-01-01\n",
      "1   2289.969935 2000-01-02\n",
      "2   2484.128006 2000-01-03\n",
      "3   2736.266141 2000-01-04\n",
      "4   3015.576969 2000-01-05\n",
      "5   3148.198937 2000-01-06\n",
      "6   3386.121646 2000-01-07\n",
      "7   3513.265389 2000-01-08\n",
      "8   3839.337714 2000-01-09\n",
      "9   3910.904124 2000-01-10\n",
      "10  3837.721332 2000-01-11\n",
      "11  4138.368404 2000-01-12\n",
      "12  4213.831606 2000-01-13\n",
      "13  4136.402534 2000-01-14\n",
      "14  3781.838197 2000-01-15\n",
      "15  3977.455381 2000-01-16\n",
      "16  3816.332665 2000-01-17\n",
      "17  3650.518072 2000-01-18\n",
      "18  3666.306194 2000-01-19\n",
      "19  3891.883239 2000-01-20\n",
      "20  4169.001030 2000-01-21\n",
      "21  4203.329491 2000-01-22\n",
      "22  4427.840597 2000-01-23\n",
      "23  4700.546101 2000-01-24\n",
      "24  4615.672935 2000-01-25\n",
      "25  4068.182472 2000-01-26\n",
      "26  4045.675443 2000-01-27\n",
      "27  4335.497124 2000-01-28\n",
      "28  4354.142310 2000-01-29\n",
      "29  4369.301353 2000-01-30\n",
      "30  4820.726296 2000-01-31\n",
      "31  4558.557855 2000-02-01\n",
      "32  4314.370573 2000-02-02\n",
      "33  4359.201149 2000-02-03\n",
      "34  4204.841026 2000-02-04\n",
      "35  4188.607308 2000-02-05\n",
      "36  4092.768954 2000-02-06\n",
      "37  4246.613582 2000-02-07\n",
      "38  4513.535060 2000-02-08\n",
      "39  4562.847820 2000-02-09\n",
      "40  4771.911556 2000-02-10\n",
      "41  5054.193032 2000-02-11\n",
      "42  4929.128743 2000-02-12\n"
     ]
    }
   ],
   "source": [
    "for dataset, df in datasets.items():\n",
    "    idx_ts = int(dataset.split('.')[0].split('_')[-1])-1\n",
    "    freq = mapping(frequencies.iloc[\n",
    "        idx_ts][[col for col in frequencies.columns if usecase in col][0]])\n",
    "    df_ts = df.copy(deep = True)\n",
    "    len_ts = df_ts.shape[0]\n",
    "    df_ts['ds'] = pd.date_range(start = '2000-01-01', periods = len_ts, freq = freq)\n",
    "    df_ts.columns = ['y', 'ds']\n",
    "    datasets.update({dataset: df_ts})\n",
    "    df_ts.to_csv(f'../../LIBRA_updated/{dataset}', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "06db8b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>ds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2174.560252</td>\n",
       "      <td>2000-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2289.969935</td>\n",
       "      <td>2000-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2484.128006</td>\n",
       "      <td>2000-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2736.266141</td>\n",
       "      <td>2000-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3015.576969</td>\n",
       "      <td>2000-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3148.198937</td>\n",
       "      <td>2000-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3386.121646</td>\n",
       "      <td>2000-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3513.265389</td>\n",
       "      <td>2000-01-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3839.337714</td>\n",
       "      <td>2000-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>3910.904124</td>\n",
       "      <td>2000-01-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3837.721332</td>\n",
       "      <td>2000-01-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4138.368404</td>\n",
       "      <td>2000-01-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>4213.831606</td>\n",
       "      <td>2000-01-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>4136.402534</td>\n",
       "      <td>2000-01-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3781.838197</td>\n",
       "      <td>2000-01-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3977.455381</td>\n",
       "      <td>2000-01-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3816.332665</td>\n",
       "      <td>2000-01-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3650.518072</td>\n",
       "      <td>2000-01-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3666.306194</td>\n",
       "      <td>2000-01-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3891.883239</td>\n",
       "      <td>2000-01-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>4169.001030</td>\n",
       "      <td>2000-01-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>4203.329491</td>\n",
       "      <td>2000-01-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4427.840597</td>\n",
       "      <td>2000-01-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4700.546101</td>\n",
       "      <td>2000-01-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>4615.672935</td>\n",
       "      <td>2000-01-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>4068.182472</td>\n",
       "      <td>2000-01-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>4045.675443</td>\n",
       "      <td>2000-01-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>4335.497124</td>\n",
       "      <td>2000-01-28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>4354.142310</td>\n",
       "      <td>2000-01-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4369.301353</td>\n",
       "      <td>2000-01-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4820.726296</td>\n",
       "      <td>2000-01-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>4558.557855</td>\n",
       "      <td>2000-02-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>4314.370573</td>\n",
       "      <td>2000-02-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>4359.201149</td>\n",
       "      <td>2000-02-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>4204.841026</td>\n",
       "      <td>2000-02-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>4188.607308</td>\n",
       "      <td>2000-02-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>4092.768954</td>\n",
       "      <td>2000-02-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>4246.613582</td>\n",
       "      <td>2000-02-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>4513.535060</td>\n",
       "      <td>2000-02-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>4562.847820</td>\n",
       "      <td>2000-02-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4771.911556</td>\n",
       "      <td>2000-02-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>5054.193032</td>\n",
       "      <td>2000-02-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4929.128743</td>\n",
       "      <td>2000-02-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              y         ds\n",
       "0   2174.560252 2000-01-01\n",
       "1   2289.969935 2000-01-02\n",
       "2   2484.128006 2000-01-03\n",
       "3   2736.266141 2000-01-04\n",
       "4   3015.576969 2000-01-05\n",
       "5   3148.198937 2000-01-06\n",
       "6   3386.121646 2000-01-07\n",
       "7   3513.265389 2000-01-08\n",
       "8   3839.337714 2000-01-09\n",
       "9   3910.904124 2000-01-10\n",
       "10  3837.721332 2000-01-11\n",
       "11  4138.368404 2000-01-12\n",
       "12  4213.831606 2000-01-13\n",
       "13  4136.402534 2000-01-14\n",
       "14  3781.838197 2000-01-15\n",
       "15  3977.455381 2000-01-16\n",
       "16  3816.332665 2000-01-17\n",
       "17  3650.518072 2000-01-18\n",
       "18  3666.306194 2000-01-19\n",
       "19  3891.883239 2000-01-20\n",
       "20  4169.001030 2000-01-21\n",
       "21  4203.329491 2000-01-22\n",
       "22  4427.840597 2000-01-23\n",
       "23  4700.546101 2000-01-24\n",
       "24  4615.672935 2000-01-25\n",
       "25  4068.182472 2000-01-26\n",
       "26  4045.675443 2000-01-27\n",
       "27  4335.497124 2000-01-28\n",
       "28  4354.142310 2000-01-29\n",
       "29  4369.301353 2000-01-30\n",
       "30  4820.726296 2000-01-31\n",
       "31  4558.557855 2000-02-01\n",
       "32  4314.370573 2000-02-02\n",
       "33  4359.201149 2000-02-03\n",
       "34  4204.841026 2000-02-04\n",
       "35  4188.607308 2000-02-05\n",
       "36  4092.768954 2000-02-06\n",
       "37  4246.613582 2000-02-07\n",
       "38  4513.535060 2000-02-08\n",
       "39  4562.847820 2000-02-09\n",
       "40  4771.911556 2000-02-10\n",
       "41  5054.193032 2000-02-11\n",
       "42  4929.128743 2000-02-12"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da0f6af7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'finance_33.csv':                y         ds\n",
       " 0    2854.123802 2000-01-31\n",
       " 1    2862.026398 2000-02-29\n",
       " 2    2862.026398 2000-03-31\n",
       " 3    2877.831590 2000-04-30\n",
       " 4    2885.734186 2000-05-31\n",
       " ..           ...        ...\n",
       " 319  1676.636996 2026-08-31\n",
       " 320  1668.734400 2026-09-30\n",
       " 321  1660.831804 2026-10-31\n",
       " 322  1652.929208 2026-11-30\n",
       " 323  1668.734400 2026-12-31\n",
       " \n",
       " [324 rows x 2 columns],\n",
       " 'finance_27.csv':                y         ds\n",
       " 0     111.314362 2000-01-01\n",
       " 1     111.681110 2000-01-02\n",
       " 2     109.629995 2000-01-03\n",
       " 3     109.049671 2000-01-04\n",
       " 4     111.845929 2000-01-05\n",
       " ...          ...        ...\n",
       " 4206  557.732206 2011-07-08\n",
       " 4207  553.035318 2011-07-09\n",
       " 4208  553.635142 2011-07-10\n",
       " 4209  556.589981 2011-07-11\n",
       " 4210  554.253337 2011-07-12\n",
       " \n",
       " [4211 rows x 2 columns],\n",
       " 'finance_26.csv':                 y         ds\n",
       " 0     3694.299157 2000-01-01\n",
       " 1     3757.561279 2000-01-02\n",
       " 2     3846.590277 2000-01-03\n",
       " 3     3810.872056 2000-01-04\n",
       " 4     3762.803506 2000-01-05\n",
       " ...           ...        ...\n",
       " 4205  3640.988380 2011-07-07\n",
       " 4206  3723.086977 2011-07-08\n",
       " 4207  3693.410644 2011-07-09\n",
       " 4208  3789.547746 2011-07-10\n",
       " 4209  3781.462278 2011-07-11\n",
       " \n",
       " [4210 rows x 2 columns],\n",
       " 'finance_32.csv':                y         ds\n",
       " 0     994.064991 2000-01-31\n",
       " 1     994.064991 2000-02-29\n",
       " 2    1008.736841 2000-03-31\n",
       " 3    1016.072766 2000-04-30\n",
       " 4    1016.072766 2000-05-31\n",
       " ..           ...        ...\n",
       " 319  1815.688566 2026-08-31\n",
       " 320  1808.352641 2026-09-30\n",
       " 321  1830.360416 2026-10-31\n",
       " 322  1823.024491 2026-11-30\n",
       " 323  1830.360416 2026-12-31\n",
       " \n",
       " [324 rows x 2 columns],\n",
       " 'finance_24.csv':                 y         ds\n",
       " 0     1313.121294 2000-01-01\n",
       " 1     1313.121294 2000-01-02\n",
       " 2     1313.121294 2000-01-03\n",
       " 3     1323.318707 2000-01-04\n",
       " 4     1323.318707 2000-01-05\n",
       " ..            ...        ...\n",
       " 547  13300.180250 2001-07-01\n",
       " 548  13300.180250 2001-07-02\n",
       " 549  13300.180250 2001-07-03\n",
       " 550  13300.180250 2001-07-04\n",
       " 551  13300.180250 2001-07-05\n",
       " \n",
       " [552 rows x 2 columns],\n",
       " 'finance_30.csv':                y         ds\n",
       " 0    4072.143310 2000-01-31\n",
       " 1    4182.706782 2000-02-29\n",
       " 2    4230.091128 2000-03-31\n",
       " 3    4024.758964 2000-04-30\n",
       " 4    3929.990273 2000-05-31\n",
       " ..           ...        ...\n",
       " 319  7704.943133 2026-08-31\n",
       " 320  7768.122260 2026-09-30\n",
       " 321  7926.070079 2026-10-31\n",
       " 322  8052.428333 2026-11-30\n",
       " 323  8068.223115 2026-12-31\n",
       " \n",
       " [324 rows x 2 columns],\n",
       " 'finance_18.csv':               y         ds\n",
       " 0   6147.079672 2000-01-01\n",
       " 1   6266.143415 2000-01-02\n",
       " 2   6384.943451 2000-01-03\n",
       " 3   6332.729451 2000-01-04\n",
       " 4   6631.179930 2000-01-05\n",
       " 5   6694.008140 2000-01-06\n",
       " 6   6507.105753 2000-01-07\n",
       " 7   6850.584214 2000-01-08\n",
       " 8   6854.342040 2000-01-09\n",
       " 9   6733.366421 2000-01-10\n",
       " 10  6163.363584 2000-01-11\n",
       " 11  6398.656219 2000-01-12\n",
       " 12  6179.911203 2000-01-13\n",
       " 13  5869.593906 2000-01-14\n",
       " 14  5825.818532 2000-01-15\n",
       " 15  6008.963093 2000-01-16\n",
       " 16  6299.897921 2000-01-17\n",
       " 17  6343.673295 2000-01-18\n",
       " 18  6681.482054 2000-01-19\n",
       " 19  7091.546551 2000-01-20\n",
       " 20  6979.339192 2000-01-21\n",
       " 21  6217.093900 2000-01-22\n",
       " 22  6268.055292 2000-01-23\n",
       " 23  6613.709337 2000-01-24\n",
       " 24  6726.510037 2000-01-25\n",
       " 25  6936.223086 2000-01-26\n",
       " 26  7440.628788 2000-01-27\n",
       " 27  6787.228590 2000-01-28\n",
       " 28  6300.227555 2000-01-29\n",
       " 29  6150.244157 2000-01-30\n",
       " 30  5561.584045 2000-01-31\n",
       " 31  5443.245497 2000-02-01\n",
       " 32  5361.430378 2000-02-02\n",
       " 33  5494.404669 2000-02-03\n",
       " 34  5880.339969 2000-02-04\n",
       " 35  5949.892709 2000-02-05\n",
       " 36  6111.347364 2000-02-06\n",
       " 37  6377.823360 2000-02-07\n",
       " 38  6292.250416 2000-02-08,\n",
       " 'finance_19.csv':               y         ds\n",
       " 0   5738.044421 2000-01-01\n",
       " 1   5748.203368 2000-01-02\n",
       " 2   5754.045852 2000-01-03\n",
       " 3   5723.525411 2000-01-04\n",
       " 4   5645.044277 2000-01-05\n",
       " 5   5566.563143 2000-01-06\n",
       " 6   5525.840154 2000-01-07\n",
       " 7   5460.439209 2000-01-08\n",
       " 8   5432.840010 2000-01-09\n",
       " 9   5249.717364 2000-01-10\n",
       " 10  5100.036401 2000-01-11\n",
       " 11  5406.679632 2000-01-12\n",
       " 12  5485.160766 2000-01-13\n",
       " 13  5525.840154 2000-01-14\n",
       " 14  5560.720658 2000-01-15\n",
       " 15  5700.242675 2000-01-16\n",
       " 16  5572.362026 2000-01-17\n",
       " 17  5861.565006 2000-01-18\n",
       " 18  5909.525699 2000-01-19\n",
       " 19  5963.328877 2000-01-20\n",
       " 20  5976.409066 2000-01-21\n",
       " 21  5820.885618 2000-01-22\n",
       " 22  5924.088310 2000-01-23\n",
       " 23  5916.807004 2000-01-24\n",
       " 24  5736.605600 2000-01-25\n",
       " 25  5653.764403 2000-01-26\n",
       " 26  5348.559992 2000-01-27\n",
       " 27  4838.432620 2000-01-28\n",
       " 28  4688.708056 2000-01-29\n",
       " 29  4717.789676 2000-01-30\n",
       " 30  4947.434195 2000-01-31\n",
       " 31  4687.269235 2000-02-01\n",
       " 32  4748.310117 2000-02-02\n",
       " 33  4646.589847 2000-02-03\n",
       " 34  4646.589847 2000-02-04\n",
       " 35  4530.306967 2000-02-05\n",
       " 36  4236.743924 2000-02-06\n",
       " 37  4230.901440 2000-02-07\n",
       " 38  4246.902871 2000-02-08\n",
       " 39  4117.539802 2000-02-09\n",
       " 40  4166.982916 2000-02-10\n",
       " 41  4521.586841 2000-02-11,\n",
       " 'finance_31.csv':                 y         ds\n",
       " 0     7997.749506 2000-01-31\n",
       " 1     8016.064157 2000-02-29\n",
       " 2     8052.693459 2000-03-31\n",
       " 3     8144.266714 2000-04-30\n",
       " 4     8199.210667 2000-05-31\n",
       " ..            ...        ...\n",
       " 319  13382.256903 2026-08-31\n",
       " 320  13363.942252 2026-09-30\n",
       " 321  13455.515507 2026-10-31\n",
       " 322  13437.200856 2026-11-30\n",
       " 323  13418.886205 2026-12-31\n",
       " \n",
       " [324 rows x 2 columns],\n",
       " 'finance_25.csv':                  y         ds\n",
       " 0      1036.385787 2000-01-01\n",
       " 1       930.588031 2000-01-02\n",
       " 2       861.718869 2000-01-03\n",
       " 3       863.367241 2000-01-04\n",
       " 4       927.537193 2000-01-05\n",
       " ...            ...        ...\n",
       " 4203  11923.498774 2011-07-05\n",
       " 4204  11896.508151 2011-07-06\n",
       " 4205  11852.956820 2011-07-07\n",
       " 4206  11808.101989 2011-07-08\n",
       " 4207  12019.957406 2011-07-09\n",
       " \n",
       " [4208 rows x 2 columns],\n",
       " 'finance_21.csv':                y         ds\n",
       " 0   11338.747712 2000-01-01\n",
       " 1   11743.262665 2000-01-02\n",
       " 2   12312.811040 2000-01-03\n",
       " 3   12211.105973 2000-01-04\n",
       " 4   11779.469669 2000-01-05\n",
       " 5   12649.590418 2000-01-06\n",
       " 6   10784.997523 2000-01-07\n",
       " 7   10728.517310 2000-01-08\n",
       " 8   10667.494269 2000-01-09\n",
       " 9   11146.592938 2000-01-10\n",
       " 10  11361.326236 2000-01-11\n",
       " 11  11092.350236 2000-01-12\n",
       " 12  10771.436848 2000-01-13\n",
       " 13   9702.380987 2000-01-14\n",
       " 14   8904.606442 2000-01-15\n",
       " 15   8793.815722 2000-01-16\n",
       " 16   9105.711261 2000-01-17\n",
       " 17   9008.549020 2000-01-18\n",
       " 18   8906.843953 2000-01-19\n",
       " 19   8418.659631 2000-01-20\n",
       " 20   8337.295578 2000-01-21\n",
       " 21   8217.487009 2000-01-22\n",
       " 22   8339.533089 2000-01-23\n",
       " 23   8599.491241 2000-01-24\n",
       " 24   8662.751792 2000-01-25\n",
       " 25   7932.712821 2000-01-26\n",
       " 26   6893.083627 2000-01-27\n",
       " 27   6474.940194 2000-01-28\n",
       " 28   5826.333081 2000-01-29\n",
       " 29   5885.050806 2000-01-30\n",
       " 30   5620.617632 2000-01-31\n",
       " 31   4938.108829 2000-02-01\n",
       " 32   4908.682163 2000-02-02\n",
       " 33   5069.172758 2000-02-03\n",
       " 34   4840.878785 2000-02-04\n",
       " 35   4278.110747 2000-02-05\n",
       " 36   3972.995546 2000-02-06\n",
       " 37   3778.671065 2000-02-07\n",
       " 38   4782.161059 2000-02-08\n",
       " 39   5665.842485 2000-02-09\n",
       " 40   6070.425241 2000-02-10\n",
       " 41   5914.477472 2000-02-11\n",
       " 42   5281.600742 2000-02-12\n",
       " 43   5362.964795 2000-02-13,\n",
       " 'finance_35.csv':                y         ds\n",
       " 0     368.883734 2000-01-31\n",
       " 1     364.674112 2000-02-29\n",
       " 2     368.883734 2000-03-31\n",
       " 3     419.980302 2000-04-30\n",
       " 4     364.674112 2000-05-31\n",
       " ..           ...        ...\n",
       " 95  18235.880404 2007-12-31\n",
       " 96  21142.245336 2008-01-31\n",
       " 97  19234.768935 2008-02-29\n",
       " 98  18803.303149 2008-03-31\n",
       " 99  21889.029895 2008-04-30\n",
       " \n",
       " [100 rows x 2 columns],\n",
       " 'finance_34.csv':                 y         ds\n",
       " 0     2326.958954 2000-01-31\n",
       " 1     2437.347549 2000-02-29\n",
       " 2     2437.347549 2000-03-31\n",
       " 3     2437.347549 2000-04-30\n",
       " 4     2437.347549 2000-05-31\n",
       " ..            ...        ...\n",
       " 246  11489.212350 2020-07-31\n",
       " 247  11489.212350 2020-08-31\n",
       " 248  11709.989541 2020-09-30\n",
       " 249  11709.989541 2020-10-31\n",
       " 250  11709.989541 2020-11-30\n",
       " \n",
       " [251 rows x 2 columns],\n",
       " 'finance_20.csv':               y         ds\n",
       " 0   7053.806645 2000-01-01\n",
       " 1   7162.719618 2000-01-02\n",
       " 2   7266.040399 2000-01-03\n",
       " 3   7418.747637 2000-01-04\n",
       " 4   7063.913015 2000-01-05\n",
       " 5   7215.508553 2000-01-06\n",
       " 6   6874.115401 2000-01-07\n",
       " 7   7283.996048 2000-01-08\n",
       " 8   6903.322808 2000-01-09\n",
       " 9   6886.478859 2000-01-10\n",
       " 10  5496.280399 2000-01-11\n",
       " 11  5479.436450 2000-01-12\n",
       " 12  5090.913930 2000-01-13\n",
       " 13  4860.724528 2000-01-14\n",
       " 14  4859.579139 2000-01-15\n",
       " 15  5099.908599 2000-01-16\n",
       " 16  5147.071655 2000-01-17\n",
       " 17  5126.858917 2000-01-18\n",
       " 18  4852.841560 2000-01-19\n",
       " 19  4636.127316 2000-01-20\n",
       " 20  4577.746190 2000-01-21\n",
       " 21  4614.802877 2000-01-22\n",
       " 22  4600.182329 2000-01-23\n",
       " 23  5011.174677 2000-01-24\n",
       " 24  5188.608833 2000-01-25\n",
       " 25  5048.231364 2000-01-26\n",
       " 26  5048.231364 2000-01-27\n",
       " 27  5094.282720 2000-01-28\n",
       " 28  5131.339407 2000-01-29\n",
       " 29  5156.032636 2000-01-30\n",
       " 30  6296.940656 2000-01-31\n",
       " 31  6295.828955 2000-02-01\n",
       " 32  6209.352122 2000-02-02\n",
       " 33  5131.339407 2000-02-03\n",
       " 34  5613.076339 2000-02-04\n",
       " 35  5065.075313 2000-02-05\n",
       " 36  5081.919262 2000-02-06\n",
       " 37  4949.424761 2000-02-07\n",
       " 38  4659.708844 2000-02-08\n",
       " 39  4724.827550 2000-02-09\n",
       " 40  3846.718817 2000-02-10\n",
       " 41  3530.052582 2000-02-11\n",
       " 42  3421.105922 2000-02-12\n",
       " 43  3409.887852 2000-02-13\n",
       " 44  4084.757500 2000-02-14\n",
       " 45  3665.915872 2000-02-15\n",
       " 46  3747.878526 2000-02-16,\n",
       " 'finance_36.csv':                y         ds\n",
       " 0    1387.314249 2000-01-31\n",
       " 1    1202.042049 2000-02-29\n",
       " 2    1278.633185 2000-03-31\n",
       " 3    1155.090049 2000-04-30\n",
       " 4    1226.889766 2000-05-31\n",
       " ..           ...        ...\n",
       " 188  2407.864260 2015-09-30\n",
       " 189  2169.801406 2015-10-31\n",
       " 190  2024.869226 2015-11-30\n",
       " 191  2266.012322 2015-12-31\n",
       " 192  2172.331620 2016-01-31\n",
       " \n",
       " [193 rows x 2 columns],\n",
       " 'finance_22.csv':               y         ds\n",
       " 0   5516.671011 2000-01-01\n",
       " 1   5658.026814 2000-01-02\n",
       " 2   5603.655614 2000-01-03\n",
       " 3   5550.868493 2000-01-04\n",
       " 4   5786.896343 2000-01-05\n",
       " 5   5715.472992 2000-01-06\n",
       " 6   4620.594494 2000-01-07\n",
       " 7   4710.654074 2000-01-08\n",
       " 8   5645.587131 2000-01-09\n",
       " 9   5644.049642 2000-01-10\n",
       " 10  5479.398552 2000-01-11\n",
       " 11  6085.076019 2000-01-12\n",
       " 12  8647.557612 2000-01-13\n",
       " 13  8290.394268 2000-01-14\n",
       " 14  6970.296933 2000-01-15\n",
       " 15  5712.351424 2000-01-16\n",
       " 16  5029.054059 2000-01-17\n",
       " 17  4904.796997 2000-01-18\n",
       " 18  5459.224833 2000-01-19\n",
       " 19  6179.841247 2000-01-20\n",
       " 20  6582.057676 2000-01-21\n",
       " 21  7030.864679 2000-01-22\n",
       " 22  7079.039333 2000-01-23\n",
       " 23  6985.858185 2000-01-24\n",
       " 24  6842.964893 2000-01-25\n",
       " 25  6846.086461 2000-01-26\n",
       " 26  6880.237352 2000-01-27\n",
       " 27  6726.488457 2000-01-28\n",
       " 28  6133.250673 2000-01-29\n",
       " 29  5906.494347 2000-01-30\n",
       " 30  5887.858117 2000-01-31\n",
       " 31  5864.562830 2000-02-01\n",
       " 32  5746.548905 2000-02-02\n",
       " 33  6022.970783 2000-02-03\n",
       " 34  6656.602595 2000-02-04\n",
       " 35  6970.296933 2000-02-05\n",
       " 36  6148.765334 2000-02-06,\n",
       " 'finance_23.csv':                y         ds\n",
       " 0     272.189234 2000-01-01\n",
       " 1     260.792034 2000-01-02\n",
       " 2     243.696233 2000-01-03\n",
       " 3     272.189234 2000-01-04\n",
       " 4     249.394833 2000-01-05\n",
       " ..           ...        ...\n",
       " 64  15453.260485 2000-03-05\n",
       " 65  15390.575882 2000-03-06\n",
       " 66  16940.595169 2000-03-07\n",
       " 67  16097.202321 2000-03-08\n",
       " 68  17185.634982 2000-03-09\n",
       " \n",
       " [69 rows x 2 columns],\n",
       " 'finance_37.csv':               y         ds\n",
       " 0   1875.511918 2000-03-31\n",
       " 1   1609.459649 2000-06-30\n",
       " 2   1568.644812 2000-09-30\n",
       " 3   1691.089322 2000-12-31\n",
       " 4   1939.001664 2001-03-31\n",
       " ..          ...        ...\n",
       " 91  4791.505258 2022-12-31\n",
       " 92  6761.199049 2023-03-31\n",
       " 93  4590.454395 2023-06-30\n",
       " 94  4717.433888 2023-09-30\n",
       " 95  4779.411973 2023-12-31\n",
       " \n",
       " [96 rows x 2 columns],\n",
       " 'finance_5.csv':                y         ds\n",
       " 0    2622.948850 2000-01-01\n",
       " 1    2824.855654 2000-01-02\n",
       " 2    2714.724670 2000-01-03\n",
       " 3    2622.948850 2000-01-04\n",
       " 4    2824.855654 2000-01-05\n",
       " 5    2925.809055 2000-01-06\n",
       " 6    3146.071023 2000-01-07\n",
       " 7    2898.276309 2000-01-08\n",
       " 8    2980.874547 2000-01-09\n",
       " 9    3274.557171 2000-01-10\n",
       " 10   3861.922418 2000-01-11\n",
       " 11   3816.034508 2000-01-12\n",
       " 12   4265.736026 2000-01-13\n",
       " 13   4339.156682 2000-01-14\n",
       " 14   4274.913608 2000-01-15\n",
       " 15   4238.203280 2000-01-16\n",
       " 16   4128.072296 2000-01-17\n",
       " 17   4192.315370 2000-01-18\n",
       " 18   4256.558444 2000-01-19\n",
       " 19   4898.989183 2000-01-20\n",
       " 20   5339.513119 2000-01-21\n",
       " 21   5972.766276 2000-01-22\n",
       " 22   6752.860745 2000-01-23\n",
       " 23   7808.282674 2000-01-24\n",
       " 24   7285.160501 2000-01-25\n",
       " 25   7000.655459 2000-01-26\n",
       " 26   7156.674353 2000-01-27\n",
       " 27   8285.516937 2000-01-28\n",
       " 28   8781.106365 2000-01-29\n",
       " 29   8267.161773 2000-01-30\n",
       " 30   7734.862018 2000-01-31\n",
       " 31   8322.227265 2000-02-01\n",
       " 32   9285.873374 2000-02-02\n",
       " 33  11699.577438 2000-02-03\n",
       " 34  13819.598877 2000-02-04\n",
       " 35  13709.467893 2000-02-05\n",
       " 36  11727.110184 2000-02-06\n",
       " 37  12378.718505 2000-02-07\n",
       " 38  11057.146698 2000-02-08\n",
       " 39   8909.592513 2000-02-09\n",
       " 40   9093.144153 2000-02-10\n",
       " 41   9340.938866 2000-02-11\n",
       " 42   8863.704603 2000-02-12\n",
       " 43   8964.658005 2000-02-13\n",
       " 44   8469.068577 2000-02-14\n",
       " 45   7844.993002 2000-02-15\n",
       " 46   6918.057221 2000-02-16,\n",
       " 'finance_93.csv':                y         ds\n",
       " 0     133.210199 2000-01-01\n",
       " 1     133.174191 2000-01-02\n",
       " 2     132.548786 2000-01-03\n",
       " 3     132.850005 2000-01-04\n",
       " 4     132.868786 2000-01-05\n",
       " ...          ...        ...\n",
       " 1197  164.295154 2003-04-12\n",
       " 1198  164.015468 2003-04-13\n",
       " 1199  163.904096 2003-04-14\n",
       " 1200  162.651013 2003-04-15\n",
       " 1201  162.149660 2003-04-16\n",
       " \n",
       " [1202 rows x 2 columns],\n",
       " 'finance_87.csv':                y         ds\n",
       " 0      12.968413 2000-01-01\n",
       " 1      12.974406 2000-01-02\n",
       " 2      12.977402 2000-01-03\n",
       " 3      12.977402 2000-01-04\n",
       " 4      12.995383 2000-01-05\n",
       " ...          ...        ...\n",
       " 12123  81.374017 2033-03-11\n",
       " 12124  80.560845 2033-03-12\n",
       " 12125  79.977813 2033-03-13\n",
       " 12126  79.686300 2033-03-14\n",
       " 12127  79.295054 2033-03-15\n",
       " \n",
       " [12128 rows x 2 columns],\n",
       " 'finance_50.csv':                  y         ds\n",
       " 0      1222.723531 2000-01-02\n",
       " 1      1425.355651 2000-01-09\n",
       " 2      1296.603268 2000-01-16\n",
       " 3      1271.646131 2000-01-23\n",
       " 4      1240.738948 2000-01-30\n",
       " ...            ...        ...\n",
       " 2187  11818.433099 2041-12-01\n",
       " 2188  12466.492268 2041-12-08\n",
       " 2189  12466.492268 2041-12-15\n",
       " 2190  12604.665557 2041-12-22\n",
       " 2191  12604.665557 2041-12-29\n",
       " \n",
       " [2192 rows x 2 columns],\n",
       " 'finance_44.csv':                  y         ds\n",
       " 0      2861.064688 2000-01-02\n",
       " 1      2795.138658 2000-01-09\n",
       " 2      2930.008303 2000-01-16\n",
       " 3      2823.856221 2000-01-23\n",
       " 4      2981.553457 2000-01-30\n",
       " ...            ...        ...\n",
       " 1652  15674.684795 2031-08-31\n",
       " 1653  15565.534066 2031-09-07\n",
       " 1654  15448.239644 2031-09-14\n",
       " 1655  15536.305154 2031-09-21\n",
       " 1656  15685.479922 2031-09-28\n",
       " \n",
       " [1657 rows x 2 columns],\n",
       " 'finance_78.csv':               y         ds\n",
       " 0     24.268246 2000-01-01\n",
       " 1     24.021774 2000-01-02\n",
       " 2     24.310197 2000-01-03\n",
       " 3     24.179114 2000-01-04\n",
       " 4     24.336454 2000-01-05\n",
       " ...         ...        ...\n",
       " 5421  43.607446 2014-11-04\n",
       " 5422  43.833096 2014-11-05\n",
       " 5423  43.556163 2014-11-06\n",
       " 5424  43.525392 2014-11-07\n",
       " 5425  43.094604 2014-11-08\n",
       " \n",
       " [5426 rows x 2 columns],\n",
       " 'finance_79.csv':                y         ds\n",
       " 0    2545.321492 2000-01-02\n",
       " 1    2521.464423 2000-01-09\n",
       " 2    2530.028499 2000-01-16\n",
       " 3    2539.714061 2000-01-23\n",
       " 4    2523.503489 2000-01-30\n",
       " ..           ...        ...\n",
       " 255  3709.831892 2004-11-21\n",
       " 256  3676.493168 2004-11-28\n",
       " 257  3669.764252 2004-12-05\n",
       " 258  3622.457928 2004-12-12\n",
       " 259  3700.554143 2004-12-19\n",
       " \n",
       " [260 rows x 2 columns],\n",
       " 'finance_45.csv':                y         ds\n",
       " 0      33.307799 2000-01-02\n",
       " 1      33.242052 2000-01-09\n",
       " 2      33.361861 2000-01-16\n",
       " 3      33.233806 2000-01-23\n",
       " 4      33.753303 2000-01-30\n",
       " ...          ...        ...\n",
       " 1652  137.622427 2031-08-31\n",
       " 1653  138.084801 2031-09-07\n",
       " 1654  138.141263 2031-09-14\n",
       " 1655  137.917677 2031-09-21\n",
       " 1656  138.161248 2031-09-28\n",
       " \n",
       " [1657 rows x 2 columns],\n",
       " 'finance_51.csv':                 y         ds\n",
       " 0      337.153897 2000-01-01\n",
       " 1      342.192319 2000-01-02\n",
       " 2      338.569274 2000-01-03\n",
       " 3      336.953891 2000-01-04\n",
       " 4      335.707753 2000-01-05\n",
       " ...           ...        ...\n",
       " 8313  6682.634107 2022-10-05\n",
       " 8314  6731.235924 2022-10-06\n",
       " 8315  6748.466835 2022-10-07\n",
       " 8316  6756.412976 2022-10-08\n",
       " 8317  6795.817662 2022-10-09\n",
       " \n",
       " [8318 rows x 2 columns],\n",
       " 'finance_86.csv':              y                  ds\n",
       " 0    23.853570 2000-01-01 00:00:00\n",
       " 1    20.346301 2000-01-01 01:00:00\n",
       " 2    23.152117 2000-01-01 02:00:00\n",
       " 3    21.328336 2000-01-01 03:00:00\n",
       " 4    23.011826 2000-01-01 04:00:00\n",
       " ..         ...                 ...\n",
       " 278  20.065719 2000-01-12 14:00:00\n",
       " 279  18.382230 2000-01-12 15:00:00\n",
       " 280  18.803103 2000-01-12 16:00:00\n",
       " 281  18.522521 2000-01-12 17:00:00\n",
       " 282  17.961358 2000-01-12 18:00:00\n",
       " \n",
       " [283 rows x 2 columns],\n",
       " 'finance_92.csv':                 y         ds\n",
       " 0      121.197952 2000-01-01\n",
       " 1      121.271358 2000-01-02\n",
       " 2      121.239322 2000-01-03\n",
       " 3      121.230412 2000-01-04\n",
       " 4      121.365130 2000-01-05\n",
       " ...           ...        ...\n",
       " 11748   98.536742 2032-03-01\n",
       " 11749   98.536742 2032-03-02\n",
       " 11750   97.817113 2032-03-03\n",
       " 11751   97.875455 2032-03-04\n",
       " 11752   97.799080 2032-03-05\n",
       " \n",
       " [11753 rows x 2 columns],\n",
       " 'finance_4.csv':                y         ds\n",
       " 0    1531.868414 2000-01-01\n",
       " 1    1092.176718 2000-01-02\n",
       " 2     928.223882 2000-01-03\n",
       " 3    1825.824257 2000-01-04\n",
       " 4     795.736742 2000-01-05\n",
       " 5    1671.807956 2000-01-06\n",
       " 6    1648.622707 2000-01-07\n",
       " 7    1483.013781 2000-01-08\n",
       " 8    1811.747498 2000-01-09\n",
       " 9    4394.418688 2000-01-10\n",
       " 10   3508.410938 2000-01-11\n",
       " 11   3014.896340 2000-01-12\n",
       " 12   4059.888659 2000-01-13\n",
       " 13   3582.934954 2000-01-14\n",
       " 14   2996.679358 2000-01-15\n",
       " 15   2710.175918 2000-01-16\n",
       " 16   3063.750973 2000-01-17\n",
       " 17   2462.590574 2000-01-18\n",
       " 18   3726.186674 2000-01-19\n",
       " 19   5696.932885 2000-01-20\n",
       " 20   4874.684571 2000-01-21\n",
       " 21   3241.780568 2000-01-22\n",
       " 22   4589.837220 2000-01-23\n",
       " 23   1890.411738 2000-01-24\n",
       " 24   3452.103903 2000-01-25\n",
       " 25  12395.813912 2000-01-26\n",
       " 26   6079.489502 2000-01-27\n",
       " 27   3351.082459 2000-01-28,\n",
       " 'finance_100.csv':               y         ds\n",
       " 0     88.563259 2000-01-01\n",
       " 1     88.563259 2000-01-02\n",
       " 2     88.563259 2000-01-03\n",
       " 3     88.563259 2000-01-04\n",
       " 4     88.701120 2000-01-05\n",
       " ..          ...        ...\n",
       " 382  185.479231 2001-01-17\n",
       " 383  185.617092 2001-01-18\n",
       " 384  185.203510 2001-01-19\n",
       " 385  185.341371 2001-01-20\n",
       " 386  184.858859 2001-01-21\n",
       " \n",
       " [387 rows x 2 columns],\n",
       " 'finance_6.csv':               y         ds\n",
       " 0   1832.966600 2000-01-01\n",
       " 1   1967.740312 2000-01-02\n",
       " 2   1909.143046 2000-01-03\n",
       " 3   1827.106873 2000-01-04\n",
       " 4   1920.862499 2000-01-05\n",
       " 5   1979.459765 2000-01-06\n",
       " 6   2090.794571 2000-01-07\n",
       " 7   1915.002772 2000-01-08\n",
       " 8   1967.740312 2000-01-09\n",
       " 9   2149.391837 2000-01-10\n",
       " 10  2541.993520 2000-01-11\n",
       " 11  2583.011606 2000-01-12\n",
       " 12  2793.961765 2000-01-13\n",
       " 13  2893.577117 2000-01-14\n",
       " 14  2858.418757 2000-01-15\n",
       " 15  2858.418757 2000-01-16\n",
       " 16  2735.364498 2000-01-17\n",
       " 17  2747.083952 2000-01-18\n",
       " 18  2776.382585 2000-01-19\n",
       " 19  3157.264815 2000-01-20\n",
       " 20  3461.970599 2000-01-21\n",
       " 21  3977.626541 2000-01-22\n",
       " 22  4381.947677 2000-01-23\n",
       " 23  5149.571864 2000-01-24\n",
       " 24  4921.042526 2000-01-25\n",
       " 25  4686.653461 2000-01-26\n",
       " 26  4768.689634 2000-01-27\n",
       " 27  5272.626123 2000-01-28\n",
       " 28  5512.874914 2000-01-29\n",
       " 29  5196.449677 2000-01-30\n",
       " 30  4774.549361 2000-01-31\n",
       " 31  5073.395418 2000-02-01\n",
       " 32  5635.929173 2000-02-02\n",
       " 33  6737.557777 2000-02-03\n",
       " 34  7757.150208 2000-02-04\n",
       " 35  8026.697632 2000-02-05\n",
       " 36  7089.141374 2000-02-06\n",
       " 37  7669.254309 2000-02-07\n",
       " 38  7007.105201 2000-02-08\n",
       " 39  5782.422338 2000-02-09\n",
       " 40  5653.508353 2000-02-10\n",
       " 41  5887.897418 2000-02-11,\n",
       " 'finance_84.csv':                y                  ds\n",
       " 0      15.781587 2000-01-01 00:00:00\n",
       " 1      15.856278 2000-01-01 01:00:00\n",
       " 2      15.855355 2000-01-01 02:00:00\n",
       " 3      15.791730 2000-01-01 03:00:00\n",
       " 4      15.718883 2000-01-01 04:00:00\n",
       " ...          ...                 ...\n",
       " 3942  301.847711 2000-06-13 06:00:00\n",
       " 3943  300.879499 2000-06-13 07:00:00\n",
       " 3944  343.545386 2000-06-13 08:00:00\n",
       " 3945  338.162129 2000-06-13 09:00:00\n",
       " 3946  353.808431 2000-06-13 10:00:00\n",
       " \n",
       " [3947 rows x 2 columns],\n",
       " 'finance_90.csv':                y         ds\n",
       " 0      11.017738 2000-01-01\n",
       " 1      11.037031 2000-01-02\n",
       " 2      11.082049 2000-01-03\n",
       " 3      11.056325 2000-01-04\n",
       " 4      11.069186 2000-01-05\n",
       " ...          ...        ...\n",
       " 6440  110.971566 2017-08-19\n",
       " 6441  111.432546 2017-08-20\n",
       " 6442  111.745352 2017-08-21\n",
       " 6443  110.955099 2017-08-22\n",
       " 6444  105.867835 2017-08-23\n",
       " \n",
       " [6445 rows x 2 columns],\n",
       " 'finance_47.csv':                 y         ds\n",
       " 0     1809.740420 2000-01-02\n",
       " 1     1803.407273 2000-01-09\n",
       " 2     1798.261590 2000-01-16\n",
       " 3     1798.261590 2000-01-23\n",
       " 4     1788.563958 2000-01-30\n",
       " ...           ...        ...\n",
       " 1306  7260.799364 2025-01-12\n",
       " 1307  7259.413988 2025-01-19\n",
       " 1308  7294.048389 2025-01-26\n",
       " 1309  7316.511272 2025-02-02\n",
       " 1310  7312.355144 2025-02-09\n",
       " \n",
       " [1311 rows x 2 columns],\n",
       " 'finance_53.csv':               y         ds\n",
       " 0     11.107331 2000-01-01\n",
       " 1     11.096405 2000-01-02\n",
       " 2     11.080512 2000-01-03\n",
       " 3     11.084485 2000-01-04\n",
       " 4     11.090445 2000-01-05\n",
       " ...         ...        ...\n",
       " 9356  90.360697 2025-08-13\n",
       " 9357  89.777746 2025-08-14\n",
       " 9358  89.777746 2025-08-15\n",
       " 9359  89.755494 2025-08-16\n",
       " 9360  88.536186 2025-08-17\n",
       " \n",
       " [9361 rows x 2 columns],\n",
       " 'finance_52.csv':               y         ds\n",
       " 0     12.641907 2000-01-01\n",
       " 1     12.814758 2000-01-02\n",
       " 2     12.849328 2000-01-03\n",
       " 3     12.901183 2000-01-04\n",
       " 4     12.901183 2000-01-05\n",
       " ...         ...        ...\n",
       " 1298  13.782721 2003-07-22\n",
       " 1299  13.834576 2003-07-23\n",
       " 1300  13.921002 2003-07-24\n",
       " 1301  13.955572 2003-07-25\n",
       " 1302  13.990142 2003-07-26\n",
       " \n",
       " [1303 rows x 2 columns],\n",
       " 'finance_46.csv':                y         ds\n",
       " 0    4976.638953 2000-01-02\n",
       " 1    4994.750580 2000-01-09\n",
       " 2    4929.548725 2000-01-16\n",
       " 3    4933.895516 2000-01-23\n",
       " 4    4873.764917 2000-01-30\n",
       " ..           ...        ...\n",
       " 832  3011.165281 2015-12-13\n",
       " 833  3012.614211 2015-12-20\n",
       " 834  3066.949089 2015-12-27\n",
       " 835  3032.899232 2016-01-03\n",
       " 836  3088.683041 2016-01-10\n",
       " \n",
       " [837 rows x 2 columns],\n",
       " 'finance_91.csv':               y         ds\n",
       " 0     11.967239 2000-01-01\n",
       " 1     11.830926 2000-01-02\n",
       " 2     11.980870 2000-01-03\n",
       " 3     11.885451 2000-01-04\n",
       " 4     11.926345 2000-01-05\n",
       " ...         ...        ...\n",
       " 4827  13.837445 2013-03-20\n",
       " 4828  14.066450 2013-03-21\n",
       " 4829  14.120975 2013-03-22\n",
       " 4830  14.063724 2013-03-23\n",
       " 4831  14.028283 2013-03-24\n",
       " \n",
       " [4832 rows x 2 columns],\n",
       " 'finance_85.csv':                 y         ds\n",
       " 0       12.750099 2000-01-01\n",
       " 1       12.768573 2000-01-02\n",
       " 2       12.763955 2000-01-03\n",
       " 3       12.727008 2000-01-04\n",
       " 4       12.727008 2000-01-05\n",
       " ...           ...        ...\n",
       " 11511  130.978760 2031-07-08\n",
       " 11512  131.946404 2031-07-09\n",
       " 11513  132.115989 2031-07-10\n",
       " 11514  131.487523 2031-07-11\n",
       " 11515  131.487523 2031-07-12\n",
       " \n",
       " [11516 rows x 2 columns],\n",
       " 'finance_7.csv':                y         ds\n",
       " 0    7957.578091 2000-03-31\n",
       " 1    8637.695802 2000-06-30\n",
       " 2   10895.148653 2000-09-30\n",
       " 3    8437.887209 2000-12-31\n",
       " 4    9938.372891 2001-03-31\n",
       " 5   13340.882679 2001-06-30\n",
       " 6   13961.442058 2001-09-30\n",
       " 7   10537.798670 2001-12-31\n",
       " 8    8977.754657 2002-03-31\n",
       " 9   14401.405210 2002-06-30\n",
       " 10  12399.476809 2002-09-30\n",
       " 11  10749.134681 2002-12-31\n",
       " 12  19946.573969 2003-03-31\n",
       " 13  20796.721107 2003-06-30\n",
       " 14  15387.633526 2003-09-30\n",
       " 15  10301.966893 2003-12-31\n",
       " 16  12631.466112 2004-03-31\n",
       " 17  11754.095054 2004-06-30\n",
       " 18   9977.431629 2004-09-30\n",
       " 19   8363.112685 2004-12-31\n",
       " 20   8829.819449 2005-03-31\n",
       " 21  14348.571207 2005-06-30\n",
       " 22  16394.688046 2005-09-30\n",
       " 23  17494.595925 2005-12-31\n",
       " 24  17973.310416 2006-03-31\n",
       " 25  13885.879828 2006-06-30\n",
       " 26   9683.175051 2006-09-30,\n",
       " 'finance_3.csv':               y         ds\n",
       " 0    504.544622 2000-01-01\n",
       " 1    500.321519 2000-01-02\n",
       " 2    499.476898 2000-01-03\n",
       " 3    533.261720 2000-01-04\n",
       " 4    549.309510 2000-01-05\n",
       " 5    591.540538 2000-01-06\n",
       " 6    661.644043 2000-01-07\n",
       " 7    713.165896 2000-01-08\n",
       " 8    655.731699 2000-01-09\n",
       " 9    643.907011 2000-01-10\n",
       " 10   671.779489 2000-01-11\n",
       " 11   750.329200 2000-01-12\n",
       " 12   753.707682 2000-01-13\n",
       " 13   755.396923 2000-01-14\n",
       " 14   757.930784 2000-01-15\n",
       " 15   802.695673 2000-01-16\n",
       " 16   900.671656 2000-01-17\n",
       " 17  1050.169492 2000-01-18\n",
       " 18  1208.113534 2000-01-19\n",
       " 19  1238.519873 2000-01-20\n",
       " 20  1037.500184 2000-01-21\n",
       " 21  1018.073912 2000-01-22\n",
       " 22   951.348889 2000-01-23\n",
       " 23   837.325115 2000-01-24\n",
       " 24   769.755472 2000-01-25\n",
       " 25   760.464646 2000-01-26\n",
       " 26   839.858977 2000-01-27\n",
       " 27   832.257392 2000-01-28\n",
       " 28   775.667816 2000-01-29\n",
       " 29   688.671900 2000-01-30\n",
       " 30   608.432948 2000-01-31,\n",
       " 'finance_81.csv':                  y         ds\n",
       " 0    192174.135805 2000-01-01\n",
       " 1    191263.378388 2000-01-02\n",
       " 2    206564.102989 2000-01-03\n",
       " 3    201281.709972 2000-01-04\n",
       " 4    204924.739639 2000-01-05\n",
       " ..             ...        ...\n",
       " 113  589446.520976 2000-04-23\n",
       " 114  533890.318556 2000-04-24\n",
       " 115  641541.845212 2000-04-25\n",
       " 116  686168.958631 2000-04-26\n",
       " 117  633891.482912 2000-04-27\n",
       " \n",
       " [118 rows x 2 columns],\n",
       " 'finance_95.csv':               y         ds\n",
       " 0      5.405689 2000-01-01\n",
       " 1      5.405689 2000-01-02\n",
       " 2      5.406105 2000-01-03\n",
       " 3      5.406105 2000-01-04\n",
       " 4      5.405273 2000-01-05\n",
       " ...         ...        ...\n",
       " 9545  11.050838 2026-02-18\n",
       " 9546  11.097744 2026-02-19\n",
       " 9547  11.134670 2026-02-20\n",
       " 9548  11.114710 2026-02-21\n",
       " 9549  11.067804 2026-02-22\n",
       " \n",
       " [9550 rows x 2 columns],\n",
       " 'finance_42.csv':                y         ds\n",
       " 0    1776.397442 2000-01-02\n",
       " 1    1854.133031 2000-01-09\n",
       " 2    1860.389920 2000-01-16\n",
       " 3    1859.468906 2000-01-23\n",
       " 4    1834.281174 2000-01-30\n",
       " ..           ...        ...\n",
       " 387  1087.198613 2007-06-03\n",
       " 388  1096.679051 2007-06-10\n",
       " 389  1095.818103 2007-06-17\n",
       " 390  1092.244168 2007-06-24\n",
       " 391  1085.406640 2007-07-01\n",
       " \n",
       " [392 rows x 2 columns],\n",
       " 'finance_56.csv':               y         ds\n",
       " 0     14.325701 2000-01-01\n",
       " 1     14.383755 2000-01-02\n",
       " 2     14.354728 2000-01-03\n",
       " 3     14.216832 2000-01-04\n",
       " 4     14.238602 2000-01-05\n",
       " ...         ...        ...\n",
       " 5005  27.397652 2013-09-14\n",
       " 5006  27.448757 2013-09-15\n",
       " 5007  27.414688 2013-09-16\n",
       " 5008  27.131910 2013-09-17\n",
       " 5009  26.917272 2013-09-18\n",
       " \n",
       " [5010 rows x 2 columns],\n",
       " 'finance_57.csv':                y         ds\n",
       " 0      47.754915 2000-01-01\n",
       " 1      47.719082 2000-01-02\n",
       " 2      47.667115 2000-01-03\n",
       " 3      47.995020 2000-01-04\n",
       " 4      47.745957 2000-01-05\n",
       " ...          ...        ...\n",
       " 5447  182.661072 2014-11-30\n",
       " 5448  184.882926 2014-12-01\n",
       " 5449  189.022040 2014-12-02\n",
       " 5450  186.692668 2014-12-03\n",
       " 5451  183.341959 2014-12-04\n",
       " \n",
       " [5452 rows x 2 columns],\n",
       " 'finance_43.csv':                y         ds\n",
       " 0    2047.954173 2000-01-02\n",
       " 1    2070.955902 2000-01-09\n",
       " 2    2056.647409 2000-01-16\n",
       " 3    2040.542950 2000-01-23\n",
       " 4    2030.183670 2000-01-30\n",
       " ..           ...        ...\n",
       " 652  3360.223954 2012-07-01\n",
       " 653  3373.867558 2012-07-08\n",
       " 654  3352.753502 2012-07-15\n",
       " 655  3356.935809 2012-07-22\n",
       " 656  3363.468155 2012-07-29\n",
       " \n",
       " [657 rows x 2 columns],\n",
       " 'finance_94.csv':               y         ds\n",
       " 0     42.336075 2000-01-01\n",
       " 1     43.069142 2000-01-02\n",
       " 2     38.273304 2000-01-03\n",
       " 3     41.064252 2000-01-04\n",
       " 4     38.741405 2000-01-05\n",
       " ...         ...        ...\n",
       " 1056  23.806302 2002-11-22\n",
       " 1057  22.967250 2002-11-23\n",
       " 1058  22.384331 2002-11-24\n",
       " 1059  22.675791 2002-11-25\n",
       " 1060  22.375499 2002-11-26\n",
       " \n",
       " [1061 rows x 2 columns],\n",
       " 'finance_80.csv':                 y         ds\n",
       " 0        3.171382 2000-01-01\n",
       " 1        3.187140 2000-01-02\n",
       " 2        3.196592 2000-01-03\n",
       " 3        3.199744 2000-01-04\n",
       " 4        3.196592 2000-01-05\n",
       " ...           ...        ...\n",
       " 12122  270.622180 2033-03-10\n",
       " 12123  272.123019 2033-03-11\n",
       " 12124  271.510438 2033-03-12\n",
       " 12125  274.159884 2033-03-13\n",
       " 12126  272.781543 2033-03-14\n",
       " \n",
       " [12127 rows x 2 columns],\n",
       " 'finance_2.csv':                y         ds\n",
       " 0    1425.979514 2000-03-31\n",
       " 1     858.914825 2000-06-30\n",
       " 2     758.103325 2000-09-30\n",
       " 3     909.320576 2000-12-31\n",
       " 4    4154.190737 2001-03-31\n",
       " 5   10051.663495 2001-06-30\n",
       " 6    2793.235485 2001-09-30\n",
       " 7    1564.595327 2001-12-31\n",
       " 8    5300.921551 2002-03-31\n",
       " 9    4349.513018 2002-06-30\n",
       " 10   4488.128831 2002-09-30\n",
       " 11   3524.118861 2002-12-31\n",
       " 12   5943.594864 2003-03-31\n",
       " 13    480.871700 2003-06-30\n",
       " 14    852.614107 2003-09-30\n",
       " 15   1652.805389 2003-12-31\n",
       " 16   2106.457140 2004-03-31\n",
       " 17   1678.008264 2004-06-30\n",
       " 18   2812.137641 2004-09-30\n",
       " 19   3366.600892 2004-12-31\n",
       " 20   1451.182389 2005-03-31\n",
       " 21   4714.954706 2005-06-30\n",
       " 22   7065.122804 2005-09-30\n",
       " 23   2106.457140 2005-12-31\n",
       " 24    808.509075 2006-03-31\n",
       " 25   6630.373209 2006-06-30\n",
       " 26   8192.951461 2006-09-30\n",
       " 27   4595.241050 2006-12-31\n",
       " 28    833.711950 2007-03-31\n",
       " 29    348.556606 2007-06-30\n",
       " 30   3599.727486 2007-09-30\n",
       " 31   5483.642395 2007-12-31\n",
       " 32   9295.577244 2008-03-31\n",
       " 33  10662.833215 2008-06-30\n",
       " 34   4021.875643 2008-09-30\n",
       " 35   4009.274205 2008-12-31\n",
       " 36   4891.374832 2009-03-31\n",
       " 37  20088.708479 2009-06-30\n",
       " 38   8318.965837 2009-09-30\n",
       " 39   5225.312926 2009-12-31\n",
       " 40   4910.276988 2010-03-31\n",
       " 41  10826.651903 2010-06-30\n",
       " 42   1684.308983 2010-09-30\n",
       " 43   2068.652827 2010-12-31\n",
       " 44   1224.356514 2011-03-31\n",
       " 45    795.907638 2011-06-30\n",
       " 46    531.277450 2011-09-30,\n",
       " 'finance_96.csv':              y         ds\n",
       " 0     6.167020 2000-01-01\n",
       " 1     6.163822 2000-01-02\n",
       " 2     6.156197 2000-01-03\n",
       " 3     6.158411 2000-01-04\n",
       " 4     6.151155 2000-01-05\n",
       " ...        ...        ...\n",
       " 4964  6.186574 2013-08-04\n",
       " 4965  6.186574 2013-08-05\n",
       " 4966  6.193584 2013-08-06\n",
       " 4967  6.192662 2013-08-07\n",
       " 4968  6.193215 2013-08-08\n",
       " \n",
       " [4969 rows x 2 columns],\n",
       " 'finance_82.csv':               y                  ds\n",
       " 0     39.861292 2000-01-01 00:00:00\n",
       " 1     47.231730 2000-01-01 01:00:00\n",
       " 2     46.448046 2000-01-01 02:00:00\n",
       " 3     45.481565 2000-01-01 03:00:00\n",
       " 4     45.594303 2000-01-01 04:00:00\n",
       " ..          ...                 ...\n",
       " 546  169.472878 2000-01-23 18:00:00\n",
       " 547  170.997085 2000-01-23 19:00:00\n",
       " 548  185.727655 2000-01-23 20:00:00\n",
       " 549  173.293704 2000-01-23 21:00:00\n",
       " 550  169.239995 2000-01-23 22:00:00\n",
       " \n",
       " [551 rows x 2 columns],\n",
       " 'finance_69.csv':                y         ds\n",
       " 0     597.936775 2000-01-01\n",
       " 1     599.286592 2000-01-02\n",
       " 2     601.356312 2000-01-03\n",
       " 3     604.325910 2000-01-04\n",
       " 4     600.906373 2000-01-05\n",
       " ...          ...        ...\n",
       " 1298  480.232702 2003-07-22\n",
       " 1299  482.410407 2003-07-23\n",
       " 1300  481.816487 2003-07-24\n",
       " 1301  482.878344 2003-07-25\n",
       " 1302  487.701691 2003-07-26\n",
       " \n",
       " [1303 rows x 2 columns],\n",
       " 'finance_55.csv':                 y         ds\n",
       " 0       17.414852 2000-01-01\n",
       " 1       17.062738 2000-01-02\n",
       " 2       16.906243 2000-01-03\n",
       " 3       16.882769 2000-01-04\n",
       " 4       16.812346 2000-01-05\n",
       " ...           ...        ...\n",
       " 5204  1001.128078 2014-04-01\n",
       " 5205   989.988156 2014-04-02\n",
       " 5206  1020.726260 2014-04-03\n",
       " 5207  1048.316976 2014-04-04\n",
       " 5208  1043.193990 2014-04-05\n",
       " \n",
       " [5209 rows x 2 columns],\n",
       " 'finance_41.csv':                 y         ds\n",
       " 0     7470.461080 2000-01-02\n",
       " 1     7428.008133 2000-01-09\n",
       " 2     7462.395417 2000-01-16\n",
       " 3     7343.814422 2000-01-23\n",
       " 4     7358.481670 2000-01-30\n",
       " ..            ...        ...\n",
       " 387  13209.240375 2007-06-03\n",
       " 388  13241.366679 2007-06-10\n",
       " 389  13340.784941 2007-06-17\n",
       " 390  13264.854132 2007-06-24\n",
       " 391  13364.369029 2007-07-01\n",
       " \n",
       " [392 rows x 2 columns],\n",
       " 'finance_40.csv':                 y         ds\n",
       " 0     1743.423704 2000-03-31\n",
       " 1     2104.312594 2000-06-30\n",
       " 2     1855.591872 2000-09-30\n",
       " 3     1844.212493 2000-12-31\n",
       " 4     1853.966247 2001-03-31\n",
       " ..            ...        ...\n",
       " 129  15444.196529 2032-06-30\n",
       " 130  13446.302628 2032-09-30\n",
       " 131  13602.362688 2032-12-31\n",
       " 132  14060.789117 2033-03-31\n",
       " 133  15923.756091 2033-06-30\n",
       " \n",
       " [134 rows x 2 columns],\n",
       " 'finance_54.csv':                y         ds\n",
       " 0    6737.897243 2000-01-01\n",
       " 1    6743.727332 2000-01-02\n",
       " 2    6740.202162 2000-01-03\n",
       " 3    6740.337745 2000-01-04\n",
       " 4    6742.913831 2000-01-05\n",
       " ..           ...        ...\n",
       " 330  8490.177942 2000-11-26\n",
       " 331  8494.381029 2000-11-27\n",
       " 332  8504.007455 2000-11-28\n",
       " 333  8500.753452 2000-11-29\n",
       " 334  8501.702537 2000-11-30\n",
       " \n",
       " [335 rows x 2 columns],\n",
       " 'finance_68.csv':               y         ds\n",
       " 0     10.632142 2000-01-01\n",
       " 1     10.632142 2000-01-02\n",
       " 2     10.632142 2000-01-03\n",
       " 3     10.632142 2000-01-04\n",
       " 4     10.632142 2000-01-05\n",
       " ...         ...        ...\n",
       " 1917  35.931584 2005-04-01\n",
       " 1918  36.172919 2005-04-02\n",
       " 1919  36.462524 2005-04-03\n",
       " 1920  36.498723 2005-04-04\n",
       " 1921  37.198596 2005-04-05\n",
       " \n",
       " [1922 rows x 2 columns],\n",
       " 'finance_83.csv':                y         ds\n",
       " 0      19.625157 2000-01-01\n",
       " 1      20.435136 2000-01-02\n",
       " 2      21.093244 2000-01-03\n",
       " 3      20.890750 2000-01-04\n",
       " 4      20.435136 2000-01-05\n",
       " ...          ...        ...\n",
       " 4339  108.034387 2011-11-18\n",
       " 4340  109.127857 2011-11-19\n",
       " 4341  109.022562 2011-11-20\n",
       " 4342  109.808237 2011-11-21\n",
       " 4343  110.666819 2011-11-22\n",
       " \n",
       " [4344 rows x 2 columns],\n",
       " 'finance_97.csv':              y                  ds\n",
       " 0    17.493556 2000-01-01 00:00:00\n",
       " 1    16.158791 2000-01-01 01:00:00\n",
       " 2    16.659328 2000-01-01 02:00:00\n",
       " 3    18.828322 2000-01-01 03:00:00\n",
       " 4    21.497852 2000-01-01 04:00:00\n",
       " ..         ...                 ...\n",
       " 277   7.649661 2000-01-12 13:00:00\n",
       " 278   7.983352 2000-01-12 14:00:00\n",
       " 279   6.815433 2000-01-12 15:00:00\n",
       " 280   6.982278 2000-01-12 16:00:00\n",
       " 281   6.648587 2000-01-12 17:00:00\n",
       " \n",
       " [282 rows x 2 columns],\n",
       " 'finance_1.csv':               y         ds\n",
       " 0     87.764439 2000-01-01\n",
       " 1     91.764396 2000-01-02\n",
       " 2     97.097672 2000-01-03\n",
       " 3    103.836339 2000-01-04\n",
       " 4    113.313714 2000-01-05\n",
       " 5    119.511846 2000-01-06\n",
       " 6    124.520801 2000-01-07\n",
       " 7    133.421606 2000-01-08\n",
       " 8    157.277206 2000-01-09\n",
       " 9    179.835522 2000-01-10\n",
       " 10   192.159713 2000-01-11\n",
       " 11   199.835307 2000-01-12\n",
       " 12   229.744895 2000-01-13\n",
       " 13   251.762676 2000-01-14\n",
       " 14   274.465135 2000-01-15\n",
       " 15   295.041490 2000-01-16\n",
       " 16   311.221496 2000-01-17\n",
       " 17   351.617458 2000-01-18\n",
       " 18   381.491011 2000-01-19\n",
       " 19   413.238418 2000-01-20\n",
       " 20   437.850766 2000-01-21\n",
       " 21   494.570876 2000-01-22\n",
       " 22   562.534110 2000-01-23\n",
       " 23   578.389795 2000-01-24\n",
       " 24   649.668308 2000-01-25\n",
       " 25   709.451449 2000-01-26\n",
       " 26   774.603902 2000-01-27\n",
       " 27   802.351351 2000-01-28\n",
       " 28   829.053767 2000-01-29\n",
       " 29   901.917848 2000-01-30\n",
       " 30  1012.655396 2000-01-31\n",
       " 31  1101.303092 2000-02-01\n",
       " 32  1233.770136 2000-02-02\n",
       " 33  1399.137728 2000-02-03\n",
       " 34  1443.029148 2000-02-04\n",
       " 35  1644.900851 2000-02-05\n",
       " 36  1788.106519 2000-02-06\n",
       " 37  1908.285407 2000-02-07\n",
       " 38  2167.489827 2000-02-08\n",
       " 39  2606.476099 2000-02-09\n",
       " 40  2761.105067 2000-02-10\n",
       " 41  3002.688055 2000-02-11\n",
       " 42  3288.630927 2000-02-12\n",
       " 43  3608.987843 2000-02-13\n",
       " 44  4193.377956 2000-02-14\n",
       " 45  4739.858567 2000-02-15,\n",
       " 'finance_71.csv':               y         ds\n",
       " 0     92.682867 2000-01-01\n",
       " 1     94.931156 2000-01-02\n",
       " 2    117.976120 2000-01-03\n",
       " 3    136.524505 2000-01-04\n",
       " 4    137.889538 2000-01-05\n",
       " ..          ...        ...\n",
       " 702  105.610530 2001-12-03\n",
       " 703   97.821814 2001-12-04\n",
       " 704   99.267143 2001-12-05\n",
       " 705  103.442537 2001-12-06\n",
       " 706   94.208492 2001-12-07\n",
       " \n",
       " [707 rows x 2 columns],\n",
       " 'finance_65.csv':                y         ds\n",
       " 0      38.822918 2000-01-01\n",
       " 1      39.327415 2000-01-02\n",
       " 2      39.201289 2000-01-03\n",
       " 3      40.147218 2000-01-04\n",
       " 4      40.399467 2000-01-05\n",
       " ...          ...        ...\n",
       " 5334  174.946240 2014-08-09\n",
       " 5335  173.871961 2014-08-10\n",
       " 5336  173.871961 2014-08-11\n",
       " 5337  174.930890 2014-08-12\n",
       " 5338  174.378405 2014-08-13\n",
       " \n",
       " [5339 rows x 2 columns],\n",
       " 'finance_59.csv':             y         ds\n",
       " 0    4.677534 2000-01-01\n",
       " 1    4.654995 2000-01-02\n",
       " 2    4.632456 2000-01-03\n",
       " 3    4.609916 2000-01-04\n",
       " 4    4.598647 2000-01-05\n",
       " ..        ...        ...\n",
       " 448  3.539309 2001-03-24\n",
       " 449  3.550579 2001-03-25\n",
       " 450  3.550579 2001-03-26\n",
       " 451  3.550579 2001-03-27\n",
       " 452  3.550579 2001-03-28\n",
       " \n",
       " [453 rows x 2 columns],\n",
       " 'finance_58.csv':                y         ds\n",
       " 0      10.298265 2000-01-01\n",
       " 1      10.297629 2000-01-02\n",
       " 2      10.297992 2000-01-03\n",
       " 3      10.301809 2000-01-04\n",
       " 4      10.302354 2000-01-05\n",
       " ...          ...        ...\n",
       " 12269  10.517091 2033-08-04\n",
       " 12270  10.517091 2033-08-05\n",
       " 12271  10.508458 2033-08-06\n",
       " 12272  10.510366 2033-08-07\n",
       " 12273  10.510275 2033-08-08\n",
       " \n",
       " [12274 rows x 2 columns],\n",
       " 'finance_64.csv':              y         ds\n",
       " 0    26.817482 2000-01-01\n",
       " 1    26.868331 2000-01-02\n",
       " 2    26.754428 2000-01-03\n",
       " 3    27.173432 2000-01-04\n",
       " 4    27.397171 2000-01-05\n",
       " ..         ...        ...\n",
       " 815  35.258560 2002-03-26\n",
       " 816  35.441621 2002-03-27\n",
       " 817  35.543318 2002-03-28\n",
       " 818  35.838249 2002-03-29\n",
       " 819  35.685701 2002-03-30\n",
       " \n",
       " [820 rows x 2 columns],\n",
       " 'finance_70.csv':                 y         ds\n",
       " 0       39.592101 2000-01-01\n",
       " 1       39.342762 2000-01-02\n",
       " 2       39.405096 2000-01-03\n",
       " 3       38.781749 2000-01-04\n",
       " 4       39.093423 2000-01-05\n",
       " ...           ...        ...\n",
       " 12993  844.801602 2035-07-29\n",
       " 12994  848.572856 2035-07-30\n",
       " 12995  847.544332 2035-07-31\n",
       " 12996  849.383208 2035-08-01\n",
       " 12997  857.736069 2035-08-02\n",
       " \n",
       " [12998 rows x 2 columns],\n",
       " 'finance_99.csv':                 y         ds\n",
       " 0        7.690361 2000-01-01\n",
       " 1        7.692155 2000-01-02\n",
       " 2        7.691258 2000-01-03\n",
       " 3        7.690361 2000-01-04\n",
       " 4        7.689463 2000-01-05\n",
       " ...           ...        ...\n",
       " 11451  199.590410 2031-05-09\n",
       " 11452  201.042022 2031-05-10\n",
       " 11453  202.989745 2031-05-11\n",
       " 11454  202.071005 2031-05-12\n",
       " 11455  204.184111 2031-05-13\n",
       " \n",
       " [11456 rows x 2 columns],\n",
       " 'finance_66.csv':              y                  ds\n",
       " 0    10.438459 2000-01-01 00:00:00\n",
       " 1    11.125112 2000-01-01 01:00:00\n",
       " 2    10.863529 2000-01-01 02:00:00\n",
       " 3    10.520203 2000-01-01 03:00:00\n",
       " 4    10.487505 2000-01-01 04:00:00\n",
       " ..         ...                 ...\n",
       " 756  11.010669 2000-02-01 12:00:00\n",
       " 757  11.027018 2000-02-01 13:00:00\n",
       " 758  11.010669 2000-02-01 14:00:00\n",
       " 759  11.010669 2000-02-01 15:00:00\n",
       " 760  11.027018 2000-02-01 16:00:00\n",
       " \n",
       " [761 rows x 2 columns],\n",
       " 'finance_72.csv':                 y         ds\n",
       " 0       23.925391 2000-01-01\n",
       " 1       23.805100 2000-01-02\n",
       " 2       23.897632 2000-01-03\n",
       " 3       23.777340 2000-01-04\n",
       " 4       23.573767 2000-01-05\n",
       " ...           ...        ...\n",
       " 14109  241.488538 2038-08-18\n",
       " 14110  237.393945 2038-08-19\n",
       " 14111  239.212231 2038-08-20\n",
       " 14112  244.667031 2038-08-21\n",
       " 14113  243.501123 2038-08-22\n",
       " \n",
       " [14114 rows x 2 columns],\n",
       " 'finance_73.csv':              y         ds\n",
       " 0     4.301017 2000-01-01\n",
       " 1     4.294630 2000-01-02\n",
       " 2     4.297823 2000-01-03\n",
       " 3     4.294630 2000-01-04\n",
       " 4     4.323371 2000-01-05\n",
       " ...        ...        ...\n",
       " 3924  4.428756 2010-09-29\n",
       " 3925  4.431950 2010-09-30\n",
       " 3926  4.435143 2010-10-01\n",
       " 3927  4.435143 2010-10-02\n",
       " 3928  4.435143 2010-10-03\n",
       " \n",
       " [3929 rows x 2 columns],\n",
       " 'finance_67.csv':                y         ds\n",
       " 0      33.086299 2000-01-01\n",
       " 1      29.691666 2000-01-02\n",
       " 2      27.280986 2000-01-03\n",
       " 3      26.518424 2000-01-04\n",
       " 4      27.490076 2000-01-05\n",
       " ...          ...        ...\n",
       " 1426  118.444106 2003-11-27\n",
       " 1427  118.413356 2003-11-28\n",
       " 1428  121.641947 2003-11-29\n",
       " 1429  124.003428 2003-11-30\n",
       " 1430  122.810386 2003-12-01\n",
       " \n",
       " [1431 rows x 2 columns],\n",
       " 'finance_98.csv':               y         ds\n",
       " 0     17.205042 2000-01-01\n",
       " 1     17.269918 2000-01-02\n",
       " 2     16.831233 2000-01-03\n",
       " 3     15.515179 2000-01-04\n",
       " 4     15.323641 2000-01-05\n",
       " ...         ...        ...\n",
       " 1666  26.825209 2004-07-24\n",
       " 1667  26.902442 2004-07-25\n",
       " 1668  27.118695 2004-07-26\n",
       " 1669  27.739650 2004-07-27\n",
       " 1670  28.196870 2004-07-28\n",
       " \n",
       " [1671 rows x 2 columns],\n",
       " 'finance_88.csv':                y         ds\n",
       " 0      35.375649 2000-01-01\n",
       " 1      35.211674 2000-01-02\n",
       " 2      35.211674 2000-01-03\n",
       " 3      35.211674 2000-01-04\n",
       " 4      35.047698 2000-01-05\n",
       " ...          ...        ...\n",
       " 1254  332.827155 2003-06-08\n",
       " 1255  333.319082 2003-06-09\n",
       " 1256  334.466910 2003-06-10\n",
       " 1257  334.958837 2003-06-11\n",
       " 1258  336.598591 2003-06-12\n",
       " \n",
       " [1259 rows x 2 columns],\n",
       " 'finance_63.csv':                y         ds\n",
       " 0      92.244120 2000-01-01\n",
       " 1      91.758715 2000-01-02\n",
       " 2      93.214726 2000-01-03\n",
       " 3      93.214726 2000-01-04\n",
       " 4      94.175462 2000-01-05\n",
       " ...          ...        ...\n",
       " 5454  147.038952 2014-12-07\n",
       " 5455  148.007081 2014-12-08\n",
       " 5456  150.133198 2014-12-09\n",
       " 5457  150.133198 2014-12-10\n",
       " 5458  148.500646 2014-12-11\n",
       " \n",
       " [5459 rows x 2 columns],\n",
       " 'finance_77.csv':                y         ds\n",
       " 0      12.067660 2000-01-01\n",
       " 1      12.063401 2000-01-02\n",
       " 2      12.061982 2000-01-03\n",
       " 3      12.063401 2000-01-04\n",
       " 4      12.054884 2000-01-05\n",
       " ...          ...        ...\n",
       " 14110  63.171297 2038-08-19\n",
       " 14111  63.247609 2038-08-20\n",
       " 14112  63.596462 2038-08-21\n",
       " 14113  63.781792 2038-08-22\n",
       " 14114  63.869003 2038-08-23\n",
       " \n",
       " [14115 rows x 2 columns],\n",
       " 'finance_76.csv':                y         ds\n",
       " 0      13.532622 2000-01-01\n",
       " 1      13.556562 2000-01-02\n",
       " 2      13.700203 2000-01-03\n",
       " 3      13.700203 2000-01-04\n",
       " 4      13.628383 2000-01-05\n",
       " ...          ...        ...\n",
       " 9545  113.022969 2026-02-18\n",
       " 9546  113.053619 2026-02-19\n",
       " 9547  113.160870 2026-02-20\n",
       " 9548  113.666489 2026-02-21\n",
       " 9549  114.309996 2026-02-22\n",
       " \n",
       " [9550 rows x 2 columns],\n",
       " 'finance_62.csv':               y         ds\n",
       " 0     21.020884 2000-01-01\n",
       " 1     21.083967 2000-01-02\n",
       " 2     21.159953 2000-01-03\n",
       " 3     21.062461 2000-01-04\n",
       " 4     21.065329 2000-01-05\n",
       " ...         ...        ...\n",
       " 8357  26.563541 2022-11-18\n",
       " 8358  26.506193 2022-11-19\n",
       " 8359  26.520530 2022-11-20\n",
       " 8360  26.526265 2022-11-21\n",
       " 8361  26.443111 2022-11-22\n",
       " \n",
       " [8362 rows x 2 columns],\n",
       " 'finance_89.csv':               y         ds\n",
       " 0     45.950354 2000-01-01\n",
       " 1     45.380874 2000-01-02\n",
       " 2     44.975911 2000-01-03\n",
       " 3     45.254323 2000-01-04\n",
       " 4     45.153082 2000-01-05\n",
       " ...         ...        ...\n",
       " 3204  49.253327 2008-10-09\n",
       " 3205  49.310276 2008-10-10\n",
       " 3206  49.746877 2008-10-11\n",
       " 3207  49.778514 2008-10-12\n",
       " 3208  49.576034 2008-10-13\n",
       " \n",
       " [3209 rows x 2 columns],\n",
       " 'finance_9.csv':              y         ds\n",
       " 0   135.265407 2000-01-01\n",
       " 1   132.267911 2000-01-02\n",
       " 2   126.565938 2000-01-03\n",
       " 3   112.167402 2000-01-04\n",
       " 4   115.537344 2000-01-05\n",
       " 5   104.940770 2000-01-06\n",
       " 6    99.630616 2000-01-07\n",
       " 7    94.935073 2000-01-08\n",
       " 8    89.900986 2000-01-09\n",
       " 9    95.889196 2000-01-10\n",
       " 10  100.138675 2000-01-11\n",
       " 11   99.742012 2000-01-12\n",
       " 12  108.660880 2000-01-13\n",
       " 13  115.269512 2000-01-14\n",
       " 14  102.517685 2000-01-15\n",
       " 15   91.810200 2000-01-16\n",
       " 16   87.887157 2000-01-17\n",
       " 17   92.482445 2000-01-18\n",
       " 18   85.789540 2000-01-19\n",
       " 19   84.156876 2000-01-20\n",
       " 20   84.642171 2000-01-21\n",
       " 21   86.201218 2000-01-22\n",
       " 22   91.370432 2000-01-23\n",
       " 23   89.035495 2000-01-24,\n",
       " 'finance_48.csv':                y         ds\n",
       " 0    7851.321687 2000-01-02\n",
       " 1    7851.321687 2000-01-09\n",
       " 2    7879.052297 2000-01-16\n",
       " 3    7879.352943 2000-01-23\n",
       " 4    7879.656753 2000-01-30\n",
       " ..           ...        ...\n",
       " 465  7889.734714 2008-11-30\n",
       " 466  7892.296531 2008-12-07\n",
       " 467  7139.266070 2008-12-14\n",
       " 468  7886.924467 2008-12-21\n",
       " 469  7139.266070 2008-12-28\n",
       " \n",
       " [470 rows x 2 columns],\n",
       " 'finance_74.csv':                 y         ds\n",
       " 0      518.663076 2000-01-01\n",
       " 1      518.778361 2000-01-02\n",
       " 2      518.850413 2000-01-03\n",
       " 3      518.864824 2000-01-04\n",
       " 4      518.792771 2000-01-05\n",
       " ...           ...        ...\n",
       " 12269  163.443795 2033-08-04\n",
       " 12270  163.443795 2033-08-05\n",
       " 12271  162.737680 2033-08-06\n",
       " 12272  162.838553 2033-08-07\n",
       " 12273  162.939427 2033-08-08\n",
       " \n",
       " [12274 rows x 2 columns],\n",
       " 'finance_60.csv':              y         ds\n",
       " 0    17.473096 2000-01-01\n",
       " 1    18.738883 2000-01-02\n",
       " 2    18.377229 2000-01-03\n",
       " 3    17.473096 2000-01-04\n",
       " 4    16.388136 2000-01-05\n",
       " ..         ...        ...\n",
       " 834  18.558056 2002-04-14\n",
       " 835  18.377229 2002-04-15\n",
       " 836  17.653923 2002-04-16\n",
       " 837  17.292270 2002-04-17\n",
       " 838  17.292270 2002-04-18\n",
       " \n",
       " [839 rows x 2 columns],\n",
       " 'finance_61.csv':                y                  ds\n",
       " 0      16.037937 2000-01-01 00:00:00\n",
       " 1      16.214932 2000-01-01 01:00:00\n",
       " 2      16.407651 2000-01-01 02:00:00\n",
       " 3      16.609200 2000-01-01 03:00:00\n",
       " 4      16.804320 2000-01-01 04:00:00\n",
       " ..           ...                 ...\n",
       " 846  1640.452615 2000-02-05 06:00:00\n",
       " 847  1644.554475 2000-02-05 07:00:00\n",
       " 848  1653.457420 2000-02-05 08:00:00\n",
       " 849  1655.043168 2000-02-05 09:00:00\n",
       " 850  1652.226901 2000-02-05 10:00:00\n",
       " \n",
       " [851 rows x 2 columns],\n",
       " 'finance_75.csv':               y         ds\n",
       " 0    330.213104 2000-01-01\n",
       " 1    486.830551 2000-01-02\n",
       " 2    376.090942 2000-01-03\n",
       " 3    339.705070 2000-01-04\n",
       " 4    376.090942 2000-01-05\n",
       " ..          ...        ...\n",
       " 198  455.190662 2000-07-17\n",
       " 199  464.682629 2000-07-18\n",
       " 200  407.730830 2000-07-19\n",
       " 201  515.306450 2000-07-20\n",
       " 202  440.952713 2000-07-21\n",
       " \n",
       " [203 rows x 2 columns],\n",
       " 'finance_49.csv':              y         ds\n",
       " 0    65.017487 2000-01-02\n",
       " 1    64.799034 2000-01-09\n",
       " 2    64.580581 2000-01-16\n",
       " 3    64.362129 2000-01-23\n",
       " 4    64.143676 2000-01-30\n",
       " ..         ...        ...\n",
       " 440  64.580581 2008-06-08\n",
       " 441  64.362129 2008-06-15\n",
       " 442  64.143676 2008-06-22\n",
       " 443  63.925223 2008-06-29\n",
       " 444  63.706771 2008-07-06\n",
       " \n",
       " [445 rows x 2 columns],\n",
       " 'finance_8.csv':              y         ds\n",
       " 0   466.742240 2000-01-01\n",
       " 1   440.854946 2000-01-02\n",
       " 2   473.172039 2000-01-03\n",
       " 3   470.158858 2000-01-04\n",
       " 4   520.735738 2000-01-05\n",
       " 5   525.904792 2000-01-06\n",
       " 6   515.936503 2000-01-07\n",
       " 7   508.649398 2000-01-08\n",
       " 8   574.569542 2000-01-09\n",
       " 9   665.229703 2000-01-10\n",
       " 10  662.565328 2000-01-11\n",
       " 11  656.244794 2000-01-12\n",
       " 12  595.985394 2000-01-13\n",
       " 13  585.823791 2000-01-14\n",
       " 14  563.407748 2000-01-15\n",
       " 15  560.226469 2000-01-16\n",
       " 16  660.997802 2000-01-17\n",
       " 17  725.535330 2000-01-18\n",
       " 18  790.825102 2000-01-19\n",
       " 19  690.406777 2000-01-20\n",
       " 20  655.320248 2000-01-21\n",
       " 21  709.607920 2000-01-22\n",
       " 22  710.574491 2000-01-23\n",
       " 23  750.393015 2000-01-24\n",
       " 24  780.159201 2000-01-25\n",
       " 25  876.517928 2000-01-26,\n",
       " 'finance_12.csv':               y         ds\n",
       " 0   2103.367106 2000-01-01\n",
       " 1   2061.346883 2000-01-02\n",
       " 2   1989.134648 2000-01-03\n",
       " 3   1918.686620 2000-01-04\n",
       " 4   1863.073977 2000-01-05\n",
       " 5   1753.131751 2000-01-06\n",
       " 6   1675.506606 2000-01-07\n",
       " 7   1589.421282 2000-01-08\n",
       " 8   1516.126465 2000-01-09\n",
       " 9   1457.266075 2000-01-10\n",
       " 10  1422.543257 2000-01-11\n",
       " 11  1391.348855 2000-01-12\n",
       " 12  1360.074261 2000-01-13\n",
       " 13  1339.304723 2000-01-14\n",
       " 14  1338.903767 2000-01-15\n",
       " 15  1304.581905 2000-01-16\n",
       " 16  1259.233744 2000-01-17\n",
       " 17  1242.112908 2000-01-18\n",
       " 18  1236.098563 2000-01-19\n",
       " 19  1226.916663 2000-01-20\n",
       " 20  1214.005870 2000-01-21\n",
       " 21  1200.854502 2000-01-22\n",
       " 22  1194.639679 2000-01-23\n",
       " 23  1193.677384 2000-01-24\n",
       " 24  1179.884486 2000-01-25\n",
       " 25  1183.092137 2000-01-26\n",
       " 26  1187.221987 2000-01-27\n",
       " 27  1167.655318 2000-01-28\n",
       " 28  1168.016179 2000-01-29\n",
       " 29  1167.976083 2000-01-30\n",
       " 30  1169.579908 2000-01-31\n",
       " 31  1163.525468 2000-02-01\n",
       " 32  1158.393227 2000-02-02\n",
       " 33  1160.638582 2000-02-03\n",
       " 34  1169.379430 2000-02-04,\n",
       " 'finance_13.csv':               y         ds\n",
       " 0   8455.974784 2000-03-31\n",
       " 1   8507.531544 2000-06-30\n",
       " 2   8212.228719 2000-09-30\n",
       " 3   7183.645846 2000-12-31\n",
       " 4   6588.446029 2001-03-31\n",
       " 5   3465.688845 2001-06-30\n",
       " 6   3303.616854 2001-09-30\n",
       " 7   2953.439260 2001-12-31\n",
       " 8   2662.475371 2002-03-31\n",
       " 9   2720.157686 2002-06-30\n",
       " 10  2686.977593 2002-09-30\n",
       " 11  2535.880556 2002-12-31\n",
       " 12  2421.536852 2003-03-31\n",
       " 13  2586.926852 2003-06-30\n",
       " 14  2506.273704 2003-09-30\n",
       " 15  2364.620231 2003-12-31\n",
       " 16  2372.277176 2004-03-31\n",
       " 17  2549.407824 2004-06-30\n",
       " 18  2615.768010 2004-09-30\n",
       " 19  2559.617083 2004-12-31\n",
       " 20  2478.198241 2005-03-31\n",
       " 21  2692.847917 2005-06-30\n",
       " 22  2803.873612 2005-09-30\n",
       " 23  2726.283241 2005-12-31\n",
       " 24  2675.492176 2006-03-31\n",
       " 25  2858.237918 2006-06-30\n",
       " 26  2909.028983 2006-09-30\n",
       " 27  2866.660556 2006-12-31\n",
       " 28  2720.412917 2007-03-31\n",
       " 29  2911.326066 2007-06-30\n",
       " 30  2938.635834 2007-09-30\n",
       " 31  2837.308936 2007-12-31\n",
       " 32  2660.433519 2008-03-31\n",
       " 33  2831.949075 2008-06-30\n",
       " 34  2918.217316 2008-09-30,\n",
       " 'finance_11.csv':                y         ds\n",
       " 0    7421.997232 2000-01-01\n",
       " 1    6933.706249 2000-01-02\n",
       " 2    6601.826435 2000-01-03\n",
       " 3    7511.837309 2000-01-04\n",
       " 4    7581.693050 2000-01-05\n",
       " 5    8705.238747 2000-01-06\n",
       " 6    8662.944803 2000-01-07\n",
       " 7    9216.945061 2000-01-08\n",
       " 8    9698.634221 2000-01-09\n",
       " 9    8792.932418 2000-01-10\n",
       " 10   8400.676820 2000-01-11\n",
       " 11   9156.504235 2000-01-12\n",
       " 12   9447.277132 2000-01-13\n",
       " 13   9637.656793 2000-01-14\n",
       " 14  13126.167315 2000-01-15\n",
       " 15  14969.701959 2000-01-16\n",
       " 16  15974.675014 2000-01-17\n",
       " 17  12799.409604 2000-01-18\n",
       " 18  13489.104966 2000-01-19\n",
       " 19  14967.994591 2000-01-20\n",
       " 20  15316.899303 2000-01-21\n",
       " 21  16245.105842 2000-01-22\n",
       " 22  16503.536312 2000-01-23\n",
       " 23  15289.841586 2000-01-24,\n",
       " 'finance_39.csv':                 y         ds\n",
       " 0     1589.284598 2000-03-31\n",
       " 1     2288.378240 2000-06-30\n",
       " 2     1682.497084 2000-09-30\n",
       " 3     1775.709569 2000-12-31\n",
       " 4     1799.012691 2001-03-31\n",
       " ..            ...        ...\n",
       " 129  20523.070753 2032-06-30\n",
       " 130  17039.254100 2032-09-30\n",
       " 131  17400.452482 2032-12-31\n",
       " 132  17272.285315 2033-03-31\n",
       " 133  20907.572256 2033-06-30\n",
       " \n",
       " [134 rows x 2 columns],\n",
       " 'finance_38.csv':               y         ds\n",
       " 0   1126.989102 2000-03-31\n",
       " 1   1366.077249 2000-06-30\n",
       " 2   1556.261002 2000-09-30\n",
       " 3   1333.474320 2000-12-31\n",
       " 4   1262.834640 2001-03-31\n",
       " ..          ...        ...\n",
       " 77  4275.345292 2019-06-30\n",
       " 78  5367.543418 2019-09-30\n",
       " 79  5086.614845 2019-12-31\n",
       " 80  4456.834931 2020-03-31\n",
       " 81  4829.051705 2020-06-30\n",
       " \n",
       " [82 rows x 2 columns],\n",
       " 'finance_10.csv':                y         ds\n",
       " 0    5874.705975 2000-01-01\n",
       " 1    5988.435067 2000-01-02\n",
       " 2    6274.731244 2000-01-03\n",
       " 3    6629.732656 2000-01-04\n",
       " 4    8156.874620 2000-01-05\n",
       " 5    8401.903801 2000-01-06\n",
       " 6    7645.166798 2000-01-07\n",
       " 7    7164.083969 2000-01-08\n",
       " 8    7135.578606 2000-01-09\n",
       " 9    9103.954361 2000-01-10\n",
       " 10  10321.118768 2000-01-11\n",
       " 11  11784.627988 2000-01-12\n",
       " 12  13507.755290 2000-01-13\n",
       " 13  13844.864105 2000-01-14\n",
       " 14  10884.881769 2000-01-15\n",
       " 15   9858.527880 2000-01-16\n",
       " 16   9618.059557 2000-01-17\n",
       " 17  10335.459158 2000-01-18\n",
       " 18   8859.685322 2000-01-19\n",
       " 19   9103.954361 2000-01-20\n",
       " 20   8613.121236 2000-01-21\n",
       " 21   9921.853642 2000-01-22\n",
       " 22   9795.830699 2000-01-23,\n",
       " 'finance_28.csv':                 y         ds\n",
       " 0      290.119563 2000-01-01\n",
       " 1      290.603970 2000-01-02\n",
       " 2      288.804747 2000-01-03\n",
       " 3      289.946561 2000-01-04\n",
       " 4      291.918787 2000-01-05\n",
       " ...           ...        ...\n",
       " 3707  7713.506238 2010-02-24\n",
       " 3708  7650.810235 2010-02-25\n",
       " 3709  7602.750219 2010-02-26\n",
       " 3710  7525.695033 2010-02-27\n",
       " 3711  7541.888040 2010-02-28\n",
       " \n",
       " [3712 rows x 2 columns],\n",
       " 'finance_14.csv':                y         ds\n",
       " 0    9123.917377 2000-03-31\n",
       " 1    8303.690189 2000-06-30\n",
       " 2    7714.120828 2000-09-30\n",
       " 3    8064.084428 2000-12-31\n",
       " 4    8738.162045 2001-03-31\n",
       " 5    8021.333193 2001-06-30\n",
       " 6    7430.769618 2001-09-30\n",
       " 7    7366.145657 2001-12-31\n",
       " 8    7590.838196 2002-03-31\n",
       " 9    7593.820841 2002-06-30\n",
       " 10   7957.703448 2002-09-30\n",
       " 11   8186.372846 2002-12-31\n",
       " 12   9721.440456 2003-03-31\n",
       " 13   9886.480108 2003-06-30\n",
       " 14   9686.642939 2003-09-30\n",
       " 15   9941.161921 2003-12-31\n",
       " 16  10356.743696 2004-03-31\n",
       " 17   9739.336322 2004-06-30\n",
       " 18   9827.821436 2004-09-30\n",
       " 19  10390.546998 2004-12-31\n",
       " 20  11514.009692 2005-03-31\n",
       " 21  11015.908091 2005-06-30\n",
       " 22  10640.094906 2005-09-30\n",
       " 23  11027.838668 2005-12-31\n",
       " 24  11247.560133 2006-03-31\n",
       " 25  10683.840356 2006-06-30\n",
       " 26  10565.528798 2006-09-30\n",
       " 27  11409.617141 2006-12-31\n",
       " 28  12606.651728 2007-03-31\n",
       " 29  12008.134435 2007-06-30\n",
       " 30  11986.261710 2007-09-30\n",
       " 31  12570.859996 2007-12-31\n",
       " 32  13324.474795 2008-03-31\n",
       " 33  12966.557476 2008-06-30\n",
       " 34  12965.563261 2008-09-30,\n",
       " 'finance_15.csv':              y         ds\n",
       " 0   309.609658 2000-01-01\n",
       " 1   323.395626 2000-01-02\n",
       " 2   340.470294 2000-01-03\n",
       " 3   354.023728 2000-01-04\n",
       " 4   379.801827 2000-01-05\n",
       " 5   374.752508 2000-01-06\n",
       " 6   373.722713 2000-01-07\n",
       " 7   431.424463 2000-01-08\n",
       " 8   414.250136 2000-01-09\n",
       " 9   377.476483 2000-01-10\n",
       " 10  365.251817 2000-01-11\n",
       " 11  387.973750 2000-01-12\n",
       " 12  363.966234 2000-01-13\n",
       " 13  350.236739 2000-01-14\n",
       " 14  365.584009 2000-01-15\n",
       " 15  396.079234 2000-01-16\n",
       " 16  399.367935 2000-01-17\n",
       " 17  408.636092 2000-01-18\n",
       " 18  435.443986 2000-01-19\n",
       " 19  451.322763 2000-01-20\n",
       " 20  397.142249 2000-01-21\n",
       " 21  375.051481 2000-01-22\n",
       " 22  407.573077 2000-01-23\n",
       " 23  443.881662 2000-01-24\n",
       " 24  411.625820 2000-01-25\n",
       " 25  444.346731 2000-01-26\n",
       " 26  462.849825 2000-01-27\n",
       " 27  400.696703 2000-01-28\n",
       " 28  397.507660 2000-01-29\n",
       " 29  384.136932 2000-01-30\n",
       " 30  389.116490 2000-01-31\n",
       " 31  370.490485 2000-02-01\n",
       " 32  382.007581 2000-02-02\n",
       " 33  398.454407 2000-02-03\n",
       " 34  410.695682 2000-02-04\n",
       " 35  407.054858 2000-02-05\n",
       " 36  443.386696 2000-02-06\n",
       " 37  444.565978 2000-02-07\n",
       " 38  436.430596 2000-02-08,\n",
       " 'finance_29.csv':                 y         ds\n",
       " 0     9742.674644 2000-01-31\n",
       " 1     9907.194277 2000-02-29\n",
       " 2    10032.178185 2000-03-31\n",
       " 3    10061.511143 2000-04-30\n",
       " 4    10037.279569 2000-05-31\n",
       " ..            ...        ...\n",
       " 247  13496.017904 2020-08-31\n",
       " 248  13603.146967 2020-09-30\n",
       " 249  13567.437280 2020-10-31\n",
       " 250  13734.507605 2020-11-30\n",
       " 251  13737.058297 2020-12-31\n",
       " \n",
       " [252 rows x 2 columns],\n",
       " 'finance_17.csv':               y         ds\n",
       " 0   2849.147411 2000-01-01\n",
       " 1   2973.340795 2000-01-02\n",
       " 2   3201.788258 2000-01-03\n",
       " 3   3324.520252 2000-01-04\n",
       " 4   3627.779326 2000-01-05\n",
       " 5   3695.713322 2000-01-06\n",
       " 6   3627.680249 2000-01-07\n",
       " 7   3918.265686 2000-01-08\n",
       " 8   3980.857764 2000-01-09\n",
       " 9   3908.679958 2000-01-10\n",
       " 10  3575.623389 2000-01-11\n",
       " 11  3758.866838 2000-01-12\n",
       " 12  3608.252843 2000-01-13\n",
       " 13  3452.899651 2000-01-14\n",
       " 14  3468.826326 2000-01-15\n",
       " 15  3683.766252 2000-01-16\n",
       " 16  3945.090862 2000-01-17\n",
       " 17  3975.169076 2000-01-18\n",
       " 18  4187.285299 2000-01-19\n",
       " 19  4443.878969 2000-01-20\n",
       " 20  4363.593338 2000-01-21\n",
       " 21  3847.227268 2000-01-22\n",
       " 22  3827.345759 2000-01-23\n",
       " 23  4099.445025 2000-01-24\n",
       " 24  4121.275054 2000-01-25\n",
       " 25  4133.172586 2000-01-26\n",
       " 26  4559.568219 2000-01-27\n",
       " 27  4309.051289 2000-01-28\n",
       " 28  4079.613054 2000-01-29\n",
       " 29  4122.472238 2000-01-30\n",
       " 30  3977.968010 2000-01-31\n",
       " 31  3965.393450 2000-02-01\n",
       " 32  3869.197657 2000-02-02\n",
       " 33  4014.833018 2000-02-03\n",
       " 34  4269.461655 2000-02-04\n",
       " 35  4322.781751 2000-02-05\n",
       " 36  4511.317578 2000-02-06\n",
       " 37  4776.423639 2000-02-07\n",
       " 38  4658.777613 2000-02-08,\n",
       " 'finance_16.csv':               y         ds\n",
       " 0   2174.560252 2000-01-01\n",
       " 1   2289.969935 2000-01-02\n",
       " 2   2484.128006 2000-01-03\n",
       " 3   2736.266141 2000-01-04\n",
       " 4   3015.576969 2000-01-05\n",
       " 5   3148.198937 2000-01-06\n",
       " 6   3386.121646 2000-01-07\n",
       " 7   3513.265389 2000-01-08\n",
       " 8   3839.337714 2000-01-09\n",
       " 9   3910.904124 2000-01-10\n",
       " 10  3837.721332 2000-01-11\n",
       " 11  4138.368404 2000-01-12\n",
       " 12  4213.831606 2000-01-13\n",
       " 13  4136.402534 2000-01-14\n",
       " 14  3781.838197 2000-01-15\n",
       " 15  3977.455381 2000-01-16\n",
       " 16  3816.332665 2000-01-17\n",
       " 17  3650.518072 2000-01-18\n",
       " 18  3666.306194 2000-01-19\n",
       " 19  3891.883239 2000-01-20\n",
       " 20  4169.001030 2000-01-21\n",
       " 21  4203.329491 2000-01-22\n",
       " 22  4427.840597 2000-01-23\n",
       " 23  4700.546101 2000-01-24\n",
       " 24  4615.672935 2000-01-25\n",
       " 25  4068.182472 2000-01-26\n",
       " 26  4045.675443 2000-01-27\n",
       " 27  4335.497124 2000-01-28\n",
       " 28  4354.142310 2000-01-29\n",
       " 29  4369.301353 2000-01-30\n",
       " 30  4820.726296 2000-01-31\n",
       " 31  4558.557855 2000-02-01\n",
       " 32  4314.370573 2000-02-02\n",
       " 33  4359.201149 2000-02-03\n",
       " 34  4204.841026 2000-02-04\n",
       " 35  4188.607308 2000-02-05\n",
       " 36  4092.768954 2000-02-06\n",
       " 37  4246.613582 2000-02-07\n",
       " 38  4513.535060 2000-02-08\n",
       " 39  4562.847820 2000-02-09\n",
       " 40  4771.911556 2000-02-10\n",
       " 41  5054.193032 2000-02-11\n",
       " 42  4929.128743 2000-02-12}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e598e770",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578ed235",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cf49841e",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_p = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0cce262b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AINFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 20.0 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "20.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.2 K    Total params\n",
      "0.081     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df8448678e3642e38f014922bfc03759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AINFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 17.2 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "17.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "17.3 K    Total params\n",
      "0.069     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd2ce9c494fd4a939b0e27044c57e288",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                                      \u001b[A\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "                                      \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AINFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 17.2 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "17.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "17.3 K    Total params\n",
      "0.069     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fa2eeb47fe4422eb40018fb275a1293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 20.0 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "20.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.2 K    Total params\n",
      "0.081     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfa9b4edee9c455eac8d71db6974f0cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 17.2 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "17.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "17.3 K    Total params\n",
      "0.069     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f8edfbbe50b46bbb374545a01445284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                                      \u001b[AWARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 20.0 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "20.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.2 K    Total params\n",
      "0.081     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40bbf910efe648df90c90a347dee389e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 17.2 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "17.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "17.3 K    Total params\n",
      "0.069     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75dbbb65e22641dca63ac7226602db45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 17.2 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "17.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "17.3 K    Total params\n",
      "0.069     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3efb6ce6d8bd46edb5a1bb51fa7dc813",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 20.0 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "20.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.2 K    Total params\n",
      "0.081     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "480e14aa10b2499dad7a0253b177091e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\u001b[AINFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 17.2 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "17.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "17.3 K    Total params\n",
      "0.069     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "771fe07a03864ad5904e8932dee4c05e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 17.2 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "17.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "17.3 K    Total params\n",
      "0.069     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e0c8316ce3e431584f14e65bd3d168c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 20.0 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "20.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.2 K    Total params\n",
      "0.081     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bdeaf3cbe1b49f394793cfec5ad3606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 20.0 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "20.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.2 K    Total params\n",
      "0.081     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cf44b3486124b58ab0c6c7c32a3101a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 17.2 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "17.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "17.3 K    Total params\n",
      "0.069     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "159a42b8f92d4fbba2070698798eb684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 20.0 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "20.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.2 K    Total params\n",
      "0.081     Total estimated model params size (MB)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "851fe81053894c88b4229c99296b4d9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 17.2 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "17.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "17.3 K    Total params\n",
      "0.069     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f83e352f9df4db69e8a96334231a1dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 17.2 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "17.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "17.3 K    Total params\n",
      "0.069     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aaa61da85a1407c86452246e1676756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 17.9 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "18.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.1 K    Total params\n",
      "0.072     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4444c20a45184260ae11af1d09f07f6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 17.2 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "17.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "17.3 K    Total params\n",
      "0.069     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e11b6e32a5d454394889a33c8bf3b65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AINFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 109 K \n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "109 K     Trainable params\n",
      "0         Non-trainable params\n",
      "109 K     Total params\n",
      "0.437     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2811ec45f0b24d489b1baae919e704a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "                                      \u001b[A\u001b[A\n",
      "                                      \u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AINFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 532 K \n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "533 K     Trainable params\n",
      "0         Non-trainable params\n",
      "533 K     Total params\n",
      "2.133     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fa0c936089843868c854157f2781d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 18.7 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "18.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.9 K    Total params\n",
      "0.076     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0badd9c0aef4909b578ebbea6533fc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 18.7 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "18.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.9 K    Total params\n",
      "0.076     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9e8ec6ffc834a29bd8c4e82c3664fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 385 K \n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "385 K     Trainable params\n",
      "0         Non-trainable params\n",
      "385 K     Total params\n",
      "1.543     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e668491d4e5f4bba8ee077ed5a0535cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 18.7 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "18.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.9 K    Total params\n",
      "0.076     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab154b5d40744519a2332d3d99eedc83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 18.7 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "18.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.9 K    Total params\n",
      "0.076     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a6990e6b1b24cd2a6f2a1b73d641017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\u001b[AINFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 109 K \n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "109 K     Trainable params\n",
      "0         Non-trainable params\n",
      "109 K     Total params\n",
      "0.437     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fd74730ef794b4a833dc9f80b54254f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                      \n",
      "                                      \u001b[A\n",
      "\n",
      "                                      \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[AINFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 41.5 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "41.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "41.7 K    Total params\n",
      "0.167     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0ee375accf9466083eb4dfe022c15ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 188 K \n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "189 K     Trainable params\n",
      "0         Non-trainable params\n",
      "189 K     Total params\n",
      "0.756     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "344f08af28254716b9a53aee5c50f6a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 17.2 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "17.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "17.3 K    Total params\n",
      "0.069     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d89f7cae85e4d0db29c915b7d0014c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 17.2 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "17.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "17.3 K    Total params\n",
      "0.069     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1621b9152a7b428890e41cdc8ce2ff72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 17.2 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "17.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "17.3 K    Total params\n",
      "0.069     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a5bfdccec2d4313bb082be39036a6be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                      \n",
      "                                      \u001b[AINFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 41.5 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "41.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "41.7 K    Total params\n",
      "0.167     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46bef991b71e475a9029c8cb90ca064e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 139 K \n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "139 K     Trainable params\n",
      "0         Non-trainable params\n",
      "139 K     Total params\n",
      "0.560     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4213d3f6e0544d919ef0e2df92699b3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 18.7 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "18.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.9 K    Total params\n",
      "0.076     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ff37ba486b347e4a6e6a308bb588ac7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\n",
      "                                      \u001b[A\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[AINFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 188 K \n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "189 K     Trainable params\n",
      "0         Non-trainable params\n",
      "189 K     Total params\n",
      "0.756     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77e2b2c101da4bfd902e6d258150a440",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 109 K \n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "109 K     Trainable params\n",
      "0         Non-trainable params\n",
      "109 K     Total params\n",
      "0.437     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62c1b1fbacda49679b71f3c32ac6c7da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 18.7 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "18.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.9 K    Total params\n",
      "0.076     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf5d5f4c07d645ca8335e1de89fc75d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 78.3 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "78.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "78.5 K    Total params\n",
      "0.314     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bdb2ced67c24c3786228edd154cf147",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                      \n",
      "                                      \u001b[A\n",
      "\n",
      "                                      \u001b[A\u001b[AINFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 385 K \n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "385 K     Trainable params\n",
      "0         Non-trainable params\n",
      "385 K     Total params\n",
      "1.543     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b95d1e681ff344ceb69fd7cdd91aa587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[AINFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 17.9 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "18.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.1 K    Total params\n",
      "0.072     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8109974b05540f1ad99bbbef9f0f77a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 17.2 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "17.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "17.3 K    Total params\n",
      "0.069     Total estimated model params size (MB)\n",
      "\n",
      "                                      \u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b39832396baa4f71ab6053aca7dcd3cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 24.6 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "24.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.8 K    Total params\n",
      "0.099     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "035da1ea67ed4922acee91e1cab16960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                                      \u001b[AINFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 203 K \n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "203 K     Trainable params\n",
      "0         Non-trainable params\n",
      "203 K     Total params\n",
      "0.816     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb54774ac7a4ad0a76ecae1c0c77729",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                      \n",
      "\n",
      "                                      \u001b[A\u001b[AINFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 18.7 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "18.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.9 K    Total params\n",
      "0.076     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbb7e99f58e7442693dd50703909bd4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 385 K \n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "385 K     Trainable params\n",
      "0         Non-trainable params\n",
      "385 K     Total params\n",
      "1.543     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "215f06037547410e930e412e864e2d9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 385 K \n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "385 K     Trainable params\n",
      "0         Non-trainable params\n",
      "385 K     Total params\n",
      "1.543     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbef13e9441849f08de559ebe0adced8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 18.7 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "18.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.9 K    Total params\n",
      "0.076     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af031de3076740f0994bd3435694223b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 109 K \n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "109 K     Trainable params\n",
      "0         Non-trainable params\n",
      "109 K     Total params\n",
      "0.437     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4228605072a84cfbaabed6e73c8e8653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                                      \u001b[A\n",
      "\n",
      "                                      \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\u001b[AINFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 532 K \n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "533 K     Trainable params\n",
      "0         Non-trainable params\n",
      "533 K     Total params\n",
      "2.133     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac87739e266e488fbb3f2aef03f8fdfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 17.9 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "18.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.1 K    Total params\n",
      "0.072     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f2a3c705d8840fbb2c911dcfbdf9a66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                                      \u001b[AINFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 32.3 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "32.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "32.5 K    Total params\n",
      "0.130     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92dea157a18941bf81b974d58a2657be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 41.5 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "41.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "41.7 K    Total params\n",
      "0.167     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8573424ec8274c3fb5efa9983607c2a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 102 K \n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "103 K     Trainable params\n",
      "0         Non-trainable params\n",
      "103 K     Total params\n",
      "0.412     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a60132a78c284499815482b016276feb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 32.3 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "32.5 K    Trainable params\n",
      "0         Non-trainable params\n",
      "32.5 K    Total params\n",
      "0.130     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84eff04d923d4465aeb29408a8c32cb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                      \n",
      "                                      \u001b[A\n",
      "\n",
      "                                      \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[AINFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 18.7 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "18.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.9 K    Total params\n",
      "0.076     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70fa1ced2d1342808311c0d9ae8ed189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 17.9 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "18.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.1 K    Total params\n",
      "0.072     Total estimated model params size (MB)\n",
      "                                      \r"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b863459dcee458e98c88906cb5d8b0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 47.6 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "47.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "47.8 K    Total params\n",
      "0.191     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab2b77299c434dcda8ea2aec17ef0a71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 63.0 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "63.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "63.2 K    Total params\n",
      "0.253     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b21a6f9b9b2a4494bf50b8e0e21e2e3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 110 K \n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "110 K     Trainable params\n",
      "0         Non-trainable params\n",
      "110 K     Total params\n",
      "0.442     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b8daca23ac04dd58a967a6f7fce0cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 41.5 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "41.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "41.7 K    Total params\n",
      "0.167     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ced6bbb3d134414bf4c720fe5da3890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 17.2 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "17.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "17.3 K    Total params\n",
      "0.069     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5da960bf3fb4bea9682479c6d4c9503",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 38.4 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "38.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "38.6 K    Total params\n",
      "0.154     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88bb228650e64181ae3b0f85549112dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[AINFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 477 K \n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "477 K     Trainable params\n",
      "0         Non-trainable params\n",
      "477 K     Total params\n",
      "1.912     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9821bea55d244a3a8d9b52d3d9e1e87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 17.2 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "17.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "17.3 K    Total params\n",
      "0.069     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6972075c2810495d9547b152059cfec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "                                      \u001b[A\n",
      "\n",
      "                                      \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[AINFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 532 K \n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "533 K     Trainable params\n",
      "0         Non-trainable params\n",
      "533 K     Total params\n",
      "2.133     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21d8a3bf19dd4999ac819334e682bc21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 90.6 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "90.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "90.8 K    Total params\n",
      "0.363     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a10022c15a12433fa10373b3d2d3a9cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 1.1 M \n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "1.1 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.1 M     Total params\n",
      "4.541     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f11f785d1aec4d63b532996f07f6cd06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                      \n",
      "                                      \u001b[AWARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 201 K \n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "201 K     Trainable params\n",
      "0         Non-trainable params\n",
      "201 K     Total params\n",
      "0.806     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42626671620c476296993946968ff118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                                      \u001b[A\u001b[AINFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 41.5 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "41.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "41.7 K    Total params\n",
      "0.167     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d072a65010b243319cbf5f3e300c5697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 754 K \n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "754 K     Trainable params\n",
      "0         Non-trainable params\n",
      "754 K     Total params\n",
      "3.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d51a50ced92742d5a93f3388aba6083d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                      \n",
      "                                      \u001b[AINFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 188 K \n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "189 K     Trainable params\n",
      "0         Non-trainable params\n",
      "189 K     Total params\n",
      "0.756     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5562ef5eda864b3db89355808631f617",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 29.2 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "29.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "29.4 K    Total params\n",
      "0.118     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac29c89bf694446b90448707044a53d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 90.6 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "90.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "90.8 K    Total params\n",
      "0.363     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42db089b925e4d339dbb87380b09e61a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 17.2 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "17.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "17.3 K    Total params\n",
      "0.069     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f02caa20a67744fd9c76b6928ccf4023",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 385 K \n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "385 K     Trainable params\n",
      "0         Non-trainable params\n",
      "385 K     Total params\n",
      "1.543     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31ae88bc1b8b48a085da399b1d222976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 754 K \n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "754 K     Trainable params\n",
      "0         Non-trainable params\n",
      "754 K     Total params\n",
      "3.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18639fe52769422e840d3de2d2e73d74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\n",
      "                                      \u001b[A\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[AINFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 203 K \n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "203 K     Trainable params\n",
      "0         Non-trainable params\n",
      "203 K     Total params\n",
      "0.816     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11ff8a3ecd594bf1bdacc324e8bd2151",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AINFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 354 K \n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "355 K     Trainable params\n",
      "0         Non-trainable params\n",
      "355 K     Total params\n",
      "1.420     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "939893d47aab49768e263c8c68b59dcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 79.6 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "79.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "79.8 K    Total params\n",
      "0.319     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5aa43c278974fff9b2a12639e8606eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 17.2 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "17.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "17.3 K    Total params\n",
      "0.069     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "251a2ef63dfa44bcada5dfc268547aa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 18.7 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "18.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.9 K    Total params\n",
      "0.076     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0378e229866e43b0b3f79c43e6d28c49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "                                      \u001b[A\u001b[AINFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 532 K \n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "533 K     Trainable params\n",
      "0         Non-trainable params\n",
      "533 K     Total params\n",
      "2.133     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf05c3dbc1a24eeeb53aeca6c9b8b4ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 90.6 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "90.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "90.8 K    Total params\n",
      "0.363     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7c4e728b65e4d62b06dd9ebb1687312",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 41.5 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "41.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "41.7 K    Total params\n",
      "0.167     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0d9691f30de4bc3b926d6afa97aa226",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 24.1 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "24.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "24.3 K    Total params\n",
      "0.097     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7795ec9cf5ff4962888e5014e2b857fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 18.7 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "18.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.9 K    Total params\n",
      "0.076     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d86f5746fcbe4359af575ee66eaf4ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 17.2 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "17.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "17.3 K    Total params\n",
      "0.069     Total estimated model params size (MB)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ca9e808b2b4cf79216a4ddeee5970f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 17.2 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "17.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "17.3 K    Total params\n",
      "0.069     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eb5ee0aed2a4cb1820357fb54ea4946",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 17.9 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "18.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.1 K    Total params\n",
      "0.072     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d5fe56729cc4a96a13d76d507de80bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 17.2 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "17.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "17.3 K    Total params\n",
      "0.069     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab614f3b84814f5884c35089037d9e3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 17.9 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "18.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.1 K    Total params\n",
      "0.072     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6312d4b6751e4063a3f82de4ffbb407c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 17.9 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "18.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.1 K    Total params\n",
      "0.072     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f90c21bddb2441fbfbed65a2af6d60e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AINFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 17.2 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "17.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "17.3 K    Total params\n",
      "0.069     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a797214073f343a9b84c37f6779ac3ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 17.2 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "17.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "17.3 K    Total params\n",
      "0.069     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5305742485cd46f49583145f63efc162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "                                      \u001b[A\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\n",
      "\n",
      "                                      \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AINFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 17.9 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "18.1 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.1 K    Total params\n",
      "0.072     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aca1d08c0fa4554a13696e943debef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 17.2 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "17.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "17.3 K    Total params\n",
      "0.069     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf63ee49bc6b4cdd80132a11b5e0bf2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 20.0 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "20.2 K    Trainable params\n",
      "0         Non-trainable params\n",
      "20.2 K    Total params\n",
      "0.081     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5c0e08476d74a1db7a0e740833f4c8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 17.2 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "17.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "17.3 K    Total params\n",
      "0.069     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22a880941f5946dca1de1ef2b24d59bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[A\u001b[A\n",
      "                                      \u001b[A\n",
      "\n",
      "                                      \u001b[A\u001b[A\n",
      "\n",
      "\n",
      "                                      \u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name      | Type         | Params\n",
      "-------------------------------------------\n",
      "0 | lstm      | LSTM         | 17.2 K\n",
      "1 | linear    | Linear       | 195   \n",
      "2 | loss_func | SmoothL1Loss | 0     \n",
      "-------------------------------------------\n",
      "17.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "17.3 K    Total params\n",
      "0.069     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f89c0369b864a98baa9967d90224083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from neuralprophet.utils.df_utils import split_df\n",
    "\n",
    "metrics = {}\n",
    "\n",
    "counter = 0\n",
    "for dataset_name, df in datasets.items():\n",
    "#     if counter == 1:\n",
    "#         break\n",
    "    \n",
    "    idx_ts = int(dataset_name.split('.')[0].split('_')[-1])-1\n",
    "    freq_number = frequencies.iloc[\n",
    "        idx_ts][[col for col in frequencies.columns if usecase in col][0]]\n",
    "\n",
    "    freq = mapping(frequencies.iloc[\n",
    "        idx_ts][[col for col in frequencies.columns if usecase in col][0]])\n",
    "    \n",
    "    n_lags = freq_number\n",
    "    n_forecasts = 3\n",
    "    \n",
    "    m = LSTM(n_lags = n_lags,\n",
    "            n_forecasts=n_forecasts,\n",
    "            num_hidden_layers=1,\n",
    "            d_hidden=64,\n",
    "            learning_rate=0.1,\n",
    "            epochs=50,\n",
    "            batch_size=None,\n",
    "            loss_func=\"Huber\",\n",
    "            optimizer=\"AdamW\",\n",
    "            train_speed=None,\n",
    "            normalize=\"auto\",\n",
    "            impute_missing=True,\n",
    "            lstm_bias = True,\n",
    "            lstm_bidirectional = False)\n",
    "    \n",
    "    tr, vl = split_df(df, n_lags = n_lags, n_forecasts = n_forecasts, valid_p = valid_p)\n",
    "    m.fit(tr, freq = freq)\n",
    "    future = m.make_future_dataframe(vl, periods = 0, n_historic_predictions=True)\n",
    "    forecast = m.predict(future)\n",
    "    fold = forecast.iloc[n_lags:][[f'yhat{i}' for i in range(1, n_forecasts+1)]]\n",
    "\n",
    "    y_predicted = [np.array(fold).diagonal(offset=-i) for i in range(len(fold) - n_forecasts + 1)]\n",
    "    y = np.array(vl[n_lags:][\"y\"])\n",
    "    y_rolled = [y[i : i + n_forecasts] for i in range(len(y) - n_forecasts + 1)]\n",
    "    \n",
    "    y_naive = np.array(vl[n_lags-1:-1][\"y\"])\n",
    "    y_naive_rolled = [y_naive[i : i + n_forecasts] for i in range(len(y_naive) - n_forecasts + 1)]\n",
    "    \n",
    "    smapes = np.mean([smape(y_rolled[i], y_predicted[i]) for i in range(len(y_rolled))])\n",
    "    mases = np.mean([mase(y_rolled[i], y_predicted[i], y_naive_rolled[i]) for i in range(len(y_rolled))])\n",
    "    mueses = np.mean([mues(y_rolled[i], y_predicted[i]) for i in range(len(y_rolled))])\n",
    "    moeses = np.mean([moes(y_rolled[i], y_predicted[i]) for i in range(len(y_rolled))])\n",
    "    muases = np.mean([muas(y_rolled[i], y_predicted[i]) for i in range(len(y_rolled))])\n",
    "    moases = np.mean([moas(y_rolled[i], y_predicted[i]) for i in range(len(y_rolled))])\n",
    "    \n",
    "    metrics.update({dataset_name:{\n",
    "        'smape': smapes,\n",
    "        'mase': mases,\n",
    "        'mues': mueses,\n",
    "        'moes': moeses,\n",
    "        'muas': muases,\n",
    "        'moas': moases\n",
    "        \n",
    "    }})\n",
    "    \n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fea944f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metrics).to_csv('lstm_libra_fin.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9acd4a63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>finance_33.csv</th>\n",
       "      <th>finance_27.csv</th>\n",
       "      <th>finance_26.csv</th>\n",
       "      <th>finance_32.csv</th>\n",
       "      <th>finance_24.csv</th>\n",
       "      <th>finance_30.csv</th>\n",
       "      <th>finance_18.csv</th>\n",
       "      <th>finance_19.csv</th>\n",
       "      <th>finance_31.csv</th>\n",
       "      <th>finance_25.csv</th>\n",
       "      <th>...</th>\n",
       "      <th>finance_11.csv</th>\n",
       "      <th>finance_39.csv</th>\n",
       "      <th>finance_38.csv</th>\n",
       "      <th>finance_10.csv</th>\n",
       "      <th>finance_28.csv</th>\n",
       "      <th>finance_14.csv</th>\n",
       "      <th>finance_15.csv</th>\n",
       "      <th>finance_29.csv</th>\n",
       "      <th>finance_17.csv</th>\n",
       "      <th>finance_16.csv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>smape</th>\n",
       "      <td>0.748306</td>\n",
       "      <td>1.860831</td>\n",
       "      <td>2.504210</td>\n",
       "      <td>3.745232</td>\n",
       "      <td>3.556806</td>\n",
       "      <td>1.653503</td>\n",
       "      <td>7.379438</td>\n",
       "      <td>4.455019</td>\n",
       "      <td>1.258408</td>\n",
       "      <td>1.973542</td>\n",
       "      <td>...</td>\n",
       "      <td>12.792803</td>\n",
       "      <td>8.789966</td>\n",
       "      <td>8.052506</td>\n",
       "      <td>9.120429</td>\n",
       "      <td>2.329199</td>\n",
       "      <td>9.866039</td>\n",
       "      <td>4.736665</td>\n",
       "      <td>1.915829</td>\n",
       "      <td>7.800125</td>\n",
       "      <td>5.294421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mase</th>\n",
       "      <td>inf</td>\n",
       "      <td>2.413253</td>\n",
       "      <td>5.024394</td>\n",
       "      <td>5.088500</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.073399</td>\n",
       "      <td>2.836589</td>\n",
       "      <td>2.009576</td>\n",
       "      <td>3.709146</td>\n",
       "      <td>1.529645</td>\n",
       "      <td>...</td>\n",
       "      <td>3.055637</td>\n",
       "      <td>0.805823</td>\n",
       "      <td>0.539749</td>\n",
       "      <td>1.230603</td>\n",
       "      <td>2.023913</td>\n",
       "      <td>2.559182</td>\n",
       "      <td>1.348744</td>\n",
       "      <td>2.375485</td>\n",
       "      <td>2.027867</td>\n",
       "      <td>1.490802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mues</th>\n",
       "      <td>0.639344</td>\n",
       "      <td>0.803409</td>\n",
       "      <td>0.888228</td>\n",
       "      <td>0.939891</td>\n",
       "      <td>0.883792</td>\n",
       "      <td>0.814208</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.639344</td>\n",
       "      <td>0.551984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.786667</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.680162</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.340426</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moes</th>\n",
       "      <td>0.360656</td>\n",
       "      <td>0.196591</td>\n",
       "      <td>0.111772</td>\n",
       "      <td>0.060109</td>\n",
       "      <td>0.116208</td>\n",
       "      <td>0.185792</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.360656</td>\n",
       "      <td>0.448016</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.213333</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.319838</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>muas</th>\n",
       "      <td>0.004857</td>\n",
       "      <td>0.016921</td>\n",
       "      <td>0.021587</td>\n",
       "      <td>0.037087</td>\n",
       "      <td>0.033485</td>\n",
       "      <td>0.016246</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006407</td>\n",
       "      <td>0.009913</td>\n",
       "      <td>0.012522</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117061</td>\n",
       "      <td>0.092376</td>\n",
       "      <td>0.080543</td>\n",
       "      <td>0.014734</td>\n",
       "      <td>0.018837</td>\n",
       "      <td>0.093593</td>\n",
       "      <td>0.046809</td>\n",
       "      <td>0.008421</td>\n",
       "      <td>0.072139</td>\n",
       "      <td>0.049054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moas</th>\n",
       "      <td>0.003771</td>\n",
       "      <td>0.003771</td>\n",
       "      <td>0.009976</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>0.004777</td>\n",
       "      <td>0.077992</td>\n",
       "      <td>0.048852</td>\n",
       "      <td>0.004268</td>\n",
       "      <td>0.010574</td>\n",
       "      <td>...</td>\n",
       "      <td>0.026323</td>\n",
       "      <td>0.016641</td>\n",
       "      <td>0.002274</td>\n",
       "      <td>0.109072</td>\n",
       "      <td>0.007958</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017548</td>\n",
       "      <td>0.015556</td>\n",
       "      <td>0.010677</td>\n",
       "      <td>0.010799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows  100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       finance_33.csv  finance_27.csv  finance_26.csv  finance_32.csv  \\\n",
       "smape        0.748306        1.860831        2.504210        3.745232   \n",
       "mase              inf        2.413253        5.024394        5.088500   \n",
       "mues         0.639344        0.803409        0.888228        0.939891   \n",
       "moes         0.360656        0.196591        0.111772        0.060109   \n",
       "muas         0.004857        0.016921        0.021587        0.037087   \n",
       "moas         0.003771        0.003771        0.009976        0.000622   \n",
       "\n",
       "       finance_24.csv  finance_30.csv  finance_18.csv  finance_19.csv  \\\n",
       "smape        3.556806        1.653503        7.379438        4.455019   \n",
       "mase              inf        1.073399        2.836589        2.009576   \n",
       "mues         0.883792        0.814208        0.000000        0.142857   \n",
       "moes         0.116208        0.185792        1.000000        0.857143   \n",
       "muas         0.033485        0.016246        0.000000        0.006407   \n",
       "moas         0.002632        0.004777        0.077992        0.048852   \n",
       "\n",
       "       finance_31.csv  finance_25.csv  ...  finance_11.csv  finance_39.csv  \\\n",
       "smape        1.258408        1.973542  ...       12.792803        8.789966   \n",
       "mase         3.709146        1.529645  ...        3.055637        0.805823   \n",
       "mues         0.639344        0.551984  ...        0.888889        0.786667   \n",
       "moes         0.360656        0.448016  ...        0.111111        0.213333   \n",
       "muas         0.009913        0.012522  ...        0.117061        0.092376   \n",
       "moas         0.004268        0.010574  ...        0.026323        0.016641   \n",
       "\n",
       "       finance_38.csv  finance_10.csv  finance_28.csv  finance_14.csv  \\\n",
       "smape        8.052506        9.120429        2.329199        9.866039   \n",
       "mase         0.539749        1.230603        2.023913        2.559182   \n",
       "mues         0.928571        0.222222        0.680162        1.000000   \n",
       "moes         0.071429        0.777778        0.319838        0.000000   \n",
       "muas         0.080543        0.014734        0.018837        0.093593   \n",
       "moas         0.002274        0.109072        0.007958        0.000000   \n",
       "\n",
       "       finance_15.csv  finance_29.csv  finance_17.csv  finance_16.csv  \n",
       "smape        4.736665        1.915829        7.800125        5.294421  \n",
       "mase         1.348744        2.375485        2.027867        1.490802  \n",
       "mues         0.722222        0.340426        0.833333        0.666667  \n",
       "moes         0.277778        0.659574        0.166667        0.333333  \n",
       "muas         0.046809        0.008421        0.072139        0.049054  \n",
       "moas         0.017548        0.015556        0.010677        0.010799  \n",
       "\n",
       "[6 rows x 100 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bedb625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b171e833",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0855e13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "42ca7b64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling weekly seasonality. Run NeuralProphet with weekly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 12    \n",
      "1 | ar_net        | ModuleList    | 1.0 K \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "1.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.0 K     Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a71d96f25ba446ab14ebb2bdf44a685",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 320   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "351       Trainable params\n",
      "0         Non-trainable params\n",
      "351       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcaf1fb3c19d46ee9deca9d26a140d6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 320   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "351       Trainable params\n",
      "0         Non-trainable params\n",
      "351       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b859e617a4aa42e5ad070b539790b405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling weekly seasonality. Run NeuralProphet with weekly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 12    \n",
      "1 | ar_net        | ModuleList    | 1.0 K \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "1.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.0 K     Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dfd927f56594aaf929cc35caa3488b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 6     \n",
      "1 | ar_net        | ModuleList    | 320   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "339       Trainable params\n",
      "0         Non-trainable params\n",
      "339       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c45f84b6e0849e28c3957fa4f1ce4f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling weekly seasonality. Run NeuralProphet with weekly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 12    \n",
      "1 | ar_net        | ModuleList    | 1.0 K \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "1.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.0 K     Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f7d77d131224c5f9bd69974f53c7dc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 6     \n",
      "1 | ar_net        | ModuleList    | 320   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "339       Trainable params\n",
      "0         Non-trainable params\n",
      "339       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "  0%|          | 0/50 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54b935fa35ac44039d88a277dfd09457",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 6     \n",
      "1 | ar_net        | ModuleList    | 320   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "339       Trainable params\n",
      "0         Non-trainable params\n",
      "339       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb16d16903fb43fca507de78d2a8a58a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling weekly seasonality. Run NeuralProphet with weekly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 12    \n",
      "1 | ar_net        | ModuleList    | 1.0 K \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "1.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.0 K     Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f687fe0bb68a41749b38581fba8d5b3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:04<?, ?it/s]\n",
      "  0%|          | 0/50 [00:03<?, ?it/s]\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 320   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "351       Trainable params\n",
      "0         Non-trainable params\n",
      "351       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5590925e242c4ae6b3ff762154a8ae80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [02:42<?, ?it/s]\n",
      "  0%|          | 0/50 [02:14<?, ?it/s]\n",
      "  0%|          | 0/50 [02:07<?, ?it/s]\n",
      "  0%|          | 0/50 [02:03<?, ?it/s]\n",
      "  0%|          | 0/50 [01:38<?, ?it/s]\n",
      "  0%|          | 0/50 [01:33<?, ?it/s]\n",
      "  0%|          | 0/50 [01:08<?, ?it/s]\n",
      "  0%|          | 0/50 [00:44<?, ?it/s]\n",
      "  0%|          | 0/50 [00:40<?, ?it/s]\n",
      "  0%|          | 0/50 [00:30<?, ?it/s]\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 6     \n",
      "1 | ar_net        | ModuleList    | 320   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "339       Trainable params\n",
      "0         Non-trainable params\n",
      "339       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e875602277cd4035b773c7c8fd3931ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling weekly seasonality. Run NeuralProphet with weekly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 12    \n",
      "1 | ar_net        | ModuleList    | 1.0 K \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "1.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.0 K     Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b789ec57260f4e0eb1aaf437a2c61e57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling weekly seasonality. Run NeuralProphet with weekly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 12    \n",
      "1 | ar_net        | ModuleList    | 1.0 K \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "1.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.0 K     Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ceb2db268904072aa0c1e11d5c76e9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 6     \n",
      "1 | ar_net        | ModuleList    | 320   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "339       Trainable params\n",
      "0         Non-trainable params\n",
      "339       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "  0%|          | 0/50 [00:04<?, ?it/s]\n",
      "  0%|          | 0/50 [00:04<?, ?it/s]\n",
      "  0%|          | 0/50 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d51172c423547819e9c7e2462caab20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling weekly seasonality. Run NeuralProphet with weekly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 12    \n",
      "1 | ar_net        | ModuleList    | 1.0 K \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "1.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.0 K     Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bf51ad8ac084deba1c7ca4de89b5e4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 6     \n",
      "1 | ar_net        | ModuleList    | 320   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "339       Trainable params\n",
      "0         Non-trainable params\n",
      "339       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14f2c79d60b047ac8b9bcf2faa2f07de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 6     \n",
      "1 | ar_net        | ModuleList    | 320   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "339       Trainable params\n",
      "0         Non-trainable params\n",
      "339       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9b0d14b09c54f8ea10d27dda678199e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling weekly seasonality. Run NeuralProphet with weekly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 12    \n",
      "1 | ar_net        | ModuleList    | 512   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "537       Trainable params\n",
      "0         Non-trainable params\n",
      "537       Total params\n",
      "0.002     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7661fbf03f564652b8d77011a3cd3846",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:04<?, ?it/s]\n",
      "  0%|          | 0/50 [00:01<?, ?it/s]\n",
      "  0%|          | 0/50 [00:01<?, ?it/s]\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 6     \n",
      "1 | ar_net        | ModuleList    | 320   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "339       Trainable params\n",
      "0         Non-trainable params\n",
      "339       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e22a642f458d4e96b79636258e512c35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 23.3 K\n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "23.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "23.3 K    Total params\n",
      "0.093     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b98a24c757480d9dddd1aca94e5f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:02<?, ?it/s]\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 129 K \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "129 K     Trainable params\n",
      "0         Non-trainable params\n",
      "129 K     Total params\n",
      "0.517     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f83d6069f9a467e8058bb559cba6992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [01:17<?, ?it/s]\n",
      "  0%|          | 0/50 [00:45<?, ?it/s]\n",
      "  0%|          | 0/50 [00:40<?, ?it/s]\n",
      "  0%|          | 0/50 [00:38<?, ?it/s]\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling weekly seasonality. Run NeuralProphet with weekly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 12    \n",
      "1 | ar_net        | ModuleList    | 704   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "729       Trainable params\n",
      "0         Non-trainable params\n",
      "729       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7993693e9674e438420df9640cd1f14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling weekly seasonality. Run NeuralProphet with weekly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 12    \n",
      "1 | ar_net        | ModuleList    | 704   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "729       Trainable params\n",
      "0         Non-trainable params\n",
      "729       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ac070f2d524165b6e0a4005c214f8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 92.4 K\n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "92.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "92.4 K    Total params\n",
      "0.370     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5561e24c7a84fc0a12db67e00cfedc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling weekly seasonality. Run NeuralProphet with weekly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 12    \n",
      "1 | ar_net        | ModuleList    | 704   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "729       Trainable params\n",
      "0         Non-trainable params\n",
      "729       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e66e3c42410a4a79ad37b7c244de0aba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling weekly seasonality. Run NeuralProphet with weekly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 12    \n",
      "1 | ar_net        | ModuleList    | 704   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "729       Trainable params\n",
      "0         Non-trainable params\n",
      "729       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "  0%|          | 0/50 [00:03<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c78c43c99cec4d14b1038a07d5c37e75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [01:54<?, ?it/s]\n",
      "  0%|          | 0/50 [01:06<?, ?it/s]\n",
      "  0%|          | 0/50 [00:53<?, ?it/s]\n",
      "  0%|          | 0/50 [00:43<?, ?it/s]\n",
      "  0%|          | 0/50 [00:10<?, ?it/s]\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 23.3 K\n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "23.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "23.3 K    Total params\n",
      "0.093     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a18cb6c1a874db4926c06932cca8c4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling weekly seasonality. Run NeuralProphet with weekly_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 12    \n",
      "1 | ar_net        | ModuleList    | 6.4 K \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "6.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.4 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fe687db725a40898bb1111b9e038163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:02<?, ?it/s]\n",
      "  0%|          | 0/50 [00:52<?, ?it/s]\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 43.3 K\n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "43.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "43.3 K    Total params\n",
      "0.173     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cdbaf81165e477989f10075c6b66b98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 6     \n",
      "1 | ar_net        | ModuleList    | 320   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "339       Trainable params\n",
      "0         Non-trainable params\n",
      "339       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "255cc7147d844e5da87dd631f813c292",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 6     \n",
      "1 | ar_net        | ModuleList    | 320   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "339       Trainable params\n",
      "0         Non-trainable params\n",
      "339       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "682a5b8165484c96be59fd7e4ea42694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:02<?, ?it/s]\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 6     \n",
      "1 | ar_net        | ModuleList    | 320   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "339       Trainable params\n",
      "0         Non-trainable params\n",
      "339       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c445895667045f898f195c22aaac7c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 6.4 K \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "6.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.4 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37d6b6a95dbc4cfe846d0793cb31893c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 31.0 K\n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "31.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "31.0 K    Total params\n",
      "0.124     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "933ab5b721b246f58fe302f424f6d274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [02:22<?, ?it/s]\n",
      "  0%|          | 0/50 [01:07<?, ?it/s]\n",
      "  0%|          | 0/50 [01:02<?, ?it/s]\n",
      "  0%|          | 0/50 [00:38<?, ?it/s]\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling weekly seasonality. Run NeuralProphet with weekly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 12    \n",
      "1 | ar_net        | ModuleList    | 704   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "729       Trainable params\n",
      "0         Non-trainable params\n",
      "729       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "639ea597356e44bfa0f07fdae86c41c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 43.3 K\n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "43.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "43.3 K    Total params\n",
      "0.173     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "321c8562e3a64ff885492eba657aa3f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 23.3 K\n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "23.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "23.3 K    Total params\n",
      "0.093     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e263f24df8445e93e3da8d7b7e32a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling weekly seasonality. Run NeuralProphet with weekly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 12    \n",
      "1 | ar_net        | ModuleList    | 704   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "729       Trainable params\n",
      "0         Non-trainable params\n",
      "729       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e87ef2d7566c44419b54a5ec7239cc1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [01:20<?, ?it/s]\n",
      "  0%|          | 0/50 [01:12<?, ?it/s]\n",
      "  0%|          | 0/50 [00:13<?, ?it/s]\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 15.6 K\n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "15.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "15.6 K    Total params\n",
      "0.063     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6433090cd3f54ddd945f5b20b9bed430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 92.4 K\n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "92.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "92.4 K    Total params\n",
      "0.370     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f7e101d97684637ac609b5468758eea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [01:20<?, ?it/s]\n",
      "  0%|          | 0/50 [01:11<?, ?it/s]\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling weekly seasonality. Run NeuralProphet with weekly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 12    \n",
      "1 | ar_net        | ModuleList    | 512   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "537       Trainable params\n",
      "0         Non-trainable params\n",
      "537       Total params\n",
      "0.002     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c62014efd9294ef89beb75be9ee24e1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 6     \n",
      "1 | ar_net        | ModuleList    | 320   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "339       Trainable params\n",
      "0         Non-trainable params\n",
      "339       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c043d31d7cb34c188e50e9b024768073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:01<?, ?it/s]\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 6     \n",
      "1 | ar_net        | ModuleList    | 2.2 K \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "2.2 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.2 K     Total params\n",
      "0.009     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c564d7b5a74939a5f0239ca3202ff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:01<?, ?it/s]\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 47.0 K\n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "47.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "47.0 K    Total params\n",
      "0.188     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5a70a859a1445f18ddfd37ff8d65d2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [01:33<?, ?it/s]\n",
      "  0%|          | 0/50 [00:19<?, ?it/s]\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling weekly seasonality. Run NeuralProphet with weekly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 12    \n",
      "1 | ar_net        | ModuleList    | 704   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "729       Trainable params\n",
      "0         Non-trainable params\n",
      "729       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b01abe8a7334413c8ff2bd71ac14667c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:04<?, ?it/s]\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 92.4 K\n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "92.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "92.4 K    Total params\n",
      "0.370     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c609d5a1e654ff4b2c8201c5d179544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [01:10<?, ?it/s]\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 92.4 K\n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "92.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "92.4 K    Total params\n",
      "0.370     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c498a2177824deea0c29a2c80cb2233",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling weekly seasonality. Run NeuralProphet with weekly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 12    \n",
      "1 | ar_net        | ModuleList    | 704   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "729       Trainable params\n",
      "0         Non-trainable params\n",
      "729       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54f01efdfb6b4c4f96bce79054339132",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 23.3 K\n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "23.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "23.3 K    Total params\n",
      "0.093     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3da680c3bd445efa07a965d13d30c56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 129 K \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "129 K     Trainable params\n",
      "0         Non-trainable params\n",
      "129 K     Total params\n",
      "0.517     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faf4c5d7905d458081725d7b772b8e7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [01:33<?, ?it/s]\n",
      "  0%|          | 0/50 [01:06<?, ?it/s]\n",
      "  0%|          | 0/50 [00:35<?, ?it/s]\n",
      "  0%|          | 0/50 [00:27<?, ?it/s]\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling weekly seasonality. Run NeuralProphet with weekly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 12    \n",
      "1 | ar_net        | ModuleList    | 512   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "537       Trainable params\n",
      "0         Non-trainable params\n",
      "537       Total params\n",
      "0.002     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "369f8dd8d7584a46b48a5c0e4920a315",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 4.1 K \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.1 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3da72ad637b4be6bfcc7fa1b6eb15f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 6.4 K \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "6.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.4 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4050783300c8446699aa798aeac82dfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 21.8 K\n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "21.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "21.8 K    Total params\n",
      "0.087     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a057167bb0f46e6a4ee03ced56e72cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [01:31<?, ?it/s]\n",
      "  0%|          | 0/50 [00:43<?, ?it/s]\n",
      "  0%|          | 0/50 [00:12<?, ?it/s]\n",
      "  0%|          | 0/50 [00:07<?, ?it/s]\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 4.1 K \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "4.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "4.1 K     Total params\n",
      "0.017     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "417ad1f5e35a4b4287b1e5baf925e4c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling weekly seasonality. Run NeuralProphet with weekly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 12    \n",
      "1 | ar_net        | ModuleList    | 704   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "729       Trainable params\n",
      "0         Non-trainable params\n",
      "729       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "619b22cd4da345a6902a6930ea165d45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling weekly seasonality. Run NeuralProphet with weekly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 12    \n",
      "1 | ar_net        | ModuleList    | 512   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "537       Trainable params\n",
      "0         Non-trainable params\n",
      "537       Total params\n",
      "0.002     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "947e09f210614ce4bb97d44dccd52882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:06<?, ?it/s]\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 6     \n",
      "1 | ar_net        | ModuleList    | 7.9 K \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "8.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "8.0 K     Total params\n",
      "0.032     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0594bbef678451c948664a111d3d29d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 11.8 K\n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "11.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "11.8 K    Total params\n",
      "0.047     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d96c2275b566405cb001e82a8ff0af4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:03<?, ?it/s]\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 23.6 K\n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "23.6 K    Trainable params\n",
      "0         Non-trainable params\n",
      "23.6 K    Total params\n",
      "0.095     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a1404edfca948a6b68bead85fea8587",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling weekly seasonality. Run NeuralProphet with weekly_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 12    \n",
      "1 | ar_net        | ModuleList    | 6.4 K \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "6.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.4 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f57ab8bc9fb4ac0b5edf1db7190bc6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 6     \n",
      "1 | ar_net        | ModuleList    | 320   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "339       Trainable params\n",
      "0         Non-trainable params\n",
      "339       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "556e6f88207b4cd4af39fb1c203f5b3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 6     \n",
      "1 | ar_net        | ModuleList    | 5.6 K \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "5.7 K     Trainable params\n",
      "0         Non-trainable params\n",
      "5.7 K     Total params\n",
      "0.023     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b54dfaef23ad465f8fa901fc3b7d0d4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:03<?, ?it/s]\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 115 K \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "115 K     Trainable params\n",
      "0         Non-trainable params\n",
      "115 K     Total params\n",
      "0.462     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a90ee82b142464ba203b5e52884cb8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [01:58<?, ?it/s]\n",
      "  0%|          | 0/50 [01:22<?, ?it/s]\n",
      "  0%|          | 0/50 [01:17<?, ?it/s]\n",
      "  0%|          | 0/50 [01:06<?, ?it/s]\n",
      "  0%|          | 0/50 [00:39<?, ?it/s]\n",
      "  0%|          | 0/50 [00:35<?, ?it/s]\n",
      "  0%|          | 0/50 [00:28<?, ?it/s]\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 6     \n",
      "1 | ar_net        | ModuleList    | 320   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "339       Trainable params\n",
      "0         Non-trainable params\n",
      "339       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80738b5924114e88b99061e366a3230b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "  0%|          | 0/50 [00:05<?, ?it/s]\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 129 K \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "129 K     Trainable params\n",
      "0         Non-trainable params\n",
      "129 K     Total params\n",
      "0.517     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "740b9a8f66db42d899b842b760d7867a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 6     \n",
      "1 | ar_net        | ModuleList    | 18.7 K\n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "18.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.7 K    Total params\n",
      "0.075     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "457be613fc42487c8fcbd285dcc61344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 279 K \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "279 K     Trainable params\n",
      "0         Non-trainable params\n",
      "279 K     Total params\n",
      "1.119     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dab0ceb1c90e41aaa1892b4b85cc036d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [01:38<?, ?it/s]\n",
      "  0%|          | 0/50 [00:50<?, ?it/s]\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 46.3 K\n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "46.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "46.4 K    Total params\n",
      "0.185     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10aa512561b04504a8066204fe032153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [01:21<?, ?it/s]\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 6.4 K \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "6.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.4 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34b5d77566ac441dadf1dd72108cd24f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 184 K \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "184 K     Trainable params\n",
      "0         Non-trainable params\n",
      "184 K     Total params\n",
      "0.738     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b80b71680aa404bbffcdf269be40fff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [01:25<?, ?it/s]\n",
      "  0%|          | 0/50 [00:11<?, ?it/s]\n",
      "  0%|          | 0/50 [00:56<?, ?it/s]\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 43.3 K\n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "43.3 K    Trainable params\n",
      "0         Non-trainable params\n",
      "43.3 K    Total params\n",
      "0.173     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f2a6a610ef149a9962213281906dfb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 3.3 K \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "3.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "3.4 K     Total params\n",
      "0.013     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e4e35227431494ca3bafabe691bf55e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 18.7 K\n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "18.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.7 K    Total params\n",
      "0.075     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83878377d7dd47afbd48fb2382ac32ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 320   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "351       Trainable params\n",
      "0         Non-trainable params\n",
      "351       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad22d9037f84407e9f367f3291678734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 92.4 K\n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "92.4 K    Trainable params\n",
      "0         Non-trainable params\n",
      "92.4 K    Total params\n",
      "0.370     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "749b4fffc1244c30b2bf0852da469a0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 184 K \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "184 K     Trainable params\n",
      "0         Non-trainable params\n",
      "184 K     Total params\n",
      "0.738     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7edbb5bab4df42d09dda34099a93cd26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [01:22<?, ?it/s]\n",
      "  0%|          | 0/50 [00:59<?, ?it/s]\n",
      "  0%|          | 0/50 [00:50<?, ?it/s]\n",
      "  0%|          | 0/50 [00:40<?, ?it/s]\n",
      "  0%|          | 0/50 [00:32<?, ?it/s]\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 47.0 K\n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "47.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "47.0 K    Total params\n",
      "0.188     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23e031fdce1c455bb84cd5c302fad9d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [01:42<?, ?it/s]\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 84.7 K\n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "84.8 K    Trainable params\n",
      "0         Non-trainable params\n",
      "84.8 K    Total params\n",
      "0.339     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b27b5b117a9c4ff088dd0450775436dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [01:53<?, ?it/s]\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 15.9 K\n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "16.0 K    Trainable params\n",
      "0         Non-trainable params\n",
      "16.0 K    Total params\n",
      "0.064     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08af78550ad24c22acbe6fc106264265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 6     \n",
      "1 | ar_net        | ModuleList    | 320   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "339       Trainable params\n",
      "0         Non-trainable params\n",
      "339       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60bbcc44e25a4ce19774d478859364b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling weekly seasonality. Run NeuralProphet with weekly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 12    \n",
      "1 | ar_net        | ModuleList    | 704   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "729       Trainable params\n",
      "0         Non-trainable params\n",
      "729       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "216edb878b844e158c2a1e371a38d008",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:05<?, ?it/s]\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 64\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 129 K \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "129 K     Trainable params\n",
      "0         Non-trainable params\n",
      "129 K     Total params\n",
      "0.517     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b20a3725691d43e99e68aa2d2f350bc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [01:53<?, ?it/s]\n",
      "  0%|          | 0/50 [01:10<?, ?it/s]\n",
      "  0%|          | 0/50 [01:00<?, ?it/s]\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 6     \n",
      "1 | ar_net        | ModuleList    | 18.7 K\n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "18.7 K    Trainable params\n",
      "0         Non-trainable params\n",
      "18.7 K    Total params\n",
      "0.075     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64e4a0e07ae6483f99d894247babb45c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 6.4 K \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "6.4 K     Trainable params\n",
      "0         Non-trainable params\n",
      "6.4 K     Total params\n",
      "0.026     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "532a34dd11b9412498ae384cb4fde8a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 6     \n",
      "1 | ar_net        | ModuleList    | 2.0 K \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "2.1 K     Trainable params\n",
      "0         Non-trainable params\n",
      "2.1 K     Total params\n",
      "0.008     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79bf2cb16aad434998360414f24d2a4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:02<?, ?it/s]\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling weekly seasonality. Run NeuralProphet with weekly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 12    \n",
      "1 | ar_net        | ModuleList    | 704   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "729       Trainable params\n",
      "0         Non-trainable params\n",
      "729       Total params\n",
      "0.003     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7be05353475b48e8b7092436638a22e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 6     \n",
      "1 | ar_net        | ModuleList    | 320   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "339       Trainable params\n",
      "0         Non-trainable params\n",
      "339       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed07c4750f134fb7ab14c07be6a33ce6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "  0%|          | 0/50 [00:05<?, ?it/s]\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 6     \n",
      "1 | ar_net        | ModuleList    | 320   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "339       Trainable params\n",
      "0         Non-trainable params\n",
      "339       Total params\n",
      "0.001     Total estimated model params size (MB)\n",
      "  0%|          | 0/50 [00:10<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d7eaa5e80ba46de837e27fa560eeb6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling weekly seasonality. Run NeuralProphet with weekly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 12    \n",
      "1 | ar_net        | ModuleList    | 512   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "537       Trainable params\n",
      "0         Non-trainable params\n",
      "537       Total params\n",
      "0.002     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3536eca3b82f4f9480c4e6d9f3cebb4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 6     \n",
      "1 | ar_net        | ModuleList    | 320   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "339       Trainable params\n",
      "0         Non-trainable params\n",
      "339       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef6c11d5a1cc42d4aaa6fd7601fd3006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling weekly seasonality. Run NeuralProphet with weekly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 12    \n",
      "1 | ar_net        | ModuleList    | 512   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "537       Trainable params\n",
      "0         Non-trainable params\n",
      "537       Total params\n",
      "0.002     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd3b6c473167406899ac47ca816e8d63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling weekly seasonality. Run NeuralProphet with weekly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 12    \n",
      "1 | ar_net        | ModuleList    | 512   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "537       Trainable params\n",
      "0         Non-trainable params\n",
      "537       Total params\n",
      "0.002     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5b51f95c9df4d01b626b618971f2cf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:03<?, ?it/s]\n",
      "  0%|          | 0/50 [00:03<?, ?it/s]\n",
      "  0%|          | 0/50 [00:02<?, ?it/s]\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 6     \n",
      "1 | ar_net        | ModuleList    | 320   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "339       Trainable params\n",
      "0         Non-trainable params\n",
      "339       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7643b0e3012b491fb79deb3c8c6c5466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 32\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 18    \n",
      "1 | ar_net        | ModuleList    | 320   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "351       Trainable params\n",
      "0         Non-trainable params\n",
      "351       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06b997dae9ea4e5f9a69a95ed1935694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling weekly seasonality. Run NeuralProphet with weekly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 12    \n",
      "1 | ar_net        | ModuleList    | 512   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "537       Trainable params\n",
      "0         Non-trainable params\n",
      "537       Total params\n",
      "0.002     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3af1cf4773742899ee29f92a96ac9a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 6     \n",
      "1 | ar_net        | ModuleList    | 320   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "339       Trainable params\n",
      "0         Non-trainable params\n",
      "339       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69f8e07a9bf0423d8810406e6d955d53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling weekly seasonality. Run NeuralProphet with weekly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 12    \n",
      "1 | ar_net        | ModuleList    | 1.0 K \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "1.0 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.0 K     Total params\n",
      "0.004     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fe82c2f0bb640699fda91e67667bb31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:02<?, ?it/s]\n",
      "  0%|          | 0/50 [00:02<?, ?it/s]\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 6     \n",
      "1 | ar_net        | ModuleList    | 320   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "339       Trainable params\n",
      "0         Non-trainable params\n",
      "339       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fe67c228237475fbc1c4317dba7c7e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling yearly seasonality. Run NeuralProphet with yearly_seasonality=True to override this.\n",
      "INFO - (NP.utils.set_auto_seasonalities) - Disabling daily seasonality. Run NeuralProphet with daily_seasonality=True to override this.\n",
      "INFO - (NP.config.set_auto_batch_epoch) - Auto-set batch_size to 16\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/50 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[AGPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: you defined a validation_step but have no val_dataloader. Skipping validation loop\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n",
      "\n",
      "  | Name          | Type          | Params\n",
      "------------------------------------------------\n",
      "0 | season_params | ParameterDict | 6     \n",
      "1 | ar_net        | ModuleList    | 320   \n",
      "2 | loss_func     | SmoothL1Loss  | 0     \n",
      "------------------------------------------------\n",
      "339       Trainable params\n",
      "0         Non-trainable params\n",
      "339       Total params\n",
      "0.001     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation sanity check: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pytorch_lightning/utilities/distributed.py:68: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12a63e986e6641f9b03a7089c0177bd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from neuralprophet.utils.df_utils import split_df\n",
    "\n",
    "metrics = {}\n",
    "\n",
    "counter = 0\n",
    "for dataset_name, df in datasets.items():\n",
    "#     if counter == 1:\n",
    "#         break\n",
    "    \n",
    "    idx_ts = int(dataset_name.split('.')[0].split('_')[-1])-1\n",
    "    freq_number = frequencies.iloc[\n",
    "        idx_ts][[col for col in frequencies.columns if usecase in col][0]]\n",
    "    freq = mapping(frequencies.iloc[\n",
    "        idx_ts][[col for col in frequencies.columns if usecase in col][0]])\n",
    "    \n",
    "    n_lags = freq_number\n",
    "    n_forecasts = 3\n",
    "    \n",
    "    m = NeuralProphet(n_lags = n_lags,\n",
    "            n_forecasts=n_forecasts,\n",
    "            num_hidden_layers=1,\n",
    "            d_hidden=64,\n",
    "            learning_rate=0.1,\n",
    "            epochs=50,\n",
    "            batch_size=None,\n",
    "            loss_func=\"Huber\",\n",
    "            optimizer=\"AdamW\",\n",
    "            train_speed=None,\n",
    "            normalize=\"auto\",\n",
    "            impute_missing=True,)\n",
    "    \n",
    "    tr, vl = split_df(df, n_lags = n_lags, n_forecasts = n_forecasts, valid_p = valid_p)\n",
    "    m.fit(tr, freq = freq)\n",
    "    future = m.make_future_dataframe(vl, periods = 0, n_historic_predictions=True)\n",
    "    forecast = m.predict(future)\n",
    "    fold = forecast.iloc[n_lags:][[f'yhat{i}' for i in range(1, n_forecasts+1)]]\n",
    "\n",
    "    y_predicted = [np.array(fold).diagonal(offset=-i) for i in range(len(fold) - n_forecasts + 1)]\n",
    "    y = np.array(vl[n_lags:][\"y\"])\n",
    "    y_rolled = [y[i : i + n_forecasts] for i in range(len(y) - n_forecasts + 1)]\n",
    "    \n",
    "    y_naive = np.array(vl[n_lags-1:-1][\"y\"])\n",
    "    y_naive_rolled = [y_naive[i : i + n_forecasts] for i in range(len(y_naive) - n_forecasts + 1)]\n",
    "    \n",
    "    smapes = np.mean([smape(y_rolled[i], y_predicted[i]) for i in range(len(y_rolled))])\n",
    "    mases = np.mean([mase(y_rolled[i], y_predicted[i], y_naive_rolled[i]) for i in range(len(y_rolled))])\n",
    "    mueses = np.mean([mues(y_rolled[i], y_predicted[i]) for i in range(len(y_rolled))])\n",
    "    moeses = np.mean([moes(y_rolled[i], y_predicted[i]) for i in range(len(y_rolled))])\n",
    "    muases = np.mean([muas(y_rolled[i], y_predicted[i]) for i in range(len(y_rolled))])\n",
    "    moases = np.mean([moas(y_rolled[i], y_predicted[i]) for i in range(len(y_rolled))])\n",
    "    \n",
    "    metrics.update({dataset_name:{\n",
    "        'smape': smapes,\n",
    "        'mase': mases,\n",
    "        'mues': mueses,\n",
    "        'moes': moeses,\n",
    "        'muas': muases,\n",
    "        'moas': moases\n",
    "        \n",
    "    }})\n",
    "    \n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a46f8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b7602f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metrics).to_csv('np_libra_fin.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f538635d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>finance_33.csv</th>\n",
       "      <th>finance_27.csv</th>\n",
       "      <th>finance_26.csv</th>\n",
       "      <th>finance_32.csv</th>\n",
       "      <th>finance_24.csv</th>\n",
       "      <th>finance_30.csv</th>\n",
       "      <th>finance_18.csv</th>\n",
       "      <th>finance_19.csv</th>\n",
       "      <th>finance_31.csv</th>\n",
       "      <th>finance_25.csv</th>\n",
       "      <th>...</th>\n",
       "      <th>finance_11.csv</th>\n",
       "      <th>finance_39.csv</th>\n",
       "      <th>finance_38.csv</th>\n",
       "      <th>finance_10.csv</th>\n",
       "      <th>finance_28.csv</th>\n",
       "      <th>finance_14.csv</th>\n",
       "      <th>finance_15.csv</th>\n",
       "      <th>finance_29.csv</th>\n",
       "      <th>finance_17.csv</th>\n",
       "      <th>finance_16.csv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>smape</th>\n",
       "      <td>1.768175</td>\n",
       "      <td>1.785110</td>\n",
       "      <td>4.839014</td>\n",
       "      <td>4.430679</td>\n",
       "      <td>13.943318</td>\n",
       "      <td>2.024036</td>\n",
       "      <td>12.391023</td>\n",
       "      <td>11.585891</td>\n",
       "      <td>6.617646</td>\n",
       "      <td>4.756577</td>\n",
       "      <td>...</td>\n",
       "      <td>15.908761</td>\n",
       "      <td>6.388955</td>\n",
       "      <td>64.770169</td>\n",
       "      <td>42.508554</td>\n",
       "      <td>3.492355</td>\n",
       "      <td>13.705860</td>\n",
       "      <td>9.806658</td>\n",
       "      <td>3.120847</td>\n",
       "      <td>6.812100</td>\n",
       "      <td>7.053095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mase</th>\n",
       "      <td>inf</td>\n",
       "      <td>2.256139</td>\n",
       "      <td>9.230062</td>\n",
       "      <td>6.938760</td>\n",
       "      <td>inf</td>\n",
       "      <td>1.408215</td>\n",
       "      <td>4.176157</td>\n",
       "      <td>7.139150</td>\n",
       "      <td>19.561150</td>\n",
       "      <td>5.030666</td>\n",
       "      <td>...</td>\n",
       "      <td>3.876151</td>\n",
       "      <td>0.622159</td>\n",
       "      <td>3.229358</td>\n",
       "      <td>7.226101</td>\n",
       "      <td>3.297267</td>\n",
       "      <td>3.442897</td>\n",
       "      <td>2.734479</td>\n",
       "      <td>4.114496</td>\n",
       "      <td>2.133255</td>\n",
       "      <td>2.546827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mues</th>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.754261</td>\n",
       "      <td>0.597305</td>\n",
       "      <td>0.726776</td>\n",
       "      <td>0.660550</td>\n",
       "      <td>0.273224</td>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.897619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.413333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.454341</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.489362</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.380952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moes</th>\n",
       "      <td>0.426230</td>\n",
       "      <td>0.245739</td>\n",
       "      <td>0.402695</td>\n",
       "      <td>0.273224</td>\n",
       "      <td>0.339450</td>\n",
       "      <td>0.726776</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.102381</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.586667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.545659</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.510638</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.619048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>muas</th>\n",
       "      <td>0.015969</td>\n",
       "      <td>0.015640</td>\n",
       "      <td>0.025364</td>\n",
       "      <td>0.035776</td>\n",
       "      <td>0.116515</td>\n",
       "      <td>0.006616</td>\n",
       "      <td>0.111431</td>\n",
       "      <td>0.035637</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025817</td>\n",
       "      <td>0.044158</td>\n",
       "      <td>0.478118</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016284</td>\n",
       "      <td>0.127987</td>\n",
       "      <td>0.087980</td>\n",
       "      <td>0.028830</td>\n",
       "      <td>0.034229</td>\n",
       "      <td>0.025453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>moas</th>\n",
       "      <td>0.008354</td>\n",
       "      <td>0.004380</td>\n",
       "      <td>0.042424</td>\n",
       "      <td>0.010064</td>\n",
       "      <td>0.009188</td>\n",
       "      <td>0.023172</td>\n",
       "      <td>0.092309</td>\n",
       "      <td>0.131852</td>\n",
       "      <td>0.069028</td>\n",
       "      <td>0.003157</td>\n",
       "      <td>...</td>\n",
       "      <td>0.186843</td>\n",
       "      <td>0.046245</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.555603</td>\n",
       "      <td>0.027008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012200</td>\n",
       "      <td>0.031659</td>\n",
       "      <td>0.043585</td>\n",
       "      <td>0.075104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows  100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       finance_33.csv  finance_27.csv  finance_26.csv  finance_32.csv  \\\n",
       "smape        1.768175        1.785110        4.839014        4.430679   \n",
       "mase              inf        2.256139        9.230062        6.938760   \n",
       "mues         0.573770        0.754261        0.597305        0.726776   \n",
       "moes         0.426230        0.245739        0.402695        0.273224   \n",
       "muas         0.015969        0.015640        0.025364        0.035776   \n",
       "moas         0.008354        0.004380        0.042424        0.010064   \n",
       "\n",
       "       finance_24.csv  finance_30.csv  finance_18.csv  finance_19.csv  \\\n",
       "smape       13.943318        2.024036       12.391023       11.585891   \n",
       "mase              inf        1.408215        4.176157        7.139150   \n",
       "mues         0.660550        0.273224        0.611111        0.428571   \n",
       "moes         0.339450        0.726776        0.388889        0.571429   \n",
       "muas         0.116515        0.006616        0.111431        0.035637   \n",
       "moas         0.009188        0.023172        0.092309        0.131852   \n",
       "\n",
       "       finance_31.csv  finance_25.csv  ...  finance_11.csv  finance_39.csv  \\\n",
       "smape        6.617646        4.756577  ...       15.908761        6.388955   \n",
       "mase        19.561150        5.030666  ...        3.876151        0.622159   \n",
       "mues         0.000000        0.897619  ...        0.111111        0.413333   \n",
       "moes         1.000000        0.102381  ...        0.888889        0.586667   \n",
       "muas         0.000000        0.045126  ...        0.025817        0.044158   \n",
       "moas         0.069028        0.003157  ...        0.186843        0.046245   \n",
       "\n",
       "       finance_38.csv  finance_10.csv  finance_28.csv  finance_14.csv  \\\n",
       "smape       64.770169       42.508554        3.492355       13.705860   \n",
       "mase         3.229358        7.226101        3.297267        3.442897   \n",
       "mues         1.000000        0.000000        0.454341        1.000000   \n",
       "moes         0.000000        1.000000        0.545659        0.000000   \n",
       "muas         0.478118        0.000000        0.016284        0.127987   \n",
       "moas         0.000000        0.555603        0.027008        0.000000   \n",
       "\n",
       "       finance_15.csv  finance_29.csv  finance_17.csv  finance_16.csv  \n",
       "smape        9.806658        3.120847        6.812100        7.053095  \n",
       "mase         2.734479        4.114496        2.133255        2.546827  \n",
       "mues         0.777778        0.489362        0.500000        0.380952  \n",
       "moes         0.222222        0.510638        0.500000        0.619048  \n",
       "muas         0.087980        0.028830        0.034229        0.025453  \n",
       "moas         0.012200        0.031659        0.043585        0.075104  \n",
       "\n",
       "[6 rows x 100 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c84d0e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd254567",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name            | Type       | Params\n",
      "-----------------------------------------------\n",
      "0 | loss            | MASE       | 0     \n",
      "1 | logging_metrics | ModuleList | 0     \n",
      "2 | net_blocks      | ModuleList | 1.6 M \n",
      "-----------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.434     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73f5865c87634c04ab7d5d9301c1d0a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Insufficient data for 75 historic forecasts, reduced to 63.\n",
      "Number of forecast steps is defined by n_forecasts. Adjusted to 3.\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pandas/core/indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name            | Type       | Params\n",
      "-----------------------------------------------\n",
      "0 | loss            | MASE       | 0     \n",
      "1 | logging_metrics | ModuleList | 0     \n",
      "2 | net_blocks      | ModuleList | 1.6 M \n",
      "-----------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.362     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f25724cc4ec9436496bea00e42601b7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Insufficient data for 844 historic forecasts, reduced to 843.\n",
      "Number of forecast steps is defined by n_forecasts. Adjusted to 3.\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pandas/core/indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name            | Type       | Params\n",
      "-----------------------------------------------\n",
      "0 | loss            | MASE       | 0     \n",
      "1 | logging_metrics | ModuleList | 0     \n",
      "2 | net_blocks      | ModuleList | 1.6 M \n",
      "-----------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.362     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c0fb2b5d9a74d0d8dbff2e951daae79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Insufficient data for 844 historic forecasts, reduced to 843.\n",
      "Number of forecast steps is defined by n_forecasts. Adjusted to 3.\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pandas/core/indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name            | Type       | Params\n",
      "-----------------------------------------------\n",
      "0 | loss            | MASE       | 0     \n",
      "1 | logging_metrics | ModuleList | 0     \n",
      "2 | net_blocks      | ModuleList | 1.6 M \n",
      "-----------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.434     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64bd6b70c9c843a4928b96ce697ccaa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Insufficient data for 75 historic forecasts, reduced to 63.\n",
      "Number of forecast steps is defined by n_forecasts. Adjusted to 3.\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pandas/core/indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name            | Type       | Params\n",
      "-----------------------------------------------\n",
      "0 | loss            | MASE       | 0     \n",
      "1 | logging_metrics | ModuleList | 0     \n",
      "2 | net_blocks      | ModuleList | 1.6 M \n",
      "-----------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.362     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8aeb87716764cf5afa55e05a85e5b02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Insufficient data for 112 historic forecasts, reduced to 111.\n",
      "Number of forecast steps is defined by n_forecasts. Adjusted to 3.\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pandas/core/indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name            | Type       | Params\n",
      "-----------------------------------------------\n",
      "0 | loss            | MASE       | 0     \n",
      "1 | logging_metrics | ModuleList | 0     \n",
      "2 | net_blocks      | ModuleList | 1.6 M \n",
      "-----------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.434     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "692612092897472e9b09cafe0882d6db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Insufficient data for 75 historic forecasts, reduced to 63.\n",
      "Number of forecast steps is defined by n_forecasts. Adjusted to 3.\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pandas/core/indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name            | Type       | Params\n",
      "-----------------------------------------------\n",
      "0 | loss            | MASE       | 0     \n",
      "1 | logging_metrics | ModuleList | 0     \n",
      "2 | net_blocks      | ModuleList | 1.6 M \n",
      "-----------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.362     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0313d8e4db7d4a55802ee9e067493574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Insufficient data for 9 historic forecasts, reduced to 8.\n",
      "Number of forecast steps is defined by n_forecasts. Adjusted to 3.\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pandas/core/indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name            | Type       | Params\n",
      "-----------------------------------------------\n",
      "0 | loss            | MASE       | 0     \n",
      "1 | logging_metrics | ModuleList | 0     \n",
      "2 | net_blocks      | ModuleList | 1.6 M \n",
      "-----------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.362     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84953ca21a714087804d1992f3f88948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Insufficient data for 10 historic forecasts, reduced to 9.\n",
      "Number of forecast steps is defined by n_forecasts. Adjusted to 3.\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pandas/core/indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name            | Type       | Params\n",
      "-----------------------------------------------\n",
      "0 | loss            | MASE       | 0     \n",
      "1 | logging_metrics | ModuleList | 0     \n",
      "2 | net_blocks      | ModuleList | 1.6 M \n",
      "-----------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.434     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e9f025aace846d2a92ef41fd6912e64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Insufficient data for 75 historic forecasts, reduced to 63.\n",
      "Number of forecast steps is defined by n_forecasts. Adjusted to 3.\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pandas/core/indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name            | Type       | Params\n",
      "-----------------------------------------------\n",
      "0 | loss            | MASE       | 0     \n",
      "1 | logging_metrics | ModuleList | 0     \n",
      "2 | net_blocks      | ModuleList | 1.6 M \n",
      "-----------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.362     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21485ed904c546f1a4a1b2fb7b219770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Insufficient data for 843 historic forecasts, reduced to 842.\n",
      "Number of forecast steps is defined by n_forecasts. Adjusted to 3.\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pandas/core/indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name            | Type       | Params\n",
      "-----------------------------------------------\n",
      "0 | loss            | MASE       | 0     \n",
      "1 | logging_metrics | ModuleList | 0     \n",
      "2 | net_blocks      | ModuleList | 1.6 M \n",
      "-----------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.362     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b2f17b0f5af4603a874bb258099655f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Insufficient data for 10 historic forecasts, reduced to 9.\n",
      "Number of forecast steps is defined by n_forecasts. Adjusted to 3.\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pandas/core/indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name            | Type       | Params\n",
      "-----------------------------------------------\n",
      "0 | loss            | MASE       | 0     \n",
      "1 | logging_metrics | ModuleList | 0     \n",
      "2 | net_blocks      | ModuleList | 1.6 M \n",
      "-----------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.434     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dd0111f95434b7e9d5e20f653f12831",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Insufficient data for 30 historic forecasts, reduced to 18.\n",
      "Number of forecast steps is defined by n_forecasts. Adjusted to 3.\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pandas/core/indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name            | Type       | Params\n",
      "-----------------------------------------------\n",
      "0 | loss            | MASE       | 0     \n",
      "1 | logging_metrics | ModuleList | 0     \n",
      "2 | net_blocks      | ModuleList | 1.6 M \n",
      "-----------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.434     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b29f64d5c7248d4a8e45735c497d979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Insufficient data for 61 historic forecasts, reduced to 49.\n",
      "Number of forecast steps is defined by n_forecasts. Adjusted to 3.\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pandas/core/indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/ipykernel_launcher.py:11: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  # This is added back by InteractiveShellApp.init_path()\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name            | Type       | Params\n",
      "-----------------------------------------------\n",
      "0 | loss            | MASE       | 0     \n",
      "1 | logging_metrics | ModuleList | 0     \n",
      "2 | net_blocks      | ModuleList | 1.6 M \n",
      "-----------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.362     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "075645251d5d4cdd82bdaafa13f08ccc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Insufficient data for 11 historic forecasts, reduced to 10.\n",
      "Number of forecast steps is defined by n_forecasts. Adjusted to 3.\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pandas/core/indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name            | Type       | Params\n",
      "-----------------------------------------------\n",
      "0 | loss            | MASE       | 0     \n",
      "1 | logging_metrics | ModuleList | 0     \n",
      "2 | net_blocks      | ModuleList | 1.6 M \n",
      "-----------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.434     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5c576e90dfe4f91ab5fd74071219a51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Insufficient data for 49 historic forecasts, reduced to 37.\n",
      "Number of forecast steps is defined by n_forecasts. Adjusted to 3.\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pandas/core/indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name            | Type       | Params\n",
      "-----------------------------------------------\n",
      "0 | loss            | MASE       | 0     \n",
      "1 | logging_metrics | ModuleList | 0     \n",
      "2 | net_blocks      | ModuleList | 1.6 M \n",
      "-----------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.362     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7dfbc850c984111a97abadd57a507e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Insufficient data for 9 historic forecasts, reduced to 8.\n",
      "Number of forecast steps is defined by n_forecasts. Adjusted to 3.\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pandas/core/indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name            | Type       | Params\n",
      "-----------------------------------------------\n",
      "0 | loss            | MASE       | 0     \n",
      "1 | logging_metrics | ModuleList | 0     \n",
      "2 | net_blocks      | ModuleList | 1.6 M \n",
      "-----------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.362     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90980059f68b451abcd2f7cb3585e5ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Insufficient data for 15 historic forecasts, reduced to 14.\n",
      "Number of forecast steps is defined by n_forecasts. Adjusted to 3.\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pandas/core/indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name            | Type       | Params\n",
      "-----------------------------------------------\n",
      "0 | loss            | MASE       | 0     \n",
      "1 | logging_metrics | ModuleList | 0     \n",
      "2 | net_blocks      | ModuleList | 1.6 M \n",
      "-----------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.381     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed684bd6bc70492e8cedad6622f02f93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Insufficient data for 23 historic forecasts, reduced to 19.\n",
      "Number of forecast steps is defined by n_forecasts. Adjusted to 3.\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pandas/core/indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name            | Type       | Params\n",
      "-----------------------------------------------\n",
      "0 | loss            | MASE       | 0     \n",
      "1 | logging_metrics | ModuleList | 0     \n",
      "2 | net_blocks      | ModuleList | 1.6 M \n",
      "-----------------------------------------------\n",
      "1.6 M     Trainable params\n",
      "0         Non-trainable params\n",
      "1.6 M     Total params\n",
      "6.362     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ab4986d675245d597d321b8c855469b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Insufficient data for 11 historic forecasts, reduced to 10.\n",
      "Number of forecast steps is defined by n_forecasts. Adjusted to 3.\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pandas/core/indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name            | Type       | Params\n",
      "-----------------------------------------------\n",
      "0 | loss            | MASE       | 0     \n",
      "1 | logging_metrics | ModuleList | 0     \n",
      "2 | net_blocks      | ModuleList | 2.2 M \n",
      "-----------------------------------------------\n",
      "2.2 M     Trainable params\n",
      "0         Non-trainable params\n",
      "2.2 M     Total params\n",
      "8.705     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8368e0a6e9e8460a9550377972f54844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validating: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Insufficient data for 529 historic forecasts, reduced to 169.\n",
      "Number of forecast steps is defined by n_forecasts. Adjusted to 3.\n",
      "WARNING - (py.warnings._showwarnmsg) - /Users/polina/.conda/envs/neural_prophet/lib/python3.7/site-packages/pandas/core/indexing.py:1738: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(loc, value[:, i].tolist(), pi)\n",
      "\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "\n",
      "  | Name            | Type       | Params\n",
      "-----------------------------------------------\n",
      "0 | loss            | MASE       | 0     \n",
      "1 | logging_metrics | ModuleList | 0     \n",
      "2 | net_blocks      | ModuleList | 4.9 M \n",
      "-----------------------------------------------\n",
      "4.9 M     Trainable params\n",
      "0         Non-trainable params\n",
      "4.9 M     Total params\n",
      "19.516    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7604eb9cc914fcc94eda60b0621d548",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from neuralprophet.utils.df_utils import split_df\n",
    "\n",
    "metrics = {}\n",
    "\n",
    "counter = 0\n",
    "for dataset_name, df in datasets.items():\n",
    "#     if counter == 1:\n",
    "#         break\n",
    "    \n",
    "    idx_ts = int(dataset_name.split('.')[0].split('_')[-1])-1\n",
    "    freq_number = frequencies.iloc[\n",
    "        idx_ts][[col for col in frequencies.columns if usecase in col][0]]\n",
    "    freq = mapping(frequencies.iloc[\n",
    "        idx_ts][[col for col in frequencies.columns if usecase in col][0]])\n",
    "    \n",
    "    n_lags = freq_number\n",
    "    n_forecasts = 3\n",
    "    \n",
    "    m = NBeats(context_length = int(n_lags), prediction_length = 3)\n",
    "    \n",
    "    tr, vl = split_df(df, n_lags = n_lags, n_forecasts = n_forecasts, valid_p = valid_p)\n",
    "    m.fit(tr, freq = freq)\n",
    "    future = m.make_future_dataframe(vl, freq = freq, periods = 1, n_historic_predictions=len(vl))\n",
    "    forecast = m.predict(future)\n",
    "    fold = forecast.iloc[n_lags:][[f'yhat{i}' for i in range(1, n_forecasts+1)]]\n",
    "\n",
    "    y_predicted = [np.array(fold).diagonal(offset=-i) for i in range(len(fold) - n_forecasts + 1)]\n",
    "    y = np.array(vl[n_lags:][\"y\"])\n",
    "    y_rolled = [y[i : i + n_forecasts] for i in range(len(y) - n_forecasts + 1)]\n",
    "    \n",
    "    y_naive = np.array(vl[n_lags-1:-1][\"y\"])\n",
    "    y_naive_rolled = [y_naive[i : i + n_forecasts] for i in range(len(y_naive) - n_forecasts + 1)]\n",
    "    \n",
    "    smapes = np.mean([smape(y_rolled[i], y_predicted[i]) for i in range(len(y_rolled))])\n",
    "    mases = np.mean([mase(y_rolled[i], y_predicted[i], y_naive_rolled[i]) for i in range(len(y_rolled))])\n",
    "    mueses = np.mean([mues(y_rolled[i], y_predicted[i]) for i in range(len(y_rolled))])\n",
    "    moeses = np.mean([moes(y_rolled[i], y_predicted[i]) for i in range(len(y_rolled))])\n",
    "    muases = np.mean([muas(y_rolled[i], y_predicted[i]) for i in range(len(y_rolled))])\n",
    "    moases = np.mean([moas(y_rolled[i], y_predicted[i]) for i in range(len(y_rolled))])\n",
    "    \n",
    "    metrics.update({dataset_name:{\n",
    "        'smape': smapes,\n",
    "        'mase': mases,\n",
    "        'mues': mueses,\n",
    "        'moes': moeses,\n",
    "        'muas': muases,\n",
    "        'moas': moases\n",
    "        \n",
    "    }})\n",
    "    \n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74599dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(metrics).to_csv('nbeats_libra_fin.csv', index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19cd872",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e85ebf39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'economics_80.csv': {'smape': 14.227959482889146,\n",
       "  'mase': 0.6793891006101452,\n",
       "  'mues': 0.6845238095238094,\n",
       "  'moes': 0.3154761904761904,\n",
       "  'muas': 0.10425659722191864,\n",
       "  'moas': 0.2198020913237889},\n",
       " 'economics_94.csv': {'smape': 0.7190360801962151,\n",
       "  'mase': 3.1163183418894147,\n",
       "  'mues': 0.36507936507936506,\n",
       "  'moes': 0.6349206349206349,\n",
       "  'muas': 0.001503754856503776,\n",
       "  'moas': 0.006099359626964676},\n",
       " 'economics_43.csv': {'smape': 5.829709637480135,\n",
       "  'mase': 1.0738051638414605,\n",
       "  'mues': 0.725,\n",
       "  'moes': 0.275,\n",
       "  'muas': 0.05530059414642341,\n",
       "  'moas': 0.028149931598778904},\n",
       " 'economics_57.csv': {'smape': 0.1298987500371631,\n",
       "  'mase': 0.4951778316399436,\n",
       "  'mues': 0.1733333333333333,\n",
       "  'moes': 0.8266666666666667,\n",
       "  'muas': 0.0003500760304027347,\n",
       "  'moas': 0.0014781010942533108},\n",
       " 'economics_56.csv': {'smape': 3.0017473773169367,\n",
       "  'mase': 2.069085805064148,\n",
       "  'mues': 0.4533333333333333,\n",
       "  'moes': 0.5466666666666666,\n",
       "  'muas': 0.018881944477294157,\n",
       "  'moas': 0.020638514320898648},\n",
       " 'economics_42.csv': {'smape': 9.61000141191509,\n",
       "  'mase': 1.6570290106837926,\n",
       "  'mues': 0.7021276595744681,\n",
       "  'moes': 0.2978723404255319,\n",
       "  'muas': 0.09288098112270195,\n",
       "  'moas': 0.03599283928318368},\n",
       " 'economics_95.csv': {'smape': 6.839938192537175,\n",
       "  'mase': 3.0502205373032303,\n",
       "  'mues': 1.0,\n",
       "  'moes': 0.0,\n",
       "  'muas': 0.06582318844300734,\n",
       "  'moas': 0.0},\n",
       " 'economics_81.csv': {'smape': 91.25028668834187,\n",
       "  'mase': 1.0803097393017866,\n",
       "  'mues': 0.6467391304347826,\n",
       "  'moes': 0.3532608695652174,\n",
       "  'muas': 0.41625799195007357,\n",
       "  'moas': 10.749751581531644},\n",
       " 'economics_97.csv': {'smape': 4.422645556640115,\n",
       "  'mase': 0.36784582879769134,\n",
       "  'mues': 0.9444444444444443,\n",
       "  'moes': 0.05555555555555555,\n",
       "  'muas': 0.0447588883810909,\n",
       "  'moas': 0.002548247244359869},\n",
       " 'economics_83.csv': {'smape': 17.03762329208775,\n",
       "  'mase': 0.9168272740587948,\n",
       "  'mues': 0.6785714285714286,\n",
       "  'moes': 0.32142857142857145,\n",
       "  'muas': 0.143619340594877,\n",
       "  'moas': 0.9749866220085062},\n",
       " 'economics_54.csv': {'smape': 1.4249805814372911,\n",
       "  'mase': 2.5328365170965763,\n",
       "  'mues': 0.0849673202614379,\n",
       "  'moes': 0.9150326797385621,\n",
       "  'muas': 0.0009613446086038794,\n",
       "  'moas': 0.014483701027232558},\n",
       " 'economics_40.csv': {'smape': 24.090367905209188,\n",
       "  'mase': 1.0024320815732848,\n",
       "  'mues': 0.8888888888888888,\n",
       "  'moes': 0.1111111111111111,\n",
       "  'muas': 0.21989433013477197,\n",
       "  'moas': 0.051695541248395004},\n",
       " 'economics_68.csv': {'smape': 0.34211343193890786,\n",
       "  'mase': 0.43876481160744385,\n",
       "  'mues': 0.48,\n",
       "  'moes': 0.5199999999999999,\n",
       "  'muas': 0.0029165538240354056,\n",
       "  'moas': 0.00318679178855473},\n",
       " 'economics_69.csv': {'smape': 1.3415475218117583,\n",
       "  'mase': 1.6783363711068662,\n",
       "  'mues': 0.5066666666666666,\n",
       "  'moes': 0.4933333333333333,\n",
       "  'muas': 0.010307601532497167,\n",
       "  'moas': 0.008795437350301381},\n",
       " 'economics_41.csv': {'smape': 5.510194395606914,\n",
       "  'mase': 1.6891015815163508,\n",
       "  'mues': 0.7385620915032679,\n",
       "  'moes': 0.26143790849673204,\n",
       "  'muas': 0.05151703295466673,\n",
       "  'moas': 0.019923128751453766},\n",
       " 'economics_55.csv': {'smape': 8.736317723524843,\n",
       "  'mase': 4.980777208312392,\n",
       "  'mues': 0.2198581560283688,\n",
       "  'moes': 0.780141843971631,\n",
       "  'muas': 0.014578688076821252,\n",
       "  'moas': 0.10018259610003617},\n",
       " 'economics_82.csv': {'smape': 29.113515042684213,\n",
       "  'mase': 1.0149314194403194,\n",
       "  'mues': 0.6893424036281178,\n",
       "  'moes': 0.31065759637188206,\n",
       "  'muas': 0.20716716737822657,\n",
       "  'moas': 0.56312838770452},\n",
       " 'economics_96.csv': {'smape': 3.398268113912444,\n",
       "  'mase': 0.4556073404398605,\n",
       "  'mues': 0.45035460992907805,\n",
       "  'moes': 0.549645390070922,\n",
       "  'muas': 0.02367875427002627,\n",
       "  'moas': 0.03094150815139687},\n",
       " 'economics_92.csv': {'smape': 3.1431963251971387,\n",
       "  'mase': 0.6312340251788657,\n",
       "  'mues': 0.9105691056910568,\n",
       "  'moes': 0.08943089430894309,\n",
       "  'muas': 0.03255341510775175,\n",
       "  'moas': 0.002444939389541213},\n",
       " 'economics_86.csv': {'smape': 15.952551711059844,\n",
       "  'mase': 1.334743305770605,\n",
       "  'mues': 0.5386904761904762,\n",
       "  'moes': 0.46130952380952384,\n",
       "  'muas': 0.0970986369140917,\n",
       "  'moas': 1.5613519226757955},\n",
       " 'economics_79.csv': {'smape': 45.04500266573304,\n",
       "  'mase': 0.9820299053560204,\n",
       "  'mues': 0.33876811594202894,\n",
       "  'moes': 0.6612318840579711,\n",
       "  'muas': 0.09809478737086523,\n",
       "  'moas': 9.962760923113054},\n",
       " 'economics_51.csv': {'smape': 1.5772862641721492,\n",
       "  'mase': 0.20308639452261953,\n",
       "  'mues': 0.16666666666666666,\n",
       "  'moes': 0.8333333333333334,\n",
       "  'muas': 0.002917858697478418,\n",
       "  'moas': 0.017285649816703965},\n",
       " 'economics_45.csv': {'smape': 11.765290383961775,\n",
       "  'mase': 0.7637489786898649,\n",
       "  'mues': 0.7647058823529411,\n",
       "  'moes': 0.23529411764705882,\n",
       "  'muas': 0.10160678680686865,\n",
       "  'moas': 0.06095026255501438},\n",
       " 'economics_44.csv': {'smape': 7.917361353859095,\n",
       "  'mase': 0.61847055548791,\n",
       "  'mues': 0.7166666666666666,\n",
       "  'moes': 0.2833333333333333,\n",
       "  'muas': 0.0855060784002507,\n",
       "  'moas': 0.0498170395690643},\n",
       " 'economics_50.csv': {'smape': 9.228707720591073,\n",
       "  'mase': 0.5943719212276495,\n",
       "  'mues': 0.3333333333333333,\n",
       "  'moes': 0.6666666666666666,\n",
       "  'muas': 0.05427445171419929,\n",
       "  'moas': 0.1143377321166178},\n",
       " 'economics_78.csv': {'smape': 47.407936260865306,\n",
       "  'mase': 0.9828636476636595,\n",
       "  'mues': 0.41666666666666663,\n",
       "  'moes': 0.5833333333333334,\n",
       "  'muas': 0.1338417742188001,\n",
       "  'moas': 20.07130374433401},\n",
       " 'economics_87.csv': {'smape': 7.0436582920388116,\n",
       "  'mase': 0.7377290460873672,\n",
       "  'mues': 0.5349301397205589,\n",
       "  'moes': 0.4650698602794411,\n",
       "  'muas': 0.055760198285582575,\n",
       "  'moas': 0.04904660008864736},\n",
       " 'economics_93.csv': {'smape': 4.409842094429452,\n",
       "  'mase': 1.8911019543414167,\n",
       "  'mues': 0.7777777777777777,\n",
       "  'moes': 0.22222222222222218,\n",
       "  'muas': 0.04120249220005556,\n",
       "  'moas': 0.004038177765872105},\n",
       " 'economics_85.csv': {'smape': 8.554384917765395,\n",
       "  'mase': 0.8273916831491854,\n",
       "  'mues': 0.7019607843137254,\n",
       "  'moes': 0.2980392156862745,\n",
       "  'muas': 0.08122190362911141,\n",
       "  'moas': 0.03893781436783668},\n",
       " 'economics_91.csv': {'smape': 17.34097348135875,\n",
       "  'mase': 0.7374014839779356,\n",
       "  'mues': 0.38888888888888884,\n",
       "  'moes': 0.6111111111111112,\n",
       "  'muas': 0.14938657131187474,\n",
       "  'moas': 0.19425418557524665},\n",
       " 'economics_46.csv': {'smape': 3.0931608955678627,\n",
       "  'mase': 1.2597074530034338,\n",
       "  'mues': 0.7777777777777777,\n",
       "  'moes': 0.22222222222222224,\n",
       "  'muas': 0.0351991113890133,\n",
       "  'moas': 0.006429204696179638},\n",
       " 'economics_52.csv': {'smape': 2.657073284096728,\n",
       "  'mase': 2.4275542029288246,\n",
       "  'mues': 0.9019607843137255,\n",
       "  'moes': 0.09803921568627451,\n",
       "  'muas': 0.026113902640586033,\n",
       "  'moas': 0.0021535522070902824},\n",
       " 'economics_53.csv': {'smape': 5.257289397851125,\n",
       "  'mase': 9.0294769033635,\n",
       "  'mues': 1.0,\n",
       "  'moes': 0.0,\n",
       "  'muas': 0.05115830091548908,\n",
       "  'moas': 0.0},\n",
       " 'economics_47.csv': {'smape': 1.436107127731436,\n",
       "  'mase': 1.1844237552915116,\n",
       "  'mues': 0.8148148148148147,\n",
       "  'moes': 0.18518518518518515,\n",
       "  'muas': 0.016127780858240768,\n",
       "  'moas': 0.00268047261573718},\n",
       " 'economics_90.csv': {'smape': 7.395525368181334,\n",
       "  'mase': 2.027746723196569,\n",
       "  'mues': 0.6851851851851851,\n",
       "  'moes': 0.31481481481481477,\n",
       "  'muas': 0.07254091024624848,\n",
       "  'moas': 0.0335673516947653},\n",
       " 'economics_84.csv': {'smape': 67.64910958307131,\n",
       "  'mase': 1.2957695020800235,\n",
       "  'mues': 0.6974637681159421,\n",
       "  'moes': 0.302536231884058,\n",
       "  'muas': 0.4025460618073101,\n",
       "  'moas': 8.91960463072262},\n",
       " 'economics_7.csv': {'smape': 16.906319364318254,\n",
       "  'mase': 0.7451475992810144,\n",
       "  'mues': 0.5555555555555555,\n",
       "  'moes': 0.4444444444444444,\n",
       "  'muas': 0.11528906885319112,\n",
       "  'moas': 0.2716595023258559},\n",
       " 'economics_20.csv': {'smape': 3.474391729752525,\n",
       "  'mase': 1.997206485177343,\n",
       "  'mues': 0.8837209302325582,\n",
       "  'moes': 0.11627906976744186,\n",
       "  'muas': 0.03506348211009249,\n",
       "  'moas': 0.0043480836065051395},\n",
       " 'economics_34.csv': {'smape': 2.545932852033881,\n",
       "  'mase': 0.6758165896464956,\n",
       "  'mues': 0.5166666666666667,\n",
       "  'moes': 0.4833333333333333,\n",
       "  'muas': 0.016487999442118467,\n",
       "  'moas': 0.02375702956502767},\n",
       " 'economics_35.csv': {'smape': 8.429580246321356,\n",
       "  'mase': 0.5544964690875231,\n",
       "  'mues': 0.44791666666666663,\n",
       "  'moes': 0.5520833333333333,\n",
       "  'muas': 0.06858261623332577,\n",
       "  'moas': 0.09854654605016469},\n",
       " 'economics_21.csv': {'smape': 0.8747058945603597,\n",
       "  'mase': 6.4015211039676965,\n",
       "  'mues': 0.9251700680272108,\n",
       "  'moes': 0.0748299319727891,\n",
       "  'muas': 0.008755855597952751,\n",
       "  'moas': 0.00028693300419913216},\n",
       " 'economics_6.csv': {'smape': 34.84606275725361,\n",
       "  'mase': 3.0944868667091314,\n",
       "  'mues': 0.3333333333333333,\n",
       "  'moes': 0.6666666666666666,\n",
       "  'muas': 0.09116915025065171,\n",
       "  'moas': 0.48487083266390246},\n",
       " 'economics_37.csv': {'smape': 3.538460521899133,\n",
       "  'mase': 0.9894506134327045,\n",
       "  'mues': 0.7681159420289856,\n",
       "  'moes': 0.23188405797101447,\n",
       "  'muas': 0.03930249837653597,\n",
       "  'moas': 0.011929963110564256},\n",
       " 'economics_4.csv': {'smape': 58.97343452283271,\n",
       "  'mase': 2.7768175407670594,\n",
       "  'mues': 0.1111111111111111,\n",
       "  'moes': 0.8888888888888888,\n",
       "  'muas': 0.05583616684351304,\n",
       "  'moas': 0.9979377972544571},\n",
       " 'economics_23.csv': {'smape': 6.102337760113277,\n",
       "  'mase': 0.68705329542361,\n",
       "  'mues': 0.4666666666666666,\n",
       "  'moes': 0.5333333333333333,\n",
       "  'muas': 0.047045101938789594,\n",
       "  'moas': 0.0648738301943579},\n",
       " 'economics_22.csv': {'smape': 9.564220608964456,\n",
       "  'mase': 1.0552537664319963,\n",
       "  'mues': 0.5135135135135135,\n",
       "  'moes': 0.4864864864864865,\n",
       "  'muas': 0.08387429660677047,\n",
       "  'moas': 0.09113443207121044},\n",
       " 'economics_5.csv': {'smape': 13.331686001877765,\n",
       "  'mase': 0.8875002253067411,\n",
       "  'mues': 0.4444444444444444,\n",
       "  'moes': 0.5555555555555555,\n",
       "  'muas': 0.09228097687913328,\n",
       "  'moas': 0.16812099473517672},\n",
       " 'economics_36.csv': {'smape': 10.933769894143758,\n",
       "  'mase': 0.6363765116071743,\n",
       "  'mues': 0.6851851851851851,\n",
       "  'moes': 0.31481481481481477,\n",
       "  'muas': 0.1067764687903329,\n",
       "  'moas': 0.0342236106496627},\n",
       " 'economics_32.csv': {'smape': 2.223930498866933,\n",
       "  'mase': 1.1876558438019118,\n",
       "  'mues': 0.5352798053527981,\n",
       "  'moes': 0.4647201946472019,\n",
       "  'muas': 0.01957153604157833,\n",
       "  'moas': 0.01713902225688456},\n",
       " 'economics_1.csv': {'smape': 27.2459105089238,\n",
       "  'mase': 3.6463128073289965,\n",
       "  'mues': 1.0,\n",
       "  'moes': 0.0,\n",
       "  'muas': 0.2358545612346947,\n",
       "  'moas': 0.0},\n",
       " 'economics_26.csv': {'smape': 5.592992759541615,\n",
       "  'mase': 0.262392745894337,\n",
       "  'mues': 0.75,\n",
       "  'moes': 0.25,\n",
       "  'muas': 0.05825624619420663,\n",
       "  'moas': 0.01688094661631455},\n",
       " 'economics_27.csv': {'smape': 4.281890116494577,\n",
       "  'mase': 1.6239213140040167,\n",
       "  'mues': 0.9655172413793104,\n",
       "  'moes': 0.034482758620689655,\n",
       "  'muas': 0.042134274966870694,\n",
       "  'moas': 0.001395058261456888},\n",
       " 'economics_33.csv': {'smape': 5.4135475682173935,\n",
       "  'mase': 1.184500703692203,\n",
       "  'mues': 1.0,\n",
       "  'moes': 0.0,\n",
       "  'muas': 0.052557531575975196,\n",
       "  'moas': 0.0},\n",
       " 'economics_19.csv': {'smape': 0.8680454185570292,\n",
       "  'mase': 1.3730420450685397,\n",
       "  'mues': 0.4590163934426229,\n",
       "  'moes': 0.5409836065573771,\n",
       "  'muas': 0.004857769965794686,\n",
       "  'moas': 0.0072639976722707784},\n",
       " 'economics_2.csv': {'smape': 10.841812837495306,\n",
       "  'mase': 1.2343208315267822,\n",
       "  'mues': 0.5555555555555555,\n",
       "  'moes': 0.4444444444444444,\n",
       "  'muas': 0.043890688656150485,\n",
       "  'moas': 0.07817577256047827},\n",
       " 'economics_25.csv': {'smape': 1.5290399812939413,\n",
       "  'mase': 1.4561048521246014,\n",
       "  'mues': 0.7333333333333334,\n",
       "  'moes': 0.2666666666666667,\n",
       "  'muas': 0.015230858616694523,\n",
       "  'moas': 0.0055590092802896215},\n",
       " 'economics_31.csv': {'smape': 4.320371369121796,\n",
       "  'mase': 0.6550076340422842,\n",
       "  'mues': 0.6666666666666666,\n",
       "  'moes': 0.3333333333333333,\n",
       "  'muas': 0.04139264119895218,\n",
       "  'moas': 0.02486427973490156},\n",
       " 'economics_30.csv': {'smape': 6.776817750247845,\n",
       "  'mase': 0.9377184754971049,\n",
       "  'mues': 0.6268115942028986,\n",
       "  'moes': 0.3731884057971015,\n",
       "  'muas': 0.05601999963589605,\n",
       "  'moas': 0.04081399676078718},\n",
       " 'economics_24.csv': {'smape': 4.139902961947342,\n",
       "  'mase': 0.40226840022394134,\n",
       "  'mues': 0.19841269841269837,\n",
       "  'moes': 0.8015873015873015,\n",
       "  'muas': 0.009820211417044155,\n",
       "  'moas': 0.050996856914773486},\n",
       " 'economics_3.csv': {'smape': 60.21449538090993,\n",
       "  'mase': 18.327401257765317,\n",
       "  'mues': 0.0,\n",
       "  'moes': 1.0,\n",
       "  'muas': 0.0,\n",
       "  'moas': 0.8868031394217413},\n",
       " 'economics_18.csv': {'smape': 2.938071003732803,\n",
       "  'mase': 2.535475935835182,\n",
       "  'mues': 0.819672131147541,\n",
       "  'moes': 0.180327868852459,\n",
       "  'muas': 0.02785580780597723,\n",
       "  'moas': 0.0038281072237893025},\n",
       " 'economics_15.csv': {'smape': 27.818199773082267,\n",
       "  'mase': 4.579216269546277,\n",
       "  'mues': 1.0,\n",
       "  'moes': 0.0,\n",
       "  'muas': 0.23750563197678978,\n",
       "  'moas': 0.0},\n",
       " 'economics_29.csv': {'smape': 7.821832833477396,\n",
       "  'mase': 8.413908125006952,\n",
       "  'mues': 1.0,\n",
       "  'moes': 0.0,\n",
       "  'muas': 0.07511183517623019,\n",
       "  'moas': 0.0},\n",
       " 'economics_28.csv': {'smape': 21.958026498394524,\n",
       "  'mase': 0.7886955230405374,\n",
       "  'mues': 0.5714285714285714,\n",
       "  'moes': 0.42857142857142855,\n",
       "  'muas': 0.14853164109628728,\n",
       "  'moas': 0.20397720357740348},\n",
       " 'economics_14.csv': {'smape': 8.796302854965152,\n",
       "  'mase': 2.897758961337978,\n",
       "  'mues': 0.5999999999999999,\n",
       "  'moes': 0.39999999999999997,\n",
       "  'muas': 0.06297880739833486,\n",
       "  'moas': 0.04573372673870914},\n",
       " 'economics_16.csv': {'smape': 9.381620087208075,\n",
       "  'mase': 2.131142415413844,\n",
       "  'mues': 0.5833333333333334,\n",
       "  'moes': 0.41666666666666663,\n",
       "  'muas': 0.08365184620887534,\n",
       "  'moas': 0.01966222466512336},\n",
       " 'economics_17.csv': {'smape': 1.4427773525802112,\n",
       "  'mase': 3.9284348577704504,\n",
       "  'mues': 0.6666666666666667,\n",
       "  'moes': 0.33333333333333337,\n",
       "  'muas': 0.016221593769239775,\n",
       "  'moas': 0.009529371263353148},\n",
       " 'economics_8.csv': {'smape': 53.99466297240489,\n",
       "  'mase': 1.2172021579011598,\n",
       "  'mues': 0.3333333333333333,\n",
       "  'moes': 0.6666666666666666,\n",
       "  'muas': 0.17675684198853728,\n",
       "  'moas': 0.5372846672829189},\n",
       " 'economics_13.csv': {'smape': 5.785715556253233,\n",
       "  'mase': 2.365525609490359,\n",
       "  'mues': 0.8,\n",
       "  'moes': 0.19999999999999998,\n",
       "  'muas': 0.06098610818963811,\n",
       "  'moas': 0.010426339606121163},\n",
       " 'economics_12.csv': {'smape': 10.283606218895548,\n",
       "  'mase': 1.4820205871705978,\n",
       "  'mues': 1.0,\n",
       "  'moes': 0.0,\n",
       "  'muas': 0.09686097188298892,\n",
       "  'moas': 0.0},\n",
       " 'economics_9.csv': {'smape': 12.61196176148097,\n",
       "  'mase': 1.0092217747539234,\n",
       "  'mues': 0.6666666666666666,\n",
       "  'moes': 0.3333333333333333,\n",
       "  'muas': 0.14513587403261552,\n",
       "  'moas': 0.030709370577281587},\n",
       " 'economics_38.csv': {'smape': 0.5123379056227407,\n",
       "  'mase': 2.098427147509615,\n",
       "  'mues': 0.7719298245614034,\n",
       "  'moes': 0.22807017543859648,\n",
       "  'muas': 0.005287569235560665,\n",
       "  'moas': 0.0006973363625242161},\n",
       " 'economics_100.csv': {'smape': 2.572361055334474,\n",
       "  'mase': 3.6329083122218147,\n",
       "  'mues': 0.9270833333333333,\n",
       "  'moes': 0.07291666666666666,\n",
       "  'muas': 0.026589136672831255,\n",
       "  'moas': 0.0032438468198980907},\n",
       " 'economics_10.csv': {'smape': 10.41564524035495,\n",
       "  'mase': 0.6943776924399546,\n",
       "  'mues': 0.619047619047619,\n",
       "  'moes': 0.38095238095238093,\n",
       "  'muas': 0.10695787205468958,\n",
       "  'moas': 0.05769791658723529},\n",
       " 'economics_11.csv': {'smape': 13.139690209205133,\n",
       "  'mase': 1.2993143544472836,\n",
       "  'mues': 0.0,\n",
       "  'moes': 1.0,\n",
       "  'muas': 0.0,\n",
       "  'moas': 0.14167513120844366},\n",
       " 'economics_39.csv': {'smape': 1.1548865421398191,\n",
       "  'mase': 1.5613901974439963,\n",
       "  'mues': 0.42857142857142855,\n",
       "  'moes': 0.5714285714285714,\n",
       "  'muas': 0.009225884183051244,\n",
       "  'moas': 0.011202215201889557},\n",
       " 'economics_89.csv': {'smape': 45.26583948982703,\n",
       "  'mase': 1.249131548326927,\n",
       "  'mues': 0.3242753623188406,\n",
       "  'moes': 0.6757246376811594,\n",
       "  'muas': 0.11414672362877944,\n",
       "  'moas': 4.777839258933405},\n",
       " 'economics_62.csv': {'smape': 0.5059807164805954,\n",
       "  'mase': 0.6550226632616504,\n",
       "  'mues': 0.22666666666666666,\n",
       "  'moes': 0.7733333333333333,\n",
       "  'muas': 0.0009983179899367275,\n",
       "  'moas': 0.0049199287902831},\n",
       " 'economics_76.csv': {'smape': 45.121998118723084,\n",
       "  'mase': 0.8737024353883109,\n",
       "  'mues': 0.4764492753623188,\n",
       "  'moes': 0.5235507246376813,\n",
       "  'muas': 0.1707378492242026,\n",
       "  'moas': 4.177874902092064},\n",
       " 'economics_77.csv': {'smape': 30.22335574887233,\n",
       "  'mase': 0.9428660483687807,\n",
       "  'mues': 0.5102040816326531,\n",
       "  'moes': 0.4897959183673469,\n",
       "  'muas': 0.13371827770625455,\n",
       "  'moas': 1.035703992439203},\n",
       " 'economics_63.csv': {'smape': 4.952238447284784,\n",
       "  'mase': 1.916303623885968,\n",
       "  'mues': 0.5866666666666667,\n",
       "  'moes': 0.4133333333333333,\n",
       "  'muas': 0.04215858331989043,\n",
       "  'moas': 0.014635278722703236},\n",
       " 'economics_88.csv': {'smape': 35.55909666866131,\n",
       "  'mase': 0.7860106730937109,\n",
       "  'mues': 0.41847826086956524,\n",
       "  'moes': 0.5815217391304348,\n",
       "  'muas': 0.13582045358873748,\n",
       "  'moas': 2.1986602955773646},\n",
       " 'economics_75.csv': {'smape': 43.69112981706823,\n",
       "  'mase': 0.8256845900697272,\n",
       "  'mues': 0.47282608695652173,\n",
       "  'moes': 0.5271739130434783,\n",
       "  'muas': 0.13198986343045543,\n",
       "  'moas': 3.9041309519253993},\n",
       " 'economics_61.csv': {'smape': 1.8508847984149783,\n",
       "  'mase': 0.5479667145250869,\n",
       "  'mues': 0.3466666666666666,\n",
       "  'moes': 0.6533333333333333,\n",
       "  'muas': 0.010917431914117155,\n",
       "  'moas': 0.019227385086070956},\n",
       " 'economics_49.csv': {'smape': 5.904755176958997,\n",
       "  'mase': 1.767063992723962,\n",
       "  'mues': 0.8765432098765431,\n",
       "  'moes': 0.12345679012345678,\n",
       "  'muas': 0.0525084322971182,\n",
       "  'moas': 0.006365176820074477},\n",
       " 'economics_48.csv': {'smape': 5.136089731642818,\n",
       "  'mase': 0.4325162970122138,\n",
       "  'mues': 0.8571428571428571,\n",
       "  'moes': 0.14285714285714285,\n",
       "  'muas': 0.05141608922013389,\n",
       "  'moas': 0.010370127491122523},\n",
       " 'economics_60.csv': {'smape': 7.005584641147945,\n",
       "  'mase': 2.3060138918094295,\n",
       "  'mues': 0.026666666666666665,\n",
       "  'moes': 0.9733333333333333,\n",
       "  'muas': 0.00034366463177281146,\n",
       "  'moas': 0.07475701343376309},\n",
       " 'economics_74.csv': {'smape': 26.805978409697673,\n",
       "  'mase': 0.8963676466026906,\n",
       "  'mues': 0.40036231884057966,\n",
       "  'moes': 0.5996376811594203,\n",
       "  'muas': 0.1039979298746762,\n",
       "  'moas': 0.7573586927521841},\n",
       " 'economics_58.csv': {'smape': 4.415129849497343,\n",
       "  'mase': 1.7154141768803495,\n",
       "  'mues': 0.68,\n",
       "  'moes': 0.31999999999999995,\n",
       "  'muas': 0.037584645889526834,\n",
       "  'moas': 0.016798480764808818},\n",
       " 'economics_70.csv': {'smape': 45.49128539270653,\n",
       "  'mase': 1.1298563205532475,\n",
       "  'mues': 0.32608695652173914,\n",
       "  'moes': 0.6739130434782609,\n",
       "  'muas': 0.09580938712264238,\n",
       "  'moas': 14.064893543565516},\n",
       " 'economics_64.csv': {'smape': 1.3725066351064499,\n",
       "  'mase': 1.3607225373569167,\n",
       "  'mues': 0.6399999999999999,\n",
       "  'moes': 0.35999999999999993,\n",
       "  'muas': 0.010596680781665648,\n",
       "  'moas': 0.006692206578534307},\n",
       " 'economics_65.csv': {'smape': 7.670207546254136,\n",
       "  'mase': 3.6568726180919384,\n",
       "  'mues': 0.96,\n",
       "  'moes': 0.04,\n",
       "  'muas': 0.07422083130679949,\n",
       "  'moas': 0.0018862509030282684},\n",
       " 'economics_71.csv': {'smape': 21.52526673664133,\n",
       "  'mase': 0.7032473152485209,\n",
       "  'mues': 0.4202898550724638,\n",
       "  'moes': 0.5797101449275361,\n",
       "  'muas': 0.09842593218438742,\n",
       "  'moas': 0.41706846538092635},\n",
       " 'economics_59.csv': {'smape': 2.29387977433087,\n",
       "  'mase': 0.4549962513123058,\n",
       "  'mues': 0.08,\n",
       "  'moes': 0.92,\n",
       "  'muas': 0.0020565445271405014,\n",
       "  'moas': 0.02372677485553933},\n",
       " 'economics_98.csv': {'smape': 7.725750439893425,\n",
       "  'mase': 0.44322869666397885,\n",
       "  'mues': 0.8888888888888888,\n",
       "  'moes': 0.1111111111111111,\n",
       "  'muas': 0.07706815655299092,\n",
       "  'moas': 0.008932662647303906},\n",
       " 'economics_67.csv': {'smape': 3.1025367694068495,\n",
       "  'mase': 2.0137354367632776,\n",
       "  'mues': 0.22666666666666668,\n",
       "  'moes': 0.7733333333333333,\n",
       "  'muas': 0.0068151013891228525,\n",
       "  'moas': 0.03291290747813089},\n",
       " 'economics_73.csv': {'smape': 53.32980106296969,\n",
       "  'mase': 0.8187693311068338,\n",
       "  'mues': 0.3717948717948718,\n",
       "  'moes': 0.6282051282051281,\n",
       "  'muas': 0.5977477183973625,\n",
       "  'moas': 7.452169691222025},\n",
       " 'economics_72.csv': {'smape': 48.030753529629415,\n",
       "  'mase': 1.4217918393910585,\n",
       "  'mues': 0.21739130434782608,\n",
       "  'moes': 0.782608695652174,\n",
       "  'muas': 0.07059251990488648,\n",
       "  'moas': 12.405464693074459},\n",
       " 'economics_66.csv': {'smape': 0.16057407251129066,\n",
       "  'mase': 0.35295686452694014,\n",
       "  'mues': 0.42666666666666664,\n",
       "  'moes': 0.5733333333333333,\n",
       "  'muas': 0.0005878788324634295,\n",
       "  'moas': 0.0014462013224655111},\n",
       " 'economics_99.csv': {'smape': 9.204953996234527,\n",
       "  'mase': 0.6491907657968645,\n",
       "  'mues': 0.71875,\n",
       "  'moes': 0.28125,\n",
       "  'muas': 0.10088989293142045,\n",
       "  'moas': 0.04725506851283118}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db03c8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0635fff0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "fb46b5dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 3)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y_rolled).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "23eaec8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(112, 3)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y_predicted).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1001cf48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364bacac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080750c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9000cbae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "f25b75dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                       \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "dict_items([('economics_80.csv',               y         ds\n",
       "0    118.546043 2000-01-01\n",
       "1    104.810656 2000-01-02\n",
       "2     86.660324 2000-01-03\n",
       "3    100.003271 2000-01-04\n",
       "4     95.392105 2000-01-05\n",
       "..          ...        ...\n",
       "926  110.599140 2002-07-15\n",
       "927  152.393959 2002-07-16\n",
       "928  124.138307 2002-07-17\n",
       "929  101.671139 2002-07-18\n",
       "930   94.411006 2002-07-19\n",
       "\n",
       "[931 rows x 2 columns]), ('economics_94.csv',              y         ds\n",
       "0    16.855022 2000-01-31\n",
       "1    16.855022 2000-02-29\n",
       "2    16.907295 2000-03-31\n",
       "3    16.959569 2000-04-30\n",
       "4    17.011842 2000-05-31\n",
       "..         ...        ...\n",
       "117  17.203512 2009-10-31\n",
       "118  17.255786 2009-11-30\n",
       "119  17.273210 2009-12-31\n",
       "120  17.273210 2010-01-31\n",
       "121  17.325484 2010-02-28\n",
       "\n",
       "[122 rows x 2 columns]), ('economics_43.csv',                  y         ds\n",
       "0    112607.239182 2000-01-31\n",
       "1    104416.948874 2000-02-29\n",
       "2    122801.816481 2000-03-31\n",
       "3    108323.609959 2000-04-30\n",
       "4    134909.726251 2000-05-31\n",
       "..             ...        ...\n",
       "415  349798.002672 2034-08-31\n",
       "416  326024.901529 2034-09-30\n",
       "417  346496.243949 2034-10-31\n",
       "418  332499.110138 2034-11-30\n",
       "419  329682.807476 2034-12-31\n",
       "\n",
       "[420 rows x 2 columns]), ('economics_57.csv',              y         ds\n",
       "0    14.018281 2000-01-31\n",
       "1    14.036616 2000-02-29\n",
       "2    14.009113 2000-03-31\n",
       "3    13.999945 2000-04-30\n",
       "4    13.963274 2000-05-31\n",
       "..         ...        ...\n",
       "139  13.899100 2011-08-31\n",
       "140  13.963274 2011-09-30\n",
       "141  13.954106 2011-10-31\n",
       "142  13.963274 2011-11-30\n",
       "143  13.889932 2011-12-31\n",
       "\n",
       "[144 rows x 2 columns]), ('economics_56.csv',                  y         ds\n",
       "0    315268.605301 2000-01-31\n",
       "1    320409.766011 2000-02-29\n",
       "2    327987.446430 2000-03-31\n",
       "3    334027.984874 2000-04-30\n",
       "4    331142.427078 2000-05-31\n",
       "..             ...        ...\n",
       "139  551352.006664 2011-08-31\n",
       "140  573081.545412 2011-09-30\n",
       "141  607505.195654 2011-10-31\n",
       "142  623617.202852 2011-11-30\n",
       "143  581333.433741 2011-12-31\n",
       "\n",
       "[144 rows x 2 columns]), ('economics_42.csv',               y         ds\n",
       "0     37.293089 2000-01-31\n",
       "1     41.362274 2000-02-29\n",
       "2     40.843653 2000-03-31\n",
       "3     40.045773 2000-04-30\n",
       "4     46.069763 2000-05-31\n",
       "..          ...        ...\n",
       "247  277.255331 2020-08-31\n",
       "248  221.363876 2020-09-30\n",
       "249  219.488859 2020-10-31\n",
       "250  209.156320 2020-11-30\n",
       "251  196.868977 2020-12-31\n",
       "\n",
       "[252 rows x 2 columns]), ('economics_95.csv',              y         ds\n",
       "0    10.332497 2000-01-31\n",
       "1    10.614654 2000-02-29\n",
       "2    10.597097 2000-03-31\n",
       "3    10.733787 2000-04-30\n",
       "4    10.682371 2000-05-31\n",
       "..         ...        ...\n",
       "247  22.961190 2020-08-31\n",
       "248  23.594474 2020-09-30\n",
       "249  23.010097 2020-10-31\n",
       "250  22.332294 2020-11-30\n",
       "251  22.053900 2020-12-31\n",
       "\n",
       "[252 rows x 2 columns]), ('economics_81.csv',               y         ds\n",
       "0    828.596577 2000-01-02\n",
       "1    602.038266 2000-01-09\n",
       "2    572.411410 2000-01-16\n",
       "3    598.552754 2000-01-23\n",
       "4    619.465828 2000-01-30\n",
       "..          ...        ...\n",
       "926  673.491272 2017-10-01\n",
       "927  765.857352 2017-10-08\n",
       "928  734.487740 2017-10-15\n",
       "929  840.795871 2017-10-22\n",
       "930    7.758389 2017-10-29\n",
       "\n",
       "[931 rows x 2 columns]), ('economics_97.csv',             y         ds\n",
       "0   38.396118 2000-03-31\n",
       "1   32.301302 2000-06-30\n",
       "2   28.912815 2000-09-30\n",
       "3   31.747465 2000-12-31\n",
       "4   38.663177 2001-03-31\n",
       "..        ...        ...\n",
       "67  30.995002 2016-12-31\n",
       "68  35.926088 2017-03-31\n",
       "69  30.613136 2017-06-30\n",
       "70  28.850088 2017-09-30\n",
       "71  31.928914 2017-12-31\n",
       "\n",
       "[72 rows x 2 columns]), ('economics_83.csv',               y         ds\n",
       "0    444.325221 2000-01-01\n",
       "1    380.492084 2000-01-02\n",
       "2    348.951004 2000-01-03\n",
       "3    348.200026 2000-01-04\n",
       "4    380.492084 2000-01-05\n",
       "..          ...        ...\n",
       "926  746.218411 2002-07-15\n",
       "927  742.463520 2002-07-16\n",
       "928  792.779052 2002-07-17\n",
       "929  827.324044 2002-07-18\n",
       "930  400.017514 2002-07-19\n",
       "\n",
       "[931 rows x 2 columns]), ('economics_54.csv',                y         ds\n",
       "0     368.739968 2000-01-01\n",
       "1     368.192580 2000-01-02\n",
       "2     367.888476 2000-01-03\n",
       "3     373.321806 2000-01-04\n",
       "4     379.099787 2000-01-05\n",
       "..           ...        ...\n",
       "259  2734.732121 2000-09-16\n",
       "260  2747.991068 2000-09-17\n",
       "261  2756.526261 2000-09-18\n",
       "262  2777.610825 2000-09-19\n",
       "263  2778.482591 2000-09-20\n",
       "\n",
       "[264 rows x 2 columns]), ('economics_40.csv',              y         ds\n",
       "0    74.502390 2000-01-31\n",
       "1    48.583922 2000-02-29\n",
       "2    38.305909 2000-03-31\n",
       "3    27.581025 2000-04-30\n",
       "4    21.771713 2000-05-31\n",
       "..         ...        ...\n",
       "72  286.318839 2006-01-31\n",
       "73  143.320393 2006-02-28\n",
       "74  150.470315 2006-03-31\n",
       "75  116.508184 2006-04-30\n",
       "76  127.233067 2006-05-31\n",
       "\n",
       "[77 rows x 2 columns]), ('economics_68.csv',              y         ds\n",
       "0    18.917270 2000-01-31\n",
       "1    18.989467 2000-02-29\n",
       "2    18.664578 2000-03-31\n",
       "3    18.508150 2000-04-30\n",
       "4    18.375788 2000-05-31\n",
       "..         ...        ...\n",
       "139  18.279525 2011-08-31\n",
       "140  18.315623 2011-09-30\n",
       "141  18.219360 2011-10-31\n",
       "142  18.508150 2011-11-30\n",
       "143  18.532216 2011-12-31\n",
       "\n",
       "[144 rows x 2 columns]), ('economics_69.csv',                 y         ds\n",
       "0    39581.370394 2000-01-31\n",
       "1    39159.585365 2000-02-29\n",
       "2    39196.198649 2000-03-31\n",
       "3    39540.363516 2000-04-30\n",
       "4    39606.267427 2000-05-31\n",
       "..            ...        ...\n",
       "139  49935.607048 2011-08-31\n",
       "140  51177.529634 2011-09-30\n",
       "141  52374.051748 2011-10-31\n",
       "142  53330.390721 2011-11-30\n",
       "143  51994.738128 2011-12-31\n",
       "\n",
       "[144 rows x 2 columns]), ('economics_41.csv',              y         ds\n",
       "0    46.957675 2000-01-31\n",
       "1    49.242094 2000-02-29\n",
       "2    52.897164 2000-03-31\n",
       "3    50.612745 2000-04-30\n",
       "4    51.526513 2000-05-31\n",
       "..         ...        ...\n",
       "270  51.069629 2022-07-31\n",
       "271  50.612745 2022-08-31\n",
       "272  46.957675 2022-09-30\n",
       "273  46.500791 2022-10-31\n",
       "274  41.931953 2022-11-30\n",
       "\n",
       "[275 rows x 2 columns]), ('economics_55.csv',                y                  ds\n",
       "0     232.135780 2000-01-01 00:00:00\n",
       "1     214.044571 2000-01-01 01:00:00\n",
       "2     207.421450 2000-01-01 02:00:00\n",
       "3     248.853771 2000-01-01 03:00:00\n",
       "4     275.019923 2000-01-01 04:00:00\n",
       "..           ...                 ...\n",
       "259  2231.339362 2000-01-11 19:00:00\n",
       "260  2264.507371 2000-01-11 20:00:00\n",
       "261  2268.456709 2000-01-11 21:00:00\n",
       "262  2304.651036 2000-01-11 22:00:00\n",
       "263  2296.127087 2000-01-11 23:00:00\n",
       "\n",
       "[264 rows x 2 columns]), ('economics_82.csv',               y         ds\n",
       "0     64.180831 2000-01-02\n",
       "1     59.172141 2000-01-09\n",
       "2     55.761969 2000-01-16\n",
       "3     52.138662 2000-01-23\n",
       "4     62.156042 2000-01-30\n",
       "..          ...        ...\n",
       "742   84.748431 2014-03-23\n",
       "743   94.339539 2014-03-30\n",
       "744  102.971537 2014-04-06\n",
       "745  126.309901 2014-04-13\n",
       "746   15.266178 2014-04-20\n",
       "\n",
       "[747 rows x 2 columns]), ('economics_96.csv',               y         ds\n",
       "0    223.755723 2000-01-31\n",
       "1    200.731808 2000-02-29\n",
       "2    207.107937 2000-03-31\n",
       "3    195.279175 2000-04-30\n",
       "4    206.054682 2000-05-31\n",
       "..          ...        ...\n",
       "481  429.966014 2040-02-29\n",
       "482  451.736514 2040-03-31\n",
       "483  414.312127 2040-04-30\n",
       "484  447.244649 2040-05-31\n",
       "485  494.567980 2040-06-30\n",
       "\n",
       "[486 rows x 2 columns]), ('economics_92.csv',              y         ds\n",
       "0    20.445685 2000-01-31\n",
       "1    18.982600 2000-02-29\n",
       "2    20.027661 2000-03-31\n",
       "3    20.801005 2000-04-30\n",
       "4    20.801005 2000-05-31\n",
       "..         ...        ...\n",
       "220  35.933480 2018-05-31\n",
       "221  35.808073 2018-06-30\n",
       "222  36.853133 2018-07-31\n",
       "223  35.494554 2018-08-31\n",
       "224  35.891677 2018-09-30\n",
       "\n",
       "[225 rows x 2 columns]), ('economics_86.csv',                y         ds\n",
       "0     627.571038 2000-01-01\n",
       "1     475.659882 2000-01-02\n",
       "2     439.753608 2000-01-03\n",
       "3     496.375039 2000-01-04\n",
       "4     547.472428 2000-01-05\n",
       "..           ...        ...\n",
       "926  1891.195659 2002-07-15\n",
       "927  1905.005765 2002-07-16\n",
       "928  1772.428755 2002-07-17\n",
       "929  1826.288165 2002-07-18\n",
       "930  1602.564462 2002-07-19\n",
       "\n",
       "[931 rows x 2 columns]), ('economics_79.csv',                y         ds\n",
       "0    1080.211608 2000-01-02\n",
       "1    1055.464701 2000-01-09\n",
       "2     945.753415 2000-01-16\n",
       "3     932.555065 2000-01-23\n",
       "4    1122.281349 2000-01-30\n",
       "..           ...        ...\n",
       "926   669.412957 2017-10-01\n",
       "927   771.700171 2017-10-08\n",
       "928   795.622181 2017-10-15\n",
       "929   843.466201 2017-10-22\n",
       "930    10.320343 2017-10-29\n",
       "\n",
       "[931 rows x 2 columns]), ('economics_51.csv',                y         ds\n",
       "0   23145.098537 2000-03-31\n",
       "1   22637.744485 2000-06-30\n",
       "2   26549.747539 2000-09-30\n",
       "3   22354.081180 2000-12-31\n",
       "4   22645.844227 2001-03-31\n",
       "5   22884.011109 2001-06-30\n",
       "6   26890.109038 2001-09-30\n",
       "7   22446.797375 2001-12-31\n",
       "8   23121.143981 2002-03-31\n",
       "9   22940.019963 2002-06-30\n",
       "10  27368.510821 2002-09-30\n",
       "11  23047.384628 2002-12-31\n",
       "12  24136.713761 2003-03-31\n",
       "13  24216.849506 2003-06-30\n",
       "14  28706.519267 2003-09-30\n",
       "15  23447.029346 2003-12-31\n",
       "16  24454.844053 2004-03-31\n",
       "17  24360.576843 2004-06-30\n",
       "18  28241.904278 2004-09-30\n",
       "19  23299.510640 2004-12-31\n",
       "20  24177.212471 2005-03-31\n",
       "21  24538.598832 2005-06-30\n",
       "22  28855.933656 2005-09-30\n",
       "23  24146.881522 2005-12-31\n",
       "24  24424.340769 2006-03-31\n",
       "25  24490.517385 2006-06-30\n",
       "26  29128.395191 2006-09-30\n",
       "27  24566.861762 2006-12-31\n",
       "28  25379.076316 2007-03-31\n",
       "29  25613.968835 2007-06-30\n",
       "30  29932.337668 2007-09-30\n",
       "31  25147.630497 2007-12-31\n",
       "32  25644.472118 2008-03-31\n",
       "33  25515.048581 2008-06-30\n",
       "34  29507.704385 2008-09-30\n",
       "35  24630.108683 2008-12-31\n",
       "36  25102.134074 2009-03-31\n",
       "37  25714.784772 2009-06-30\n",
       "38  29899.077026 2009-09-30), ('economics_45.csv',                 y         ds\n",
       "0     4995.575292 2000-01-31\n",
       "1     4742.056691 2000-02-29\n",
       "2     4889.203851 2000-03-31\n",
       "3     4828.926701 2000-04-30\n",
       "4     5227.819605 2000-05-31\n",
       "..            ...        ...\n",
       "100   8192.037096 2008-05-31\n",
       "101   9422.400098 2008-06-30\n",
       "102   7624.722744 2008-07-31\n",
       "103   2510.029286 2008-08-31\n",
       "104  10424.064501 2008-09-30\n",
       "\n",
       "[105 rows x 2 columns]), ('economics_44.csv',               y         ds\n",
       "0    161.514348 2000-01-31\n",
       "1    161.365512 2000-02-29\n",
       "2    135.765820 2000-03-31\n",
       "3     86.203624 2000-04-30\n",
       "4     67.599197 2000-05-31\n",
       "..          ...        ...\n",
       "114  124.603163 2009-07-31\n",
       "115  112.696329 2009-08-31\n",
       "116  144.993616 2009-09-30\n",
       "117  163.002702 2009-10-31\n",
       "118  201.253405 2009-11-30\n",
       "\n",
       "[119 rows x 2 columns]), ('economics_50.csv',              y         ds\n",
       "0   211.860675 2000-03-31\n",
       "1   224.652655 2000-06-30\n",
       "2   250.792787 2000-09-30\n",
       "3   200.181041 2000-12-31\n",
       "4   222.984135 2001-03-31\n",
       "5   238.000807 2001-06-30\n",
       "6   287.500208 2001-09-30\n",
       "7   225.765001 2001-12-31\n",
       "8   273.595882 2002-03-31\n",
       "9   295.842803 2002-06-30\n",
       "10  334.218743 2002-09-30\n",
       "11  274.152055 2002-12-31\n",
       "12  313.084167 2003-03-31\n",
       "13  334.218743 2003-06-30\n",
       "14  389.279874 2003-09-30\n",
       "15  320.314417 2003-12-31\n",
       "16  359.802703 2004-03-31\n",
       "17  403.740373 2004-06-30\n",
       "18  440.447793 2004-09-30\n",
       "19  339.780473 2004-12-31\n",
       "20  359.246530 2005-03-31\n",
       "21  413.751487 2005-06-30\n",
       "22  485.497809 2005-09-30\n",
       "23  378.156413 2005-12-31), ('economics_78.csv',                y         ds\n",
       "0    1535.333049 2000-01-02\n",
       "1    1188.508902 2000-01-09\n",
       "2     917.399885 2000-01-16\n",
       "3    1233.693738 2000-01-23\n",
       "4    1171.411937 2000-01-30\n",
       "..           ...        ...\n",
       "926   795.278706 2017-10-01\n",
       "927   873.436260 2017-10-08\n",
       "928   901.524131 2017-10-15\n",
       "929   605.990879 2017-10-22\n",
       "930     6.375891 2017-10-29\n",
       "\n",
       "[931 rows x 2 columns]), ('economics_87.csv',               y         ds\n",
       "0    621.632005 2000-01-01\n",
       "1    596.963737 2000-01-02\n",
       "2    606.881907 2000-01-03\n",
       "3    605.356034 2000-01-04\n",
       "4    666.645237 2000-01-05\n",
       "..          ...        ...\n",
       "926  800.667685 2002-07-15\n",
       "927  809.822919 2002-07-16\n",
       "928  976.142996 2002-07-17\n",
       "929  743.956099 2002-07-18\n",
       "930  721.068015 2002-07-19\n",
       "\n",
       "[931 rows x 2 columns]), ('economics_93.csv',              y         ds\n",
       "0    11.751942 2000-01-31\n",
       "1    11.751942 2000-02-29\n",
       "2    12.001824 2000-03-31\n",
       "3    12.251706 2000-04-30\n",
       "4    12.501588 2000-05-31\n",
       "..         ...        ...\n",
       "117  15.999936 2009-10-31\n",
       "118  17.624169 2009-11-30\n",
       "119  15.125349 2009-12-31\n",
       "120  13.376175 2010-01-31\n",
       "121  13.501116 2010-02-28\n",
       "\n",
       "[122 rows x 2 columns]), ('economics_85.csv',                y         ds\n",
       "0    1819.789013 2000-01-02\n",
       "1    1598.750739 2000-01-09\n",
       "2    1709.931667 2000-01-16\n",
       "3    1635.811048 2000-01-23\n",
       "4    1584.191332 2000-01-30\n",
       "..           ...        ...\n",
       "857  2371.722905 2016-06-05\n",
       "858  2289.660791 2016-06-12\n",
       "859  2522.611307 2016-06-19\n",
       "860  1765.522131 2016-06-26\n",
       "861  2650.998807 2016-07-03\n",
       "\n",
       "[862 rows x 2 columns]), ('economics_91.csv',              y         ds\n",
       "0   166.802334 2000-01-31\n",
       "1   106.848650 2000-02-29\n",
       "2    83.073914 2000-03-31\n",
       "3    58.265493 2000-04-30\n",
       "4    44.827598 2000-05-31\n",
       "..         ...        ...\n",
       "72  656.768648 2006-01-31\n",
       "73  325.989702 2006-02-28\n",
       "74  342.528649 2006-03-31\n",
       "75  263.968650 2006-04-30\n",
       "76  288.777071 2006-05-31\n",
       "\n",
       "[77 rows x 2 columns]), ('economics_46.csv',              y         ds\n",
       "0    14.972683 2000-03-31\n",
       "1    15.595982 2000-06-30\n",
       "2    16.045535 2000-09-30\n",
       "3    15.574112 2000-12-31\n",
       "4    15.478126 2001-03-31\n",
       "..         ...        ...\n",
       "213  80.033952 2053-06-30\n",
       "214  81.155404 2053-09-30\n",
       "215  79.869926 2053-12-31\n",
       "216  81.052129 2054-03-31\n",
       "217  80.726507 2054-06-30\n",
       "\n",
       "[218 rows x 2 columns]), ('economics_52.csv',                 y         ds\n",
       "0      320.176928 2000-01-01\n",
       "1      324.420872 2000-01-02\n",
       "2      329.858426 2000-01-03\n",
       "3      342.855505 2000-01-04\n",
       "4      350.812901 2000-01-05\n",
       "..            ...        ...\n",
       "259  20324.804071 2000-09-16\n",
       "260  20533.420458 2000-09-17\n",
       "261  20675.725215 2000-09-18\n",
       "262  20974.658041 2000-09-19\n",
       "263  21027.972591 2000-09-20\n",
       "\n",
       "[264 rows x 2 columns]), ('economics_53.csv',                 y         ds\n",
       "0     1820.613919 2000-01-01\n",
       "1     1850.739320 2000-01-02\n",
       "2     1856.668256 2000-01-03\n",
       "3     1857.309222 2000-01-04\n",
       "4     1866.603228 2000-01-05\n",
       "..            ...        ...\n",
       "259  15214.239099 2000-09-16\n",
       "260  15306.377959 2000-09-17\n",
       "261  15363.584173 2000-09-18\n",
       "262  15423.834975 2000-09-19\n",
       "263  15503.795482 2000-09-20\n",
       "\n",
       "[264 rows x 2 columns]), ('economics_47.csv',              y         ds\n",
       "0    15.106400 2000-03-31\n",
       "1    15.175562 2000-06-30\n",
       "2    15.205498 2000-09-30\n",
       "3    15.214788 2000-12-31\n",
       "4    15.172465 2001-03-31\n",
       "..         ...        ...\n",
       "228  16.741511 2057-03-31\n",
       "229  17.235967 2057-06-30\n",
       "230  17.348484 2057-09-30\n",
       "231  17.274161 2057-12-31\n",
       "232  16.927319 2058-03-31\n",
       "\n",
       "[233 rows x 2 columns]), ('economics_90.csv',              y         ds\n",
       "0    39.173531 2000-01-31\n",
       "1    42.445618 2000-02-29\n",
       "2    50.080487 2000-03-31\n",
       "3    49.535139 2000-04-30\n",
       "4    44.081661 2000-05-31\n",
       "..         ...        ...\n",
       "102  45.172357 2008-07-31\n",
       "103  44.627009 2008-08-31\n",
       "104  40.264227 2008-09-30\n",
       "105  39.718879 2008-10-31\n",
       "106  34.265401 2008-11-30\n",
       "\n",
       "[107 rows x 2 columns]), ('economics_84.csv',               y         ds\n",
       "0    665.569295 2000-01-02\n",
       "1    617.945021 2000-01-09\n",
       "2    509.708033 2000-01-16\n",
       "3    560.218627 2000-01-23\n",
       "4    531.355431 2000-01-30\n",
       "..          ...        ...\n",
       "926  701.648291 2017-10-01\n",
       "927  746.386246 2017-10-08\n",
       "928  753.602045 2017-10-15\n",
       "929  840.191635 2017-10-22\n",
       "930    8.931571 2017-10-29\n",
       "\n",
       "[931 rows x 2 columns]), ('economics_7.csv',               y         ds\n",
       "0   5221.251156 2000-01-01\n",
       "1   4848.653572 2000-01-02\n",
       "2   6163.974872 2000-01-03\n",
       "3   8417.412810 2000-01-04\n",
       "4   5860.483486 2000-01-05\n",
       "5   4549.193381 2000-01-06\n",
       "6   2509.984657 2000-01-07\n",
       "7   2934.411889 2000-01-08\n",
       "8   5319.151603 2000-01-09\n",
       "9   8296.476964 2000-01-10\n",
       "10  5748.761800 2000-01-11\n",
       "11  5389.409571 2000-01-12\n",
       "12  4691.436971 2000-01-13\n",
       "13  6313.129083 2000-01-14\n",
       "14  6454.796789 2000-01-15\n",
       "15  5507.465992 2000-01-16\n",
       "16  4029.745126 2000-01-17\n",
       "17  5869.121761 2000-01-18\n",
       "18  6161.095447 2000-01-19\n",
       "19  5298.419743 2000-01-20), ('economics_20.csv',                 y         ds\n",
       "0     4544.988225 2000-01-31\n",
       "1     4577.856990 2000-02-29\n",
       "2     4625.422278 2000-03-31\n",
       "3     4534.677274 2000-04-30\n",
       "4     4677.974192 2000-05-31\n",
       "..            ...        ...\n",
       "445  16246.677462 2037-02-28\n",
       "446  16646.109224 2037-03-31\n",
       "447  16296.547372 2037-04-30\n",
       "448  16200.913288 2037-05-31\n",
       "449  15946.348014 2037-06-30\n",
       "\n",
       "[450 rows x 2 columns]), ('economics_34.csv',               y         ds\n",
       "0    592.849126 2000-01-31\n",
       "1    532.843824 2000-02-29\n",
       "2    584.515057 2000-03-31\n",
       "3    564.513289 2000-04-30\n",
       "4    577.847801 2000-05-31\n",
       "..          ...        ...\n",
       "415  164.477936 2034-08-31\n",
       "416  157.810681 2034-09-30\n",
       "417  164.477936 2034-10-31\n",
       "418  157.810681 2034-11-30\n",
       "419  164.477936 2034-12-31\n",
       "\n",
       "[420 rows x 2 columns]), ('economics_35.csv',                y         ds\n",
       "0    4763.513596 2000-01-31\n",
       "1    5265.709712 2000-02-29\n",
       "2    6298.089080 2000-03-31\n",
       "3    5572.310347 2000-04-30\n",
       "4    5670.108088 2000-05-31\n",
       "..           ...        ...\n",
       "171  8281.402109 2014-04-30\n",
       "172  7481.410299 2014-05-31\n",
       "173  8666.932754 2014-06-30\n",
       "174  9330.762436 2014-07-31\n",
       "175  7348.392793 2014-08-31\n",
       "\n",
       "[176 rows x 2 columns]), ('economics_21.csv',              y         ds\n",
       "0    40.579832 2000-01-31\n",
       "1    40.623397 2000-02-29\n",
       "2    40.666961 2000-03-31\n",
       "3    41.015479 2000-04-30\n",
       "4    41.015479 2000-05-31\n",
       "..         ...        ...\n",
       "259  60.793885 2021-08-31\n",
       "260  60.619626 2021-09-30\n",
       "261  60.663191 2021-10-31\n",
       "262  61.055274 2021-11-30\n",
       "263  61.055274 2021-12-31\n",
       "\n",
       "[264 rows x 2 columns]), ('economics_6.csv',              y         ds\n",
       "0    47.698077 2000-01-01\n",
       "1    54.705476 2000-01-02\n",
       "2    57.439226 2000-01-03\n",
       "3    60.167209 2000-01-04\n",
       "4    49.843552 2000-01-05\n",
       "5    60.542091 2000-01-06\n",
       "6    78.230726 2000-01-07\n",
       "7    94.967739 2000-01-08\n",
       "8   130.097011 2000-01-09\n",
       "9    65.940383 2000-01-10\n",
       "10   94.783182 2000-01-11\n",
       "11  132.986481 2000-01-12\n",
       "12  172.718143 2000-01-13\n",
       "13  232.751075 2000-01-14\n",
       "14  301.417814 2000-01-15\n",
       "15  354.720183 2000-01-16\n",
       "16  414.372466 2000-01-17\n",
       "17  395.363095 2000-01-18\n",
       "18  393.753989 2000-01-19\n",
       "19  172.833491 2000-01-20), ('economics_37.csv',                 y         ds\n",
       "0     2015.097207 2000-01-31\n",
       "1     2072.605461 2000-02-29\n",
       "2     2214.778644 2000-03-31\n",
       "3     2162.062745 2000-04-30\n",
       "4     2463.981077 2000-05-31\n",
       "..            ...        ...\n",
       "471  20829.880909 2039-04-30\n",
       "472  22804.330957 2039-05-31\n",
       "473  23131.808513 2039-06-30\n",
       "474  24547.150537 2039-07-31\n",
       "475  23106.249289 2039-08-31\n",
       "\n",
       "[476 rows x 2 columns]), ('economics_4.csv',               y         ds\n",
       "0   1878.084288 2000-01-01\n",
       "1   1920.571814 2000-01-02\n",
       "2   2016.835951 2000-01-03\n",
       "3   1980.637931 2000-01-04\n",
       "4   2923.965982 2000-01-05\n",
       "5   3878.592015 2000-01-06\n",
       "6   5010.809857 2000-01-07\n",
       "7   6676.906238 2000-01-08\n",
       "8   6768.491054 2000-01-09\n",
       "9   5468.244654 2000-01-10\n",
       "10  5175.742590 2000-01-11\n",
       "11  5660.532735 2000-01-12\n",
       "12  6168.363645 2000-01-13\n",
       "13  7041.065970 2000-01-14\n",
       "14  7300.830576 2000-01-15\n",
       "15  8097.026887 2000-01-16\n",
       "16  3408.809504 2000-01-17\n",
       "17  2852.806493 2000-01-18\n",
       "18  2673.106320 2000-01-19\n",
       "19  2996.477671 2000-01-20), ('economics_23.csv',               y         ds\n",
       "0    145.138362 2000-01-31\n",
       "1    152.669693 2000-02-29\n",
       "2    170.242799 2000-03-31\n",
       "3    166.477134 2000-04-30\n",
       "4    156.435358 2000-05-31\n",
       "..          ...        ...\n",
       "139  765.217969 2011-08-31\n",
       "140  642.206225 2011-09-30\n",
       "141  583.210797 2011-10-31\n",
       "142  494.090043 2011-11-30\n",
       "143  546.809362 2011-12-31\n",
       "\n",
       "[144 rows x 2 columns]), ('economics_22.csv',              y         ds\n",
       "0     9.107105 2000-01-31\n",
       "1     8.431168 2000-02-29\n",
       "2     8.570638 2000-03-31\n",
       "3     9.272153 2000-04-30\n",
       "4     9.183904 2000-05-31\n",
       "..         ...        ...\n",
       "199  44.551654 2016-08-31\n",
       "200  37.924577 2016-09-30\n",
       "201  47.393429 2016-10-31\n",
       "202  47.011825 2016-11-30\n",
       "203  40.205977 2016-12-31\n",
       "\n",
       "[204 rows x 2 columns]), ('economics_5.csv',              y         ds\n",
       "0   120.652404 2000-01-01\n",
       "1   151.146372 2000-01-02\n",
       "2   184.745215 2000-01-03\n",
       "3   227.146722 2000-01-04\n",
       "4   282.501109 2000-01-05\n",
       "5   303.952977 2000-01-06\n",
       "6   306.917696 2000-01-07\n",
       "7   270.459252 2000-01-08\n",
       "8   339.097445 2000-01-09\n",
       "9   534.247158 2000-01-10\n",
       "10  503.470929 2000-01-11\n",
       "11  271.140573 2000-01-12\n",
       "12  272.211219 2000-01-13\n",
       "13  261.018094 2000-01-14\n",
       "14  243.323222 2000-01-15\n",
       "15  255.489663 2000-01-16\n",
       "16  278.907629 2000-01-17\n",
       "17  339.700901 2000-01-18\n",
       "18  308.438014 2000-01-19\n",
       "19  213.714971 2000-01-20), ('economics_36.csv',                y         ds\n",
       "0    2336.995804 2000-01-31\n",
       "1    3110.312246 2000-02-29\n",
       "2    4281.293709 2000-03-31\n",
       "3    5122.426240 2000-04-30\n",
       "4    5190.597386 2000-05-31\n",
       "..           ...        ...\n",
       "103  5948.646332 2008-08-31\n",
       "104  5118.875659 2008-09-30\n",
       "105  7589.014542 2008-10-31\n",
       "106  6111.262921 2008-11-30\n",
       "107  5187.046805 2008-12-31\n",
       "\n",
       "[108 rows x 2 columns]), ('economics_32.csv',                y         ds\n",
       "0    6665.953844 2000-01-02\n",
       "1    6477.028457 2000-01-09\n",
       "2    6626.761875 2000-01-16\n",
       "3    7271.921975 2000-01-23\n",
       "4    6921.204101 2000-01-30\n",
       "..           ...        ...\n",
       "740  9227.500718 2014-03-09\n",
       "741  9364.170147 2014-03-16\n",
       "742  9080.782066 2014-03-23\n",
       "743  9232.525330 2014-03-30\n",
       "744  9326.988023 2014-04-06\n",
       "\n",
       "[745 rows x 2 columns]), ('economics_1.csv',              y         ds\n",
       "0   422.303975 2000-01-01\n",
       "1   461.676671 2000-01-02\n",
       "2   438.652980 2000-01-03\n",
       "3   489.952703 2000-01-04\n",
       "4   708.195042 2000-01-05\n",
       "5   745.068704 2000-01-06\n",
       "6   631.630841 2000-01-07\n",
       "7   559.790569 2000-01-08\n",
       "8   623.974818 2000-01-09\n",
       "9   549.635513 2000-01-10\n",
       "10  486.778255 2000-01-11\n",
       "11  442.923984 2000-01-12\n",
       "12  561.590351 2000-01-13\n",
       "13  813.031302 2000-01-14\n",
       "14  901.498691 2000-01-15\n",
       "15  900.616679 2000-01-16\n",
       "16  781.974151 2000-01-17\n",
       "17  781.406008 2000-01-18\n",
       "18  713.018296 2000-01-19\n",
       "19  830.417267 2000-01-20), ('economics_26.csv',              y         ds\n",
       "0    65.449895 2000-03-31\n",
       "1    45.423066 2000-06-30\n",
       "2    56.753701 2000-09-30\n",
       "3    60.929768 2000-12-31\n",
       "4    69.167164 2001-03-31\n",
       "..         ...        ...\n",
       "63  120.148843 2015-12-31\n",
       "64  144.801332 2016-03-31\n",
       "65   97.855896 2016-06-30\n",
       "66  122.469066 2016-09-30\n",
       "67  131.575149 2016-12-31\n",
       "\n",
       "[68 rows x 2 columns]), ('economics_27.csv',             y         ds\n",
       "0    4.117732 2000-01-31\n",
       "1    4.129107 2000-02-29\n",
       "2    4.170528 2000-03-31\n",
       "3    4.135880 2000-04-30\n",
       "4    4.285500 2000-05-31\n",
       "..        ...        ...\n",
       "159  5.365484 2013-04-30\n",
       "160  5.548882 2013-05-31\n",
       "161  5.411594 2013-06-30\n",
       "162  5.692596 2013-07-31\n",
       "163  5.681394 2013-08-31\n",
       "\n",
       "[164 rows x 2 columns]), ('economics_33.csv',               y         ds\n",
       "0    259.140278 2000-01-31\n",
       "1    247.186561 2000-02-29\n",
       "2    280.913121 2000-03-31\n",
       "3    287.743817 2000-04-30\n",
       "4    318.055030 2000-05-31\n",
       "..          ...        ...\n",
       "127  372.700596 2010-08-31\n",
       "128  353.062346 2010-09-30\n",
       "129  353.489264 2010-10-31\n",
       "130  334.704851 2010-11-30\n",
       "131  351.354672 2010-12-31\n",
       "\n",
       "[132 rows x 2 columns]), ('economics_19.csv',                y         ds\n",
       "0     934.063305 2000-01-31\n",
       "1     942.046621 2000-02-29\n",
       "2     950.029937 2000-03-31\n",
       "3     943.643285 2000-04-30\n",
       "4     954.819927 2000-05-31\n",
       "..           ...        ...\n",
       "319  2511.566560 2026-08-31\n",
       "320  2545.096487 2026-09-30\n",
       "321  2557.869793 2026-10-31\n",
       "322  2556.273130 2026-11-30\n",
       "323  2548.289814 2026-12-31\n",
       "\n",
       "[324 rows x 2 columns]), ('economics_2.csv',                y         ds\n",
       "0    2155.914051 2000-01-01\n",
       "1    2739.317736 2000-01-02\n",
       "2    3401.382592 2000-01-03\n",
       "3    4270.615056 2000-01-04\n",
       "4    5233.930220 2000-01-05\n",
       "5    4784.697636 2000-01-06\n",
       "6    5139.108649 2000-01-07\n",
       "7    4593.216795 2000-01-08\n",
       "8    5430.734711 2000-01-09\n",
       "9    6776.140072 2000-01-10\n",
       "10   7115.792643 2000-01-11\n",
       "11   7003.446606 2000-01-12\n",
       "12   7850.171971 2000-01-13\n",
       "13   9835.949741 2000-01-14\n",
       "14   9772.406975 2000-01-15\n",
       "15   9902.713221 2000-01-16\n",
       "16   8700.800082 2000-01-17\n",
       "17   9544.001609 2000-01-18\n",
       "18  10588.592406 2000-01-19\n",
       "19  12814.673233 2000-01-20), ('economics_25.csv',              y         ds\n",
       "0    13.000434 2000-01-31\n",
       "1    12.999849 2000-02-29\n",
       "2    12.973695 2000-03-31\n",
       "3    12.992822 2000-04-30\n",
       "4    12.979160 2000-05-31\n",
       "..         ...        ...\n",
       "411  19.305738 2034-04-30\n",
       "412  19.451143 2034-05-31\n",
       "413  19.546388 2034-06-30\n",
       "414  19.586008 2034-07-31\n",
       "415  19.511647 2034-08-31\n",
       "\n",
       "[416 rows x 2 columns]), ('economics_31.csv',                  y         ds\n",
       "0     45313.710505 2000-01-31\n",
       "1     44897.815832 2000-02-29\n",
       "2     49832.754855 2000-03-31\n",
       "3     50706.391988 2000-04-30\n",
       "4     58705.002327 2000-05-31\n",
       "..             ...        ...\n",
       "187  126398.705781 2015-08-31\n",
       "188  122749.682088 2015-09-30\n",
       "189  122749.682088 2015-10-31\n",
       "190  112518.156500 2015-11-30\n",
       "191  117604.987491 2015-12-31\n",
       "\n",
       "[192 rows x 2 columns]), ('economics_30.csv',                 y         ds\n",
       "0     2170.537117 2000-01-31\n",
       "1     2090.872993 2000-02-29\n",
       "2     2278.020459 2000-03-31\n",
       "3     2384.239291 2000-04-30\n",
       "4     2757.269714 2000-05-31\n",
       "..            ...        ...\n",
       "471  61986.913746 2039-04-30\n",
       "472  71611.098646 2039-05-31\n",
       "473  78079.066820 2039-06-30\n",
       "474  84225.849476 2039-07-31\n",
       "475  75948.367627 2039-08-31\n",
       "\n",
       "[476 rows x 2 columns]), ('economics_24.csv',               y         ds\n",
       "0    570.756788 2000-03-31\n",
       "1    429.126876 2000-06-30\n",
       "2    457.053901 2000-09-30\n",
       "3    618.631687 2000-12-31\n",
       "4    526.871463 2001-03-31\n",
       "..          ...        ...\n",
       "213  798.162561 2053-06-30\n",
       "214  840.053098 2053-09-30\n",
       "215  977.693435 2053-12-31\n",
       "216  830.079161 2054-03-31\n",
       "217  750.287661 2054-06-30\n",
       "\n",
       "[218 rows x 2 columns]), ('economics_3.csv',                y         ds\n",
       "0     646.874776 2000-01-01\n",
       "1     688.586614 2000-01-02\n",
       "2     768.467089 2000-01-03\n",
       "3     841.534823 2000-01-04\n",
       "4     908.265122 2000-01-05\n",
       "5    1141.209032 2000-01-06\n",
       "6    1194.803560 2000-01-07\n",
       "7    1414.654907 2000-01-08\n",
       "8    1860.911085 2000-01-09\n",
       "9    3088.918555 2000-01-10\n",
       "10   3647.793816 2000-01-11\n",
       "11   4382.446452 2000-01-12\n",
       "12   8323.178151 2000-01-13\n",
       "13   8590.128156 2000-01-14\n",
       "14   8864.020532 2000-01-15\n",
       "15   8398.075099 2000-01-16\n",
       "16   8716.358319 2000-01-17\n",
       "17   9080.789582 2000-01-18\n",
       "18   9738.240748 2000-01-19\n",
       "19  10444.893448 2000-01-20), ('economics_18.csv',                y         ds\n",
       "0    2953.266287 2000-01-31\n",
       "1    2934.621280 2000-02-29\n",
       "2    3027.846315 2000-03-31\n",
       "3    3102.426343 2000-04-30\n",
       "4    3177.006371 2000-05-31\n",
       "..           ...        ...\n",
       "319  5339.827183 2026-08-31\n",
       "320  5227.957141 2026-09-30\n",
       "321  5358.472190 2026-10-31\n",
       "322  5339.827183 2026-11-30\n",
       "323  5283.892162 2026-12-31\n",
       "\n",
       "[324 rows x 2 columns]), ('economics_15.csv',              y         ds\n",
       "0   157.760815 2000-01-01\n",
       "1   136.613960 2000-01-02\n",
       "2   149.792435 2000-01-03\n",
       "3   168.027766 2000-01-04\n",
       "4   132.783008 2000-01-05\n",
       "..         ...        ...\n",
       "81  301.957843 2000-03-22\n",
       "82  348.388979 2000-03-23\n",
       "83  347.929265 2000-03-24\n",
       "84  406.466210 2000-03-25\n",
       "85  387.004974 2000-03-26\n",
       "\n",
       "[86 rows x 2 columns]), ('economics_29.csv',               y         ds\n",
       "0    338.402916 2000-01-31\n",
       "1    333.974710 2000-02-29\n",
       "2    334.528236 2000-03-31\n",
       "3    341.032162 2000-04-30\n",
       "4    344.076554 2000-05-31\n",
       "..          ...        ...\n",
       "173  552.894110 2014-06-30\n",
       "174  552.063821 2014-07-31\n",
       "175  556.215264 2014-08-31\n",
       "176  556.492027 2014-09-30\n",
       "177  559.536418 2014-10-31\n",
       "\n",
       "[178 rows x 2 columns]), ('economics_28.csv',                y         ds\n",
       "0   6.057919e+04 2000-01-31\n",
       "1   4.736389e+04 2000-02-29\n",
       "2   5.084013e+04 2000-03-31\n",
       "3   3.399981e+04 2000-04-30\n",
       "4   5.956397e+04 2000-05-31\n",
       "..           ...        ...\n",
       "82  1.609121e+06 2006-11-30\n",
       "83  2.704533e+06 2006-12-31\n",
       "84  2.033695e+06 2007-01-31\n",
       "85  2.135183e+06 2007-02-28\n",
       "86  1.874901e+06 2007-03-31\n",
       "\n",
       "[87 rows x 2 columns]), ('economics_14.csv',              y         ds\n",
       "0    43.488471 2000-01-01\n",
       "1    41.277337 2000-01-02\n",
       "2    44.182599 2000-01-03\n",
       "3    50.151260 2000-01-04\n",
       "4    55.632912 2000-01-05\n",
       "5    59.779487 2000-01-06\n",
       "6    61.810091 2000-01-07\n",
       "7    93.107426 2000-01-08\n",
       "8   100.422360 2000-01-09\n",
       "9    90.125195 2000-01-10\n",
       "10   79.699281 2000-01-11\n",
       "11   89.106394 2000-01-12\n",
       "12   90.731158 2000-01-13\n",
       "13   87.170953 2000-01-14\n",
       "14   85.185131 2000-01-15\n",
       "15   68.738776 2000-01-16\n",
       "16   77.994749 2000-01-17\n",
       "17   73.852372 2000-01-18\n",
       "18   73.978323 2000-01-19\n",
       "19   72.360557 2000-01-20\n",
       "20   73.832780 2000-01-21\n",
       "21   76.637281 2000-01-22\n",
       "22   79.009351 2000-01-23\n",
       "23   75.086688 2000-01-24\n",
       "24   81.591339 2000-01-25\n",
       "25   89.489844 2000-01-26\n",
       "26   84.969615 2000-01-27\n",
       "27   87.613179 2000-01-28\n",
       "28   90.381295 2000-01-29\n",
       "29   88.165963 2000-01-30\n",
       "30   92.062036 2000-01-31\n",
       "31   95.308764 2000-02-01\n",
       "32  103.119103 2000-02-02\n",
       "33  104.123909 2000-02-03\n",
       "34  107.822660 2000-02-04\n",
       "35  119.572456 2000-02-05\n",
       "36  125.911971 2000-02-06\n",
       "37  130.415406 2000-02-07\n",
       "38  122.537893 2000-02-08\n",
       "39  130.139715 2000-02-09\n",
       "40  139.152183 2000-02-10\n",
       "41  144.924921 2000-02-11\n",
       "42  160.574988 2000-02-12\n",
       "43  170.091259 2000-02-13\n",
       "44  166.928498 2000-02-14\n",
       "45  164.518642 2000-02-15\n",
       "46  170.736406 2000-02-16\n",
       "47  153.668694 2000-02-17\n",
       "48  146.447524 2000-02-18\n",
       "49  147.571284 2000-02-19\n",
       "50  153.763857 2000-02-20\n",
       "51  154.610525 2000-02-21\n",
       "52  163.334706 2000-02-22\n",
       "53  163.604801 2000-02-23\n",
       "54  162.019222 2000-02-24\n",
       "55  157.445814 2000-02-25\n",
       "56  160.232122 2000-02-26), ('economics_16.csv',               y         ds\n",
       "0   9609.725528 2000-01-01\n",
       "1   9499.512169 2000-01-02\n",
       "2   8838.232015 2000-01-03\n",
       "3   8287.165220 2000-01-04\n",
       "4   7846.311784 2000-01-05\n",
       "5   7074.818270 2000-01-06\n",
       "6   6193.111398 2000-01-07\n",
       "7   5862.471321 2000-01-08\n",
       "8   5090.977808 2000-01-09\n",
       "9   4980.764449 2000-01-10\n",
       "10  4870.551090 2000-01-11\n",
       "11  4870.551090 2000-01-12\n",
       "12  4209.270936 2000-01-13\n",
       "13  4099.057576 2000-01-14\n",
       "14  3988.844217 2000-01-15\n",
       "15  3547.990781 2000-01-16\n",
       "16  4099.057576 2000-01-17\n",
       "17  5752.257962 2000-01-18\n",
       "18  6633.964834 2000-01-19\n",
       "19  6854.391552 2000-01-20\n",
       "20  7074.818270 2000-01-21\n",
       "21  7185.031630 2000-01-22\n",
       "22  6193.111398 2000-01-23\n",
       "23  5972.684680 2000-01-24\n",
       "24  5642.044603 2000-01-25), ('economics_17.csv',                y         ds\n",
       "0    4889.284525 2000-01-31\n",
       "1    5172.508185 2000-02-29\n",
       "2    5427.330587 2000-03-31\n",
       "3    5854.927311 2000-04-30\n",
       "4    5427.330587 2000-05-31\n",
       "..           ...        ...\n",
       "188  7807.513828 2015-09-30\n",
       "189  7870.627736 2015-10-31\n",
       "190  7888.772984 2015-11-30\n",
       "191  7923.485633 2015-12-31\n",
       "192  7947.153349 2016-01-31\n",
       "\n",
       "[193 rows x 2 columns]), ('economics_8.csv',             y         ds\n",
       "0   58.024331 2000-01-01\n",
       "1   54.862339 2000-01-02\n",
       "2   57.534702 2000-01-03\n",
       "3   54.015785 2000-01-04\n",
       "4   62.693340 2000-01-05\n",
       "5   62.755879 2000-01-06\n",
       "6   62.868752 2000-01-07\n",
       "7   69.116470 2000-01-08\n",
       "8   81.715628 2000-01-09\n",
       "9   90.278784 2000-01-10\n",
       "10  86.762918 2000-01-11\n",
       "11  86.753766 2000-01-12\n",
       "12  89.525275 2000-01-13\n",
       "13  94.770857 2000-01-14\n",
       "14  91.865119 2000-01-15\n",
       "15  83.112823 2000-01-16\n",
       "16  28.448342 2000-01-17\n",
       "17  69.407807 2000-01-18\n",
       "18  77.603361 2000-01-19\n",
       "19  91.033819 2000-01-20), ('economics_13.csv',                y         ds\n",
       "0     283.084657 2000-01-01\n",
       "1     306.288391 2000-01-02\n",
       "2     328.585730 2000-01-03\n",
       "3     343.813180 2000-01-04\n",
       "4     360.853423 2000-01-05\n",
       "5     383.513320 2000-01-06\n",
       "6     432.639976 2000-01-07\n",
       "7     485.210937 2000-01-08\n",
       "8     534.881431 2000-01-09\n",
       "9     572.950057 2000-01-10\n",
       "10    628.965322 2000-01-11\n",
       "11    685.705704 2000-01-12\n",
       "12    746.071669 2000-01-13\n",
       "13    800.455422 2000-01-14\n",
       "14    897.621059 2000-01-15\n",
       "15   1048.082775 2000-01-16\n",
       "16   1117.150140 2000-01-17\n",
       "17   1203.801586 2000-01-18\n",
       "18   1329.246775 2000-01-19\n",
       "19   1471.188369 2000-01-20\n",
       "20   1687.454424 2000-01-21\n",
       "21   1901.363851 2000-01-22\n",
       "22   2101.677339 2000-01-23\n",
       "23   2283.137793 2000-01-24\n",
       "24   2454.809172 2000-01-25\n",
       "25   2684.308607 2000-01-26\n",
       "26   2864.318828 2000-01-27\n",
       "27   3011.517518 2000-01-28\n",
       "28   3159.260045 2000-01-29\n",
       "29   3402.174139 2000-01-30\n",
       "30   3684.244535 2000-01-31\n",
       "31   3876.581740 2000-02-01\n",
       "32   4192.007504 2000-02-02\n",
       "33   4321.259556 2000-02-03\n",
       "34   4450.149049 2000-02-04\n",
       "35   4657.351146 2000-02-05\n",
       "36   4825.578220 2000-02-06\n",
       "37   4964.981906 2000-02-07\n",
       "38   5102.572800 2000-02-08\n",
       "39   5356.544924 2000-02-09\n",
       "40   5619.581006 2000-02-10\n",
       "41   6014.225770 2000-02-11\n",
       "42   6408.507975 2000-02-12\n",
       "43   6829.800778 2000-02-13\n",
       "44   7220.819958 2000-02-14\n",
       "45   7731.302114 2000-02-15\n",
       "46   8117.426757 2000-02-16\n",
       "47   8669.965682 2000-02-17\n",
       "48   9451.278925 2000-02-18\n",
       "49  10113.129193 2000-02-19\n",
       "50  10482.394872 2000-02-20\n",
       "51  10551.462238 2000-02-21\n",
       "52  10492.727785 2000-02-22\n",
       "53  10463.179280 2000-02-23\n",
       "54  10706.818491 2000-02-24\n",
       "55  11001.397150 2000-02-25), ('economics_12.csv',               y         ds\n",
       "0   3725.636371 2000-03-31\n",
       "1   4317.710586 2000-06-30\n",
       "2   4057.897429 2000-09-30\n",
       "3   3910.503426 2000-12-31\n",
       "4   3888.019595 2001-03-31\n",
       "5   4012.929767 2001-06-30\n",
       "6   3868.033967 2001-09-30\n",
       "7   3703.152540 2001-12-31\n",
       "8   3885.521391 2002-03-31\n",
       "9   4175.312990 2002-06-30\n",
       "10  3835.557323 2002-09-30\n",
       "11  3735.629185 2002-12-31\n",
       "12  4000.438750 2003-03-31\n",
       "13  4317.710586 2003-06-30\n",
       "14  4055.399225 2003-09-30\n",
       "15  3848.048340 2003-12-31\n",
       "16  3957.969291 2004-03-31\n",
       "17  4619.993202 2004-06-30\n",
       "18  4427.631538 2004-09-30\n",
       "19  4200.295025 2004-12-31\n",
       "20  4345.190824 2005-03-31\n",
       "21  4777.380019 2005-06-30\n",
       "22  4575.025541 2005-09-30\n",
       "23  4130.345328 2005-12-31), ('economics_9.csv',               y         ds\n",
       "0   7115.728041 2000-01-01\n",
       "1   7405.095994 2000-01-02\n",
       "2   7329.341648 2000-01-03\n",
       "3   7549.779971 2000-01-04\n",
       "4   7504.054374 2000-01-05\n",
       "5   7423.522727 2000-01-06\n",
       "6   7065.225144 2000-01-07\n",
       "7   6335.663018 2000-01-08\n",
       "8   5709.836573 2000-01-09\n",
       "9   5880.454469 2000-01-10\n",
       "10  6496.043841 2000-01-11\n",
       "11  7763.393577 2000-01-12\n",
       "12  8452.689880 2000-01-13\n",
       "13  7577.078834 2000-01-14\n",
       "14  6221.007791 2000-01-15\n",
       "15  6414.147250 2000-01-16\n",
       "16  6614.793897 2000-01-17\n",
       "17  8529.126698 2000-01-18\n",
       "18  7975.642241 2000-01-19\n",
       "19  8873.092377 2000-01-20), ('economics_38.csv',             y         ds\n",
       "0   21.533495 2000-01-01\n",
       "1   21.632617 2000-01-02\n",
       "2   21.623439 2000-01-03\n",
       "3   21.647302 2000-01-04\n",
       "4   21.819848 2000-01-05\n",
       "..        ...        ...\n",
       "95  22.495346 2000-04-05\n",
       "96  22.486168 2000-04-06\n",
       "97  22.489839 2000-04-07\n",
       "98  22.511866 2000-04-08\n",
       "99  22.515537 2000-04-09\n",
       "\n",
       "[100 rows x 2 columns]), ('economics_100.csv',              y         ds\n",
       "0    26.341057 2000-01-31\n",
       "1    26.108201 2000-02-29\n",
       "2    26.137308 2000-03-31\n",
       "3    26.479315 2000-04-30\n",
       "4    26.639403 2000-05-31\n",
       "..         ...        ...\n",
       "173  37.620004 2014-06-30\n",
       "174  37.576344 2014-07-31\n",
       "175  37.794646 2014-08-31\n",
       "176  37.809199 2014-09-30\n",
       "177  37.969287 2014-10-31\n",
       "\n",
       "[178 rows x 2 columns]), ('economics_10.csv',              y         ds\n",
       "0   111.795110 2000-03-31\n",
       "1   139.837525 2000-06-30\n",
       "2   133.654945 2000-09-30\n",
       "3   125.926721 2000-12-31\n",
       "4   147.344943 2001-03-31\n",
       "5   145.799298 2001-06-30\n",
       "6   172.737681 2001-09-30\n",
       "7   134.317364 2001-12-31\n",
       "8   115.990432 2002-03-31\n",
       "9   124.160269 2002-06-30\n",
       "10  118.640109 2002-09-30\n",
       "11  165.892682 2002-12-31\n",
       "12  132.330107 2003-03-31\n",
       "13  144.032847 2003-06-30\n",
       "14  180.907518 2003-09-30\n",
       "15  123.718657 2003-12-31\n",
       "16  163.905424 2004-03-31\n",
       "17  185.986066 2004-06-30\n",
       "18  168.983972 2004-09-30\n",
       "19  120.185754 2004-12-31\n",
       "20  191.506226 2005-03-31\n",
       "21  166.555101 2005-06-30\n",
       "22  182.673969 2005-09-30\n",
       "23  568.643584 2005-12-31\n",
       "24  200.338483 2006-03-31\n",
       "25  193.935097 2006-06-30\n",
       "26  176.270583 2006-09-30\n",
       "27  134.538171 2006-12-31\n",
       "28  190.623000 2007-03-31\n",
       "29  190.623000 2007-06-30\n",
       "30  160.814134 2007-09-30\n",
       "31  180.024292 2007-12-31\n",
       "32  180.465905 2008-03-31\n",
       "33  191.064613 2008-06-30\n",
       "34  176.270583 2008-09-30\n",
       "35  148.228169 2008-12-31\n",
       "36  195.922354 2009-03-31\n",
       "37  177.816228 2009-06-30\n",
       "38  205.196224 2009-09-30\n",
       "39  178.478648 2009-12-31\n",
       "40  207.183482 2010-03-31\n",
       "41  191.727033 2010-06-30\n",
       "42  238.758799 2010-09-30), ('economics_11.csv',               y         ds\n",
       "0   6310.053960 2000-03-31\n",
       "1   6838.354995 2000-06-30\n",
       "2   6746.209466 2000-09-30\n",
       "3   7406.585759 2000-12-31\n",
       "4   5956.829431 2001-03-31\n",
       "5   6623.348760 2001-06-30\n",
       "6   6214.836913 2001-09-30\n",
       "7   6693.993666 2001-12-31\n",
       "8   5763.323820 2002-03-31\n",
       "9   6712.422772 2002-06-30\n",
       "10  6531.203231 2002-09-30\n",
       "11  6736.994913 2002-12-31\n",
       "12  5966.043984 2003-03-31\n",
       "13  6485.130466 2003-06-30\n",
       "14  6227.122984 2003-09-30\n",
       "15  6838.354995 2003-12-31\n",
       "16  5628.177043 2004-03-31\n",
       "17  6245.552090 2004-06-30\n",
       "18  5962.972466 2004-09-30\n",
       "19  6611.062689 2004-12-31\n",
       "20  5357.883491 2005-03-31\n",
       "21  5790.967478 2005-06-30\n",
       "22  5188.950020 2005-09-30\n",
       "23  5560.603655 2005-12-31), ('economics_39.csv',                y         ds\n",
       "0    4298.862648 2000-01-31\n",
       "1    4338.199156 2000-02-29\n",
       "2    4347.943719 2000-03-31\n",
       "3    4336.551178 2000-04-30\n",
       "4    4331.535594 2000-05-31\n",
       "..           ...        ...\n",
       "154  5700.001832 2012-11-30\n",
       "155  5504.823967 2012-12-31\n",
       "156  5555.338062 2013-01-31\n",
       "157  5560.496949 2013-02-28\n",
       "158  5563.362997 2013-03-31\n",
       "\n",
       "[159 rows x 2 columns]), ('economics_89.csv',               y         ds\n",
       "0    771.239401 2000-01-02\n",
       "1    663.445012 2000-01-09\n",
       "2    494.215359 2000-01-16\n",
       "3    620.854921 2000-01-23\n",
       "4    578.264830 2000-01-30\n",
       "..          ...        ...\n",
       "926  341.192554 2017-10-01\n",
       "927  359.660824 2017-10-08\n",
       "928  355.514886 2017-10-15\n",
       "929  218.322026 2017-10-22\n",
       "930   11.025124 2017-10-29\n",
       "\n",
       "[931 rows x 2 columns]), ('economics_62.csv',              y         ds\n",
       "0    13.741771 2000-01-31\n",
       "1    13.764480 2000-02-29\n",
       "2    13.639580 2000-03-31\n",
       "3    13.616871 2000-04-30\n",
       "4    13.526035 2000-05-31\n",
       "..         ...        ...\n",
       "139  13.298944 2011-08-31\n",
       "140  13.491971 2011-09-30\n",
       "141  13.537390 2011-10-31\n",
       "142  13.594162 2011-11-30\n",
       "143  13.174044 2011-12-31\n",
       "\n",
       "[144 rows x 2 columns]), ('economics_76.csv',               y         ds\n",
       "0    726.487025 2000-01-02\n",
       "1    589.776083 2000-01-09\n",
       "2    472.840939 2000-01-16\n",
       "3    496.915821 2000-01-23\n",
       "4    588.056449 2000-01-30\n",
       "..          ...        ...\n",
       "926  379.980677 2017-10-01\n",
       "927  379.980677 2017-10-08\n",
       "928  438.448249 2017-10-15\n",
       "929  274.223156 2017-10-22\n",
       "930   15.418166 2017-10-29\n",
       "\n",
       "[931 rows x 2 columns]), ('economics_77.csv',               y         ds\n",
       "0    106.128278 2000-01-02\n",
       "1     83.792486 2000-01-09\n",
       "2     93.409285 2000-01-16\n",
       "3     90.772421 2000-01-23\n",
       "4     94.495053 2000-01-30\n",
       "..          ...        ...\n",
       "742   70.142835 2014-03-23\n",
       "743   86.429350 2014-03-30\n",
       "744   85.808912 2014-04-06\n",
       "745  100.699440 2014-04-13\n",
       "746   11.666490 2014-04-20\n",
       "\n",
       "[747 rows x 2 columns]), ('economics_63.csv',                  y         ds\n",
       "0     45941.830946 2000-01-31\n",
       "1     47183.156750 2000-02-29\n",
       "2     48079.986172 2000-03-31\n",
       "3     49206.005336 2000-04-30\n",
       "4     49102.798776 2000-05-31\n",
       "..             ...        ...\n",
       "139   94969.929576 2011-08-31\n",
       "140   97676.076770 2011-09-30\n",
       "141  104101.218989 2011-10-31\n",
       "142  109062.963357 2011-11-30\n",
       "143  111004.670233 2011-12-31\n",
       "\n",
       "[144 rows x 2 columns]), ('economics_88.csv',               y         ds\n",
       "0    179.905276 2000-01-02\n",
       "1    156.586386 2000-01-09\n",
       "2    133.860349 2000-01-16\n",
       "3    142.357911 2000-01-23\n",
       "4    126.548494 2000-01-30\n",
       "..          ...        ...\n",
       "926  102.241515 2017-10-01\n",
       "927  120.224727 2017-10-08\n",
       "928  112.715254 2017-10-15\n",
       "929   76.155977 2017-10-22\n",
       "930    5.211219 2017-10-29\n",
       "\n",
       "[931 rows x 2 columns]), ('economics_75.csv',               y         ds\n",
       "0    582.459818 2000-01-02\n",
       "1    552.256802 2000-01-09\n",
       "2    522.740219 2000-01-16\n",
       "3    513.816600 2000-01-23\n",
       "4    557.061828 2000-01-30\n",
       "..          ...        ...\n",
       "926  415.656798 2017-10-01\n",
       "927  473.317101 2017-10-08\n",
       "928  513.816600 2017-10-15\n",
       "929  564.612582 2017-10-22\n",
       "930   12.721107 2017-10-29\n",
       "\n",
       "[931 rows x 2 columns]), ('economics_61.csv',              y         ds\n",
       "0    14.303180 2000-01-31\n",
       "1    13.828167 2000-02-29\n",
       "2    13.293778 2000-03-31\n",
       "3    13.194817 2000-04-30\n",
       "4    12.719804 2000-05-31\n",
       "..         ...        ...\n",
       "139  11.809364 2011-08-31\n",
       "140  12.917726 2011-09-30\n",
       "141  12.917726 2011-10-31\n",
       "142  12.126039 2011-11-30\n",
       "143  10.028066 2011-12-31\n",
       "\n",
       "[144 rows x 2 columns]), ('economics_49.csv',                 y         ds\n",
       "0     2084.681748 2000-03-31\n",
       "1     2774.836107 2000-06-30\n",
       "2     2463.365019 2000-09-30\n",
       "3     2307.629475 2000-12-31\n",
       "4     2067.468872 2001-03-31\n",
       "..            ...        ...\n",
       "139  18058.230608 2034-12-31\n",
       "140  18000.854354 2035-03-31\n",
       "141  19004.938783 2035-06-30\n",
       "142  18107.410253 2035-09-30\n",
       "143  17917.248957 2035-12-31\n",
       "\n",
       "[144 rows x 2 columns]), ('economics_48.csv',               y         ds\n",
       "0     18.493425 2000-03-31\n",
       "1     19.908171 2000-06-30\n",
       "2     20.713293 2000-09-30\n",
       "3     19.371424 2000-12-31\n",
       "4     18.736350 2001-03-31\n",
       "..          ...        ...\n",
       "213  287.851626 2053-06-30\n",
       "214  304.046595 2053-09-30\n",
       "215  255.461687 2053-12-31\n",
       "216  249.677770 2054-03-31\n",
       "217  285.538059 2054-06-30\n",
       "\n",
       "[218 rows x 2 columns]), ('economics_60.csv',                y         ds\n",
       "0    4130.226483 2000-01-31\n",
       "1    4188.000531 2000-02-29\n",
       "2    4388.137632 2000-03-31\n",
       "3    4490.887678 2000-04-30\n",
       "4    4342.917860 2000-05-31\n",
       "..           ...        ...\n",
       "139  4497.591418 2011-08-31\n",
       "140  4934.919017 2011-09-30\n",
       "141  5463.051817 2011-10-31\n",
       "142  5548.128368 2011-11-30\n",
       "143  4227.491652 2011-12-31\n",
       "\n",
       "[144 rows x 2 columns]), ('economics_74.csv',               y         ds\n",
       "0    108.465615 2000-01-02\n",
       "1     94.121158 2000-01-09\n",
       "2     94.052851 2000-01-16\n",
       "3     82.440671 2000-01-23\n",
       "4     92.345178 2000-01-30\n",
       "..          ...        ...\n",
       "926   74.858601 2017-10-01\n",
       "927   74.995215 2017-10-08\n",
       "928   74.721987 2017-10-15\n",
       "929   81.347760 2017-10-22\n",
       "930   11.606375 2017-10-29\n",
       "\n",
       "[931 rows x 2 columns]), ('economics_58.csv',                 y         ds\n",
       "0    43747.680657 2000-01-31\n",
       "1    46502.760560 2000-02-29\n",
       "2    47797.339422 2000-03-31\n",
       "3    48866.186947 2000-04-30\n",
       "4    48225.650163 2000-05-31\n",
       "..            ...        ...\n",
       "139  73823.969594 2011-08-31\n",
       "140  76872.307301 2011-09-30\n",
       "141  79573.366029 2011-10-31\n",
       "142  80080.779205 2011-11-30\n",
       "143  66399.916747 2011-12-31\n",
       "\n",
       "[144 rows x 2 columns]), ('economics_70.csv',                y         ds\n",
       "0    1023.750187 2000-01-02\n",
       "1     853.847488 2000-01-09\n",
       "2     817.532407 2000-01-16\n",
       "3     803.265768 2000-01-23\n",
       "4     773.435523 2000-01-30\n",
       "..           ...        ...\n",
       "926   606.126759 2017-10-01\n",
       "927   658.005446 2017-10-08\n",
       "928   600.938890 2017-10-15\n",
       "929   654.114544 2017-10-22\n",
       "930     5.630960 2017-10-29\n",
       "\n",
       "[931 rows x 2 columns]), ('economics_64.csv',              y         ds\n",
       "0    18.690698 2000-01-31\n",
       "1    18.628251 2000-02-29\n",
       "2    18.316012 2000-03-31\n",
       "3    18.300400 2000-04-30\n",
       "4    18.269177 2000-05-31\n",
       "..         ...        ...\n",
       "139  17.894490 2011-08-31\n",
       "140  18.237953 2011-09-30\n",
       "141  18.503355 2011-10-31\n",
       "142  18.987325 2011-11-30\n",
       "143  18.768758 2011-12-31\n",
       "\n",
       "[144 rows x 2 columns]), ('economics_65.csv',                 y         ds\n",
       "0    21566.618585 2000-01-31\n",
       "1    21265.866602 2000-02-29\n",
       "2    22233.768921 2000-03-31\n",
       "3    22557.420800 2000-04-30\n",
       "4    22749.779936 2000-05-31\n",
       "..            ...        ...\n",
       "139  38885.047451 2011-08-31\n",
       "140  40620.859653 2011-09-30\n",
       "141  45322.971863 2011-10-31\n",
       "142  47329.002851 2011-11-30\n",
       "143  41400.982815 2011-12-31\n",
       "\n",
       "[144 rows x 2 columns]), ('economics_71.csv',              y         ds\n",
       "0    69.352955 2000-01-02\n",
       "1    66.104898 2000-01-09\n",
       "2    55.366421 2000-01-16\n",
       "3    61.265954 2000-01-23\n",
       "4    57.686462 2000-01-30\n",
       "..         ...        ...\n",
       "926  43.302206 2017-10-01\n",
       "927  50.328617 2017-10-08\n",
       "928  47.080559 2017-10-15\n",
       "929  35.878074 2017-10-22\n",
       "930  12.213653 2017-10-29\n",
       "\n",
       "[931 rows x 2 columns]), ('economics_59.csv',              y         ds\n",
       "0    12.832260 2000-01-31\n",
       "1    12.730142 2000-02-29\n",
       "2    12.253596 2000-03-31\n",
       "3    11.862147 2000-04-30\n",
       "4    11.725991 2000-05-31\n",
       "..         ...        ...\n",
       "139  11.487717 2011-08-31\n",
       "140  12.287635 2011-09-30\n",
       "141  12.100420 2011-10-31\n",
       "142  11.555795 2011-11-30\n",
       "143   9.462394 2011-12-31\n",
       "\n",
       "[144 rows x 2 columns]), ('economics_98.csv',             y         ds\n",
       "0   38.590147 2000-03-31\n",
       "1   29.391620 2000-06-30\n",
       "2   27.626482 2000-09-30\n",
       "3   29.990757 2000-12-31\n",
       "4   38.830844 2001-03-31\n",
       "..        ...        ...\n",
       "67  33.078223 2016-12-31\n",
       "68  40.655590 2017-03-31\n",
       "69  31.641436 2017-06-30\n",
       "70  30.239208 2017-09-30\n",
       "71  33.922785 2017-12-31\n",
       "\n",
       "[72 rows x 2 columns]), ('economics_67.csv',                y         ds\n",
       "0    4519.078765 2000-01-31\n",
       "1    4664.683965 2000-02-29\n",
       "2    4815.290137 2000-03-31\n",
       "3    4915.117217 2000-04-30\n",
       "4    4855.490252 2000-05-31\n",
       "..           ...        ...\n",
       "139  8551.592680 2011-08-31\n",
       "140  8797.217305 2011-09-30\n",
       "141  8851.073918 2011-10-31\n",
       "142  8804.718762 2011-11-30\n",
       "143  8877.040500 2011-12-31\n",
       "\n",
       "[144 rows x 2 columns]), ('economics_73.csv',                y         ds\n",
       "0    1451.432225 2000-01-01\n",
       "1    1133.027313 2000-01-02\n",
       "2    1099.064122 2000-01-03\n",
       "3    1082.082526 2000-01-04\n",
       "4    1147.178642 2000-01-05\n",
       "..           ...        ...\n",
       "742   838.679660 2002-01-12\n",
       "743   946.229764 2002-01-13\n",
       "744   926.417902 2002-01-14\n",
       "745   981.608087 2002-01-15\n",
       "746    13.657152 2002-01-16\n",
       "\n",
       "[747 rows x 2 columns]), ('economics_72.csv',               y         ds\n",
       "0    866.818231 2000-01-02\n",
       "1    762.903182 2000-01-09\n",
       "2    649.023676 2000-01-16\n",
       "3    742.974268 2000-01-23\n",
       "4    679.628793 2000-01-30\n",
       "..          ...        ...\n",
       "926  530.161941 2017-10-01\n",
       "927  482.474898 2017-10-08\n",
       "928  466.816465 2017-10-15\n",
       "929  456.852009 2017-10-22\n",
       "930    6.316212 2017-10-29\n",
       "\n",
       "[931 rows x 2 columns]), ('economics_66.csv',              y         ds\n",
       "0    18.175935 2000-01-31\n",
       "1    18.181708 2000-02-29\n",
       "2    18.158616 2000-03-31\n",
       "3    18.187481 2000-04-30\n",
       "4    18.170162 2000-05-31\n",
       "..         ...        ...\n",
       "139  17.939238 2011-08-31\n",
       "140  18.037381 2011-09-30\n",
       "141  18.118204 2011-10-31\n",
       "142  18.043154 2011-11-30\n",
       "143  17.719859 2011-12-31\n",
       "\n",
       "[144 rows x 2 columns]), ('economics_99.csv',                 y         ds\n",
       "0    18242.822666 2000-01-31\n",
       "1    20165.686460 2000-02-29\n",
       "2    24118.574272 2000-03-31\n",
       "3    21339.632734 2000-04-30\n",
       "4    21714.091494 2000-05-31\n",
       "..            ...        ...\n",
       "171  31712.501604 2014-04-30\n",
       "172  28649.404865 2014-05-31\n",
       "173  33188.663791 2014-06-30\n",
       "174  35730.407979 2014-07-31\n",
       "175  28140.092790 2014-08-31\n",
       "\n",
       "[176 rows x 2 columns])])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "bc94d566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6dc7c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "12c65f11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "274937f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "91564b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ds</th>\n",
       "      <th>y</th>\n",
       "      <th>t</th>\n",
       "      <th>y_scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2002-01-31</td>\n",
       "      <td>72.434388</td>\n",
       "      <td>1.044286</td>\n",
       "      <td>0.475743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002-02-28</td>\n",
       "      <td>75.966344</td>\n",
       "      <td>1.084286</td>\n",
       "      <td>0.503912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002-03-31</td>\n",
       "      <td>125.119406</td>\n",
       "      <td>1.128571</td>\n",
       "      <td>0.895931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002-04-30</td>\n",
       "      <td>113.051888</td>\n",
       "      <td>1.171429</td>\n",
       "      <td>0.799687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002-05-31</td>\n",
       "      <td>57.914122</td>\n",
       "      <td>1.215714</td>\n",
       "      <td>0.359937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2002-06-30</td>\n",
       "      <td>120.312021</td>\n",
       "      <td>1.258571</td>\n",
       "      <td>0.857590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2002-07-31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.302857</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ds           y         t  y_scaled\n",
       "0 2002-01-31   72.434388  1.044286  0.475743\n",
       "1 2002-02-28   75.966344  1.084286  0.503912\n",
       "2 2002-03-31  125.119406  1.128571  0.895931\n",
       "3 2002-04-30  113.051888  1.171429  0.799687\n",
       "4 2002-05-31   57.914122  1.215714  0.359937\n",
       "5 2002-06-30  120.312021  1.258571  0.857590\n",
       "6 2002-07-31         NaN  1.302857       NaN"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.make_future_dataframe(vl, n_historic_predictions = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "0297cfa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>ds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86.071665</td>\n",
       "      <td>2002-01-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>87.445203</td>\n",
       "      <td>2002-01-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83.717027</td>\n",
       "      <td>2002-01-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96.961864</td>\n",
       "      <td>2002-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60.366870</td>\n",
       "      <td>2002-01-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>110.599140</td>\n",
       "      <td>2002-07-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>152.393959</td>\n",
       "      <td>2002-07-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>124.138307</td>\n",
       "      <td>2002-07-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>101.671139</td>\n",
       "      <td>2002-07-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>94.411006</td>\n",
       "      <td>2002-07-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>195 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              y         ds\n",
       "0     86.071665 2002-01-06\n",
       "1     87.445203 2002-01-07\n",
       "2     83.717027 2002-01-08\n",
       "3     96.961864 2002-01-09\n",
       "4     60.366870 2002-01-10\n",
       "..          ...        ...\n",
       "190  110.599140 2002-07-15\n",
       "191  152.393959 2002-07-16\n",
       "192  124.138307 2002-07-17\n",
       "193  101.671139 2002-07-18\n",
       "194   94.411006 2002-07-19\n",
       "\n",
       "[195 rows x 2 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "44c445e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>ds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>118.546043</td>\n",
       "      <td>2000-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104.810656</td>\n",
       "      <td>2000-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86.660324</td>\n",
       "      <td>2000-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100.003271</td>\n",
       "      <td>2000-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95.392105</td>\n",
       "      <td>2000-01-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>110.599140</td>\n",
       "      <td>2002-07-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927</th>\n",
       "      <td>152.393959</td>\n",
       "      <td>2002-07-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>928</th>\n",
       "      <td>124.138307</td>\n",
       "      <td>2002-07-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>929</th>\n",
       "      <td>101.671139</td>\n",
       "      <td>2002-07-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>930</th>\n",
       "      <td>94.411006</td>\n",
       "      <td>2002-07-19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>931 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              y         ds\n",
       "0    118.546043 2000-01-01\n",
       "1    104.810656 2000-01-02\n",
       "2     86.660324 2000-01-03\n",
       "3    100.003271 2000-01-04\n",
       "4     95.392105 2000-01-05\n",
       "..          ...        ...\n",
       "926  110.599140 2002-07-15\n",
       "927  152.393959 2002-07-16\n",
       "928  124.138307 2002-07-17\n",
       "929  101.671139 2002-07-18\n",
       "930   94.411006 2002-07-19\n",
       "\n",
       "[931 rows x 2 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "c99c20b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M'"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d569cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "3e447553",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "931"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f1b7bd85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "748"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "374b822f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vl) - freq_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc7656e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b1420a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
